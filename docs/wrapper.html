

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Wrapper &mdash; TX2  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/theme_overrides.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Dashboard" href="dashboard.html" />
    <link rel="prev" title="Dashboard Widgets" href="dashboard_widgets.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> TX2
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Usage</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="basic_usage.html">Basic Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="dashboard_interface.html">Dashboard Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="dashboard_widgets.html">Dashboard Widgets</a></li>
</ul>
<p class="caption"><span class="caption-text">API</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Wrapper</a></li>
<li class="toctree-l1"><a class="reference internal" href="dashboard.html">Dashboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="calc.html">Calc</a></li>
<li class="toctree-l1"><a class="reference internal" href="visualization.html">Visualization</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">TX2</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Wrapper</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/wrapper.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-tx2.wrapper">
<span id="wrapper"></span><h1>Wrapper<a class="headerlink" href="#module-tx2.wrapper" title="Permalink to this headline">¶</a></h1>
<p>The wrapper class around a transformer and its functionality.</p>
<dl class="py class">
<dt id="tx2.wrapper.Wrapper">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">tx2.wrapper.</span></code><code class="sig-name descname"><span class="pre">Wrapper</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_texts</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">,</span> </span><span class="pre">pandas.core.series.Series</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">,</span> </span><span class="pre">pandas.core.series.Series</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_texts</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">,</span> </span><span class="pre">pandas.core.series.Series</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">,</span> </span><span class="pre">pandas.core.series.Series</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encodings</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classifier</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">language_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cuda_device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'data'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tx2.wrapper.Wrapper" title="Permalink to this definition">¶</a></dt>
<dd><p>A wrapper or interface class between a transformer and the dashboard.</p>
<p>This class handles running all of the calculations for the data needed by
the front-end visualizations.</p>
<p><strong>Methods:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.__init__" title="tx2.wrapper.Wrapper.__init__"><code class="xref py py-obj docutils literal notranslate"><span class="pre">__init__</span></code></a>(train_texts, train_labels, …[, …])</p></td>
<td><p>Constructor.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.classify" title="tx2.wrapper.Wrapper.classify"><code class="xref py py-obj docutils literal notranslate"><span class="pre">classify</span></code></a>(texts)</p></td>
<td><p>Predict the category of each passed entry text.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.embed" title="tx2.wrapper.Wrapper.embed"><code class="xref py py-obj docutils literal notranslate"><span class="pre">embed</span></code></a>(texts)</p></td>
<td><p>Get a sequence embedding from the language model for each passed text entry.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.encode" title="tx2.wrapper.Wrapper.encode"><code class="xref py py-obj docutils literal notranslate"><span class="pre">encode</span></code></a>(text)</p></td>
<td><p>Encode/tokenize passed text into a format expected by transformer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.prepare" title="tx2.wrapper.Wrapper.prepare"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prepare</span></code></a>([umap_args, clustering_alg, …])</p></td>
<td><p>Run all necessary precompute step to support the dashboard.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.project" title="tx2.wrapper.Wrapper.project"><code class="xref py py-obj docutils literal notranslate"><span class="pre">project</span></code></a>(texts)</p></td>
<td><p>Use the wrapper’s UMAP model to project passed texts into two dimensions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.recompute_projections" title="tx2.wrapper.Wrapper.recompute_projections"><code class="xref py py-obj docutils literal notranslate"><span class="pre">recompute_projections</span></code></a>([umap_args, …])</p></td>
<td><p>Re-run both projection training and clustering algorithms.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.recompute_visual_clusterings" title="tx2.wrapper.Wrapper.recompute_visual_clusterings"><code class="xref py py-obj docutils literal notranslate"><span class="pre">recompute_visual_clusterings</span></code></a>([…])</p></td>
<td><p>Re-run the clustering algorithm.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.search_test_df" title="tx2.wrapper.Wrapper.search_test_df"><code class="xref py py-obj docutils literal notranslate"><span class="pre">search_test_df</span></code></a>(search)</p></td>
<td><p>Get a list of test dataframe indices that have any of the listed terms in the passed string.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.soft_classify" title="tx2.wrapper.Wrapper.soft_classify"><code class="xref py py-obj docutils literal notranslate"><span class="pre">soft_classify</span></code></a>(texts)</p></td>
<td><p>Get the non-argmaxed final prediction layer outputs of the classification head.</p></td>
</tr>
</tbody>
</table>
<p><strong>Attributes:</strong></p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.batch_size" title="tx2.wrapper.Wrapper.batch_size"><code class="xref py py-obj docutils literal notranslate"><span class="pre">batch_size</span></code></a></p></td>
<td><p>The batch size to use in backend dataloader creation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.cache_path" title="tx2.wrapper.Wrapper.cache_path"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cache_path</span></code></a></p></td>
<td><p>The directory path to cache pre-calculated values.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.classification_function" title="tx2.wrapper.Wrapper.classification_function"><code class="xref py py-obj docutils literal notranslate"><span class="pre">classification_function</span></code></a></p></td>
<td><p>A function to take a single set of inputs and return the index of the predicted class.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.classifier" title="tx2.wrapper.Wrapper.classifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">classifier</span></code></a></p></td>
<td><p>A class containing the entire network, which can be called as a function taking the  encoded input and returning the output classification.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.cluster_class_word_sets" title="tx2.wrapper.Wrapper.cluster_class_word_sets"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cluster_class_word_sets</span></code></a></p></td>
<td><p>A dictionary of clusters, further divided version of <code class="code docutils literal notranslate"><span class="pre">cluster_word_freqs</span></code> that divides each word count up into the number of entries of each category containing that word, as calculated by <a class="reference internal" href="calc.html#tx2.calc.frequent_words_by_class_in_cluster" title="tx2.calc.frequent_words_by_class_in_cluster"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.calc.frequent_words_by_class_in_cluster()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.cluster_profiles" title="tx2.wrapper.Wrapper.cluster_profiles"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cluster_profiles</span></code></a></p></td>
<td><p>A dictionary of aggregate sorted salience maps for each cluster as calculated by  <a class="reference internal" href="calc.html#tx2.calc.aggregate_cluster_salience_maps" title="tx2.calc.aggregate_cluster_salience_maps"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.calc.aggregate_cluster_salience_maps()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.cluster_word_freqs" title="tx2.wrapper.Wrapper.cluster_word_freqs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cluster_word_freqs</span></code></a></p></td>
<td><p>A dictionary of clusters and sorted top word frequencies for each, as calculated by <a class="reference internal" href="calc.html#tx2.calc.frequent_words_in_cluster" title="tx2.calc.frequent_words_in_cluster"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.calc.frequent_words_in_cluster()</span></code></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.clusters" title="tx2.wrapper.Wrapper.clusters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clusters</span></code></a></p></td>
<td><p>A dictionary of cluster names, each associated with a list of indices of points in that cluster, as  calculated by <a class="reference internal" href="calc.html#tx2.calc.cluster_projections" title="tx2.calc.cluster_projections"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.calc.cluster_projections()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.cuda_device" title="tx2.wrapper.Wrapper.cuda_device"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cuda_device</span></code></a></p></td>
<td><p>Set the device for pytorch to place tensors on, pass either “cpu” or “cuda”.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.embedding_function" title="tx2.wrapper.Wrapper.embedding_function"><code class="xref py py-obj docutils literal notranslate"><span class="pre">embedding_function</span></code></a></p></td>
<td><p>A function to take a single set of inputs and return embedded versions - a sequence representation from the language model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.embeddings_testing" title="tx2.wrapper.Wrapper.embeddings_testing"><code class="xref py py-obj docutils literal notranslate"><span class="pre">embeddings_testing</span></code></a></p></td>
<td><p>Precomputed embeddings for each entry in <code class="code docutils literal notranslate"><span class="pre">test_texts</span></code>, as returned by  <a class="reference internal" href="#tx2.wrapper.Wrapper.embed" title="tx2.wrapper.Wrapper.embed"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.wrapper.Wrapper.embed()</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.embeddings_training" title="tx2.wrapper.Wrapper.embeddings_training"><code class="xref py py-obj docutils literal notranslate"><span class="pre">embeddings_training</span></code></a></p></td>
<td><p>Precomputed embeddings for each entry in <code class="code docutils literal notranslate"><span class="pre">train_texts</span></code>, as returned by  <a class="reference internal" href="#tx2.wrapper.Wrapper.embed" title="tx2.wrapper.Wrapper.embed"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.wrapper.Wrapper.embed()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.encode_function" title="tx2.wrapper.Wrapper.encode_function"><code class="xref py py-obj docutils literal notranslate"><span class="pre">encode_function</span></code></a></p></td>
<td><p>A function to take a single text entry and return an encoded version of it.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.encoder_options" title="tx2.wrapper.Wrapper.encoder_options"><code class="xref py py-obj docutils literal notranslate"><span class="pre">encoder_options</span></code></a></p></td>
<td><p>The default options to pass to the tokenizer’s <code class="code docutils literal notranslate"><span class="pre">encode_plus()</span></code> function.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.encodings" title="tx2.wrapper.Wrapper.encodings"><code class="xref py py-obj docutils literal notranslate"><span class="pre">encodings</span></code></a></p></td>
<td><p>A dictionary associating class label names with integer values.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.language_model" title="tx2.wrapper.Wrapper.language_model"><code class="xref py py-obj docutils literal notranslate"><span class="pre">language_model</span></code></a></p></td>
<td><p>A variable containing only the huggingface language model portion of the network.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.max_clusters" title="tx2.wrapper.Wrapper.max_clusters"><code class="xref py py-obj docutils literal notranslate"><span class="pre">max_clusters</span></code></a></p></td>
<td><p>Maximum number of clusters to retain.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.max_len" title="tx2.wrapper.Wrapper.max_len"><code class="xref py py-obj docutils literal notranslate"><span class="pre">max_len</span></code></a></p></td>
<td><p>The maximum length of each text entry, based on the expected input size of the transformer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.overwrite" title="tx2.wrapper.Wrapper.overwrite"><code class="xref py py-obj docutils literal notranslate"><span class="pre">overwrite</span></code></a></p></td>
<td><p>Whether to ignore cached calculations and overwrite them or not.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.predictions" title="tx2.wrapper.Wrapper.predictions"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predictions</span></code></a></p></td>
<td><p>The predicted class for each entry in <code class="code docutils literal notranslate"><span class="pre">test_texts</span></code>, as returned by <a class="reference internal" href="#tx2.wrapper.Wrapper.classify" title="tx2.wrapper.Wrapper.classify"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.wrapper.Wrapper.classify()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.projections_testing" title="tx2.wrapper.Wrapper.projections_testing"><code class="xref py py-obj docutils literal notranslate"><span class="pre">projections_testing</span></code></a></p></td>
<td><p>The two dimensional projections of <code class="code docutils literal notranslate"><span class="pre">embeddings_testing</span></code>, for each entry in <code class="code docutils literal notranslate"><span class="pre">test_texts</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.projections_training" title="tx2.wrapper.Wrapper.projections_training"><code class="xref py py-obj docutils literal notranslate"><span class="pre">projections_training</span></code></a></p></td>
<td><p>The two dimensional projections of <code class="code docutils literal notranslate"><span class="pre">embeddings_training</span></code>, for each entry in <code class="code docutils literal notranslate"><span class="pre">train_texts</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.projector" title="tx2.wrapper.Wrapper.projector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">projector</span></code></a></p></td>
<td><p>The trained UMAP projector.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.salience_maps" title="tx2.wrapper.Wrapper.salience_maps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">salience_maps</span></code></a></p></td>
<td><p>The salience map for each entry in <code class="code docutils literal notranslate"><span class="pre">test_texts</span></code> as calculated by <a class="reference internal" href="calc.html#tx2.calc.salience_map" title="tx2.calc.salience_map"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.calc.salience_map()</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.soft_classification_function" title="tx2.wrapper.Wrapper.soft_classification_function"><code class="xref py py-obj docutils literal notranslate"><span class="pre">soft_classification_function</span></code></a></p></td>
<td><p>A function to take a single set of inputs and return the (non arg-maxed) output layer of the network.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.test_labels" title="tx2.wrapper.Wrapper.test_labels"><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_labels</span></code></a></p></td>
<td><p>Collection of all class labels used during models testing process.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.test_texts" title="tx2.wrapper.Wrapper.test_texts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_texts</span></code></a></p></td>
<td><p>Collection of all text entries used during models testing process.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.tokenizer" title="tx2.wrapper.Wrapper.tokenizer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tokenizer</span></code></a></p></td>
<td><p>The huggingface tokenizer to use for encoding text input.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.train_labels" title="tx2.wrapper.Wrapper.train_labels"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_labels</span></code></a></p></td>
<td><p>Collection of all class labels used during models training process.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tx2.wrapper.Wrapper.train_texts" title="tx2.wrapper.Wrapper.train_texts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_texts</span></code></a></p></td>
<td><p>Collection of all text entries used during models training process.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="tx2.wrapper.Wrapper.__init__">
<code class="sig-name descname"><span class="pre">__init__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_texts</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">,</span> </span><span class="pre">pandas.core.series.Series</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">,</span> </span><span class="pre">pandas.core.series.Series</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_texts</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">,</span> </span><span class="pre">pandas.core.series.Series</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">numpy.ndarray</span><span class="p"><span class="pre">,</span> </span><span class="pre">pandas.core.series.Series</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">encodings</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classifier</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">language_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tokenizer</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cuda_device</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'data'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tx2.wrapper.Wrapper.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_texts</strong> – A set of text entries that were used during the model’s training process.</p></li>
<li><p><strong>train_labels</strong> – The set of class labels for train_texts.</p></li>
<li><p><strong>test_texts</strong> – The set of text entries that the model hadn’t seen during training.</p></li>
<li><p><strong>test_labels</strong> – The set of class labels for test_texts.</p></li>
<li><p><strong>encodings</strong> – A dictionary associating class label names with integer values.</p></li>
<li><p><strong>classifier</strong> – A class/network containing a language model and classification head.
<strong>Running this variable as a function by default should send the passed inputs through
the entire network and return the argmaxed classification index (reverse encoding)</strong>.
Note that <strong>this argument is not required</strong>, if the user intends to manually specify
classification functions.</p></li>
<li><p><strong>language_model</strong> – A <a class="reference external" href="https://huggingface.co/transformers/main_classes/model.html">huggingface transformer model</a>, if a custom network
class is being used and has a layer representing the output of just the language model,
pass it here. Note that <strong>this argument is not required</strong>, if the user intends to
manually specify classification functions.</p></li>
<li><p><strong>tokenizer</strong> – A <a class="reference external" href="https://huggingface.co/transformers/main_classes/tokenizer.html">huggingface tokenizer</a>. Note that <strong>this
argument is not required</strong>, if the user intends to manually specify encode and
classification functions.</p></li>
<li><p><strong>cuda_device</strong> – Set the device for pytorch to place tensors on, pass either “cpu” or
“cuda”. This variable is used by the default embedding function. If unspecified and a
GPU is found, “cuda” will be used, otherwise it defaults to “cpu”.</p></li>
<li><p><strong>cache_path</strong> – The directory path to cache intermediate outputs from the
<a class="reference internal" href="#tx2.wrapper.Wrapper.prepare" title="tx2.wrapper.Wrapper.prepare"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.wrapper.Wrapper.prepare()</span></code></a> function. This allows the wrapper to precompute
needed values for the dashboard to reduce render time and allow rerunning all wrapper
code without needing to recompute. Note that every wrapper/dashboard instance is expected
to have a unique cache path, otherwise filenames will conflict. You will need to set
this if you intend to use more than one dashboard.</p></li>
<li><p><strong>overwrite</strong> – Whether to ignore the cache and overwrite previous results or not.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.batch_size">
<code class="sig-name descname"><span class="pre">batch_size</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.batch_size" title="Permalink to this definition">¶</a></dt>
<dd><p>The batch size to use in backend dataloader creation.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.cache_path">
<code class="sig-name descname"><span class="pre">cache_path</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.cache_path" title="Permalink to this definition">¶</a></dt>
<dd><p>The directory path to cache pre-calculated values.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.classification_function">
<code class="sig-name descname"><span class="pre">classification_function</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.classification_function" title="Permalink to this definition">¶</a></dt>
<dd><p>A function to take a single set of inputs and return the index of the predicted class.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.classifier">
<code class="sig-name descname"><span class="pre">classifier</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.classifier" title="Permalink to this definition">¶</a></dt>
<dd><p>A class containing the entire network, which can be called as a function taking the 
encoded input and returning the output classification.</p>
</dd></dl>

<dl class="py method">
<dt id="tx2.wrapper.Wrapper.classify">
<code class="sig-name descname"><span class="pre">classify</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#tx2.wrapper.Wrapper.classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the category of each passed entry text.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> – An array of texts to predict on.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An array of predicted classes, whose labels can be reverse looked up through
<code class="code docutils literal notranslate"><span class="pre">encodings</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.cluster_class_word_sets">
<code class="sig-name descname"><span class="pre">cluster_class_word_sets</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.cluster_class_word_sets" title="Permalink to this definition">¶</a></dt>
<dd><p>A dictionary of clusters, further divided version of <code class="code docutils literal notranslate"><span class="pre">cluster_word_freqs</span></code> that divides each
word count up into the number of entries of each category containing that word, as calculated by
<a class="reference internal" href="calc.html#tx2.calc.frequent_words_by_class_in_cluster" title="tx2.calc.frequent_words_by_class_in_cluster"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.calc.frequent_words_by_class_in_cluster()</span></code></a>.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.cluster_profiles">
<code class="sig-name descname"><span class="pre">cluster_profiles</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.cluster_profiles" title="Permalink to this definition">¶</a></dt>
<dd><p>A dictionary of aggregate sorted salience maps for each cluster as calculated by 
<a class="reference internal" href="calc.html#tx2.calc.aggregate_cluster_salience_maps" title="tx2.calc.aggregate_cluster_salience_maps"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.calc.aggregate_cluster_salience_maps()</span></code></a>.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.cluster_word_freqs">
<code class="sig-name descname"><span class="pre">cluster_word_freqs</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.cluster_word_freqs" title="Permalink to this definition">¶</a></dt>
<dd><p>A dictionary of clusters and sorted top word frequencies for each, as calculated by
<a class="reference internal" href="calc.html#tx2.calc.frequent_words_in_cluster" title="tx2.calc.frequent_words_in_cluster"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.calc.frequent_words_in_cluster()</span></code></a></p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.clusters">
<code class="sig-name descname"><span class="pre">clusters</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.clusters" title="Permalink to this definition">¶</a></dt>
<dd><p>A dictionary of cluster names, each associated with a list of indices of points in that cluster, as 
calculated by <a class="reference internal" href="calc.html#tx2.calc.cluster_projections" title="tx2.calc.cluster_projections"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.calc.cluster_projections()</span></code></a>.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.cuda_device">
<code class="sig-name descname"><span class="pre">cuda_device</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.cuda_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the device for pytorch to place tensors on, pass either “cpu” or “cuda”. This 
variable is used by the default embedding function. If unspecified and a GPU is found, 
“cuda” will be used, otherwise it defaults to “cpu”.</p>
</dd></dl>

<dl class="py method">
<dt id="tx2.wrapper.Wrapper.embed">
<code class="sig-name descname"><span class="pre">embed</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#tx2.wrapper.Wrapper.embed" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a sequence embedding from the language model for each passed text entry.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> – An array of texts to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An array of sequence embeddings.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.embedding_function">
<code class="sig-name descname"><span class="pre">embedding_function</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.embedding_function" title="Permalink to this definition">¶</a></dt>
<dd><p>A function to take a single set of inputs and return embedded versions - a sequence
representation from the language model. This variable points to a sensible default function
based on a language model layer being specified in the constructor. If classifier or language
model were not specified to the constructor, <strong>this variable must be assigned to a custom
function definition.</strong></p>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p>Below is a simplified example of creating a customized embed function. 
<code class="code docutils literal notranslate"><span class="pre">my_custom_embedding_function</span></code> will be used by the wrapper, and will be
called with an array of pre-encoded inputs for a single entry, and is expected
to return an array. (TODO: 1d or 2d?)</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">my_custom_embedding_function</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">my_transformer</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;input_id&#39;</span><span class="p">],</span> <span class="n">inputs</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">wrapper</span> <span class="o">=</span> <span class="n">Wrapper</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">wrapper</span><span class="o">.</span><span class="n">embedding_function</span> <span class="o">=</span> <span class="n">my_custom_embedding_function</span>
</pre></div>
</div>
</div>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.embeddings_testing">
<code class="sig-name descname"><span class="pre">embeddings_testing</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.embeddings_testing" title="Permalink to this definition">¶</a></dt>
<dd><p>Precomputed embeddings for each entry in <code class="code docutils literal notranslate"><span class="pre">test_texts</span></code>, as returned by 
<a class="reference internal" href="#tx2.wrapper.Wrapper.embed" title="tx2.wrapper.Wrapper.embed"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.wrapper.Wrapper.embed()</span></code></a>.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.embeddings_training">
<code class="sig-name descname"><span class="pre">embeddings_training</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.embeddings_training" title="Permalink to this definition">¶</a></dt>
<dd><p>Precomputed embeddings for each entry in <code class="code docutils literal notranslate"><span class="pre">train_texts</span></code>, as returned by 
<a class="reference internal" href="#tx2.wrapper.Wrapper.embed" title="tx2.wrapper.Wrapper.embed"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.wrapper.Wrapper.embed()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt id="tx2.wrapper.Wrapper.encode">
<code class="sig-name descname"><span class="pre">encode</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">text</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tx2.wrapper.Wrapper.encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encode/tokenize passed text into a format expected by transformer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>text</strong> – The text entry to tokenize.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tokenized version of the text, by default this calls <code class="code docutils literal notranslate"><span class="pre">encode_plus()</span></code> with
the options specified in <code class="code docutils literal notranslate"><span class="pre">encoder_options</span></code>, and returns a dictionary:</p>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
     <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="p">[],</span>
     <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="p">[]</span>
<span class="p">}</span>
</pre></div>
</div>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.encode_function">
<code class="sig-name descname"><span class="pre">encode_function</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.encode_function" title="Permalink to this definition">¶</a></dt>
<dd><p>A function to take a single text entry and return an encoded version of it. The default
function will utilize the tokenizer given in the constructor if available.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.encoder_options">
<code class="sig-name descname"><span class="pre">encoder_options</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.encoder_options" title="Permalink to this definition">¶</a></dt>
<dd><p>The default options to pass to the tokenizer’s <code class="code docutils literal notranslate"><span class="pre">encode_plus()</span></code> function. See
<a class="reference external" href="https://huggingface.co/transformers/internal/tokenization_utils.html#transformers.tokenization_utils_base.PreTrainedTokenizerBase.encode_plus">huggingface documentation</a>.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.encodings">
<code class="sig-name descname"><span class="pre">encodings</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.encodings" title="Permalink to this definition">¶</a></dt>
<dd><p>A dictionary associating class label names with integer values.</p>
<p>example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s2">&quot;label1&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;label2&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.language_model">
<code class="sig-name descname"><span class="pre">language_model</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.language_model" title="Permalink to this definition">¶</a></dt>
<dd><p>A variable containing only the huggingface language model portion of the network.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.max_clusters">
<code class="sig-name descname"><span class="pre">max_clusters</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.max_clusters" title="Permalink to this definition">¶</a></dt>
<dd><p>Maximum number of clusters to retain. Note that this cannot exceed the number of colors in the dashboard.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.max_len">
<code class="sig-name descname"><span class="pre">max_len</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.max_len" title="Permalink to this definition">¶</a></dt>
<dd><p>The maximum length of each text entry, based on the expected input size of the transformer.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.overwrite">
<code class="sig-name descname"><span class="pre">overwrite</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.overwrite" title="Permalink to this definition">¶</a></dt>
<dd><p>Whether to ignore cached calculations and overwrite them or not.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.predictions">
<code class="sig-name descname"><span class="pre">predictions</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.predictions" title="Permalink to this definition">¶</a></dt>
<dd><p>The predicted class for each entry in <code class="code docutils literal notranslate"><span class="pre">test_texts</span></code>, as returned by
<a class="reference internal" href="#tx2.wrapper.Wrapper.classify" title="tx2.wrapper.Wrapper.classify"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.wrapper.Wrapper.classify()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt id="tx2.wrapper.Wrapper.prepare">
<code class="sig-name descname"><span class="pre">prepare</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">umap_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clustering_alg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'DBSCAN'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clustering_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tx2.wrapper.Wrapper.prepare" title="Permalink to this definition">¶</a></dt>
<dd><p>Run all necessary precompute step to support the dashboard. <strong>This function must
be called before using in a dashboard instance.</strong></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>umap_args</strong> – Dictionary of arguments to pass into the UMAP model on instantiation.</p></li>
<li><p><strong>clustering_alg</strong> – The name of the clustering algorithm to use, a class name
from sklearn.cluster, see <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster">sklearn’s documentation</a>.
(“DBSCAN”, “KMeans”, “AffinityPropagation”, “Birch”, “OPTICS”, “AgglomerativeClustering”,
“SpectralClustering”, “SpectralBiclustering”, “SpectralCoclustering”, “MiniBatchKMeans”,
“FeatureAgglomeration”, “MeanShift”)</p></li>
<li><p><strong>clustering_args</strong> – Dictionary of arguments to pass into clustering algorithm on instantiation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tx2.wrapper.Wrapper.project">
<code class="sig-name descname"><span class="pre">project</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">numpy.ndarray</span><a class="headerlink" href="#tx2.wrapper.Wrapper.project" title="Permalink to this definition">¶</a></dt>
<dd><p>Use the wrapper’s UMAP model to project passed texts into two dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> – An array of texts to embed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A Nx2 numpy array, containing a size 2 array of coordinates for each of the N
input text entries.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.projections_testing">
<code class="sig-name descname"><span class="pre">projections_testing</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.projections_testing" title="Permalink to this definition">¶</a></dt>
<dd><p>The two dimensional projections of <code class="code docutils literal notranslate"><span class="pre">embeddings_testing</span></code>, for each entry in <code class="code docutils literal notranslate"><span class="pre">test_texts</span></code>.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.projections_training">
<code class="sig-name descname"><span class="pre">projections_training</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.projections_training" title="Permalink to this definition">¶</a></dt>
<dd><p>The two dimensional projections of <code class="code docutils literal notranslate"><span class="pre">embeddings_training</span></code>, for each entry in <code class="code docutils literal notranslate"><span class="pre">train_texts</span></code>.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.projector">
<code class="sig-name descname"><span class="pre">projector</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.projector" title="Permalink to this definition">¶</a></dt>
<dd><p>The trained UMAP projector. See <a class="reference external" href="https://umap-learn.readthedocs.io/en/latest/">umap-learn documentation</a>.</p>
</dd></dl>

<dl class="py method">
<dt id="tx2.wrapper.Wrapper.recompute_projections">
<code class="sig-name descname"><span class="pre">recompute_projections</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">umap_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clustering_alg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'DBSCAN'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clustering_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tx2.wrapper.Wrapper.recompute_projections" title="Permalink to this definition">¶</a></dt>
<dd><p>Re-run both projection training and clustering algorithms. Note that this
automatically overrides both previously saved projections as well as clustering
data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>umap_args</strong> – Dictionary of arguments to pass into the UMAP model on instantiation.</p></li>
<li><p><strong>clustering_alg</strong> – <p>The name of the clustering algorithm to use, a class name
from sklearn.cluster, see <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster">sklearn’s documentation</a>.
(“DBSCAN”, “KMeans”, “AffinityPropagation”, “Birch”, “OPTICS”, “AgglomerativeClustering”,
“SpectralClustering”, “SpectralBiclustering”, “SpectralCoclustering”, “MiniBatchKMeans”,
“FeatureAgglomeration”, “MeanShift”)</p>
</p></li>
<li><p><strong>clustering_args</strong> – Dictionary of arguments to pass into clustering algorithm on instantiation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="tx2.wrapper.Wrapper.recompute_visual_clusterings">
<code class="sig-name descname"><span class="pre">recompute_visual_clusterings</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">clustering_alg</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'DBSCAN'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">clustering_args</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{}</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#tx2.wrapper.Wrapper.recompute_visual_clusterings" title="Permalink to this definition">¶</a></dt>
<dd><p>Re-run the clustering algorithm. Note that this automatically overrides any
previously cached data for clusters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>clustering_alg</strong> – <p>The name of the clustering algorithm to use, a class name
from sklearn.cluster, see <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster">sklearn’s documentation</a>.
(“DBSCAN”, “KMeans”, “AffinityPropagation”, “Birch”, “OPTICS”, “AgglomerativeClustering”,
“SpectralClustering”, “SpectralBiclustering”, “SpectralCoclustering”, “MiniBatchKMeans”,
“FeatureAgglomeration”, “MeanShift”)</p>
</p></li>
<li><p><strong>clustering_args</strong> – Dictionary of arguments to pass into the clustering algorithm on instantiation.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.salience_maps">
<code class="sig-name descname"><span class="pre">salience_maps</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.salience_maps" title="Permalink to this definition">¶</a></dt>
<dd><p>The salience map for each entry in <code class="code docutils literal notranslate"><span class="pre">test_texts</span></code> as calculated by <a class="reference internal" href="calc.html#tx2.calc.salience_map" title="tx2.calc.salience_map"><code class="xref py py-meth docutils literal notranslate"><span class="pre">tx2.calc.salience_map()</span></code></a>.</p>
</dd></dl>

<dl class="py method">
<dt id="tx2.wrapper.Wrapper.search_test_df">
<code class="sig-name descname"><span class="pre">search_test_df</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">search</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#tx2.wrapper.Wrapper.search_test_df" title="Permalink to this definition">¶</a></dt>
<dd><p>Get a list of test dataframe indices that have any of the listed terms in the passed string.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>search</strong> – The search string, can contain multiple terms delimited with ‘&amp;’ to search for
entries that have all of the terms.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A list of the indices for the <code class="code docutils literal notranslate"><span class="pre">test_df</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.soft_classification_function">
<code class="sig-name descname"><span class="pre">soft_classification_function</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.soft_classification_function" title="Permalink to this definition">¶</a></dt>
<dd><p>A function to take a single set of inputs and return the (non arg-maxed) output layer of
the network.</p>
</dd></dl>

<dl class="py method">
<dt id="tx2.wrapper.Wrapper.soft_classify">
<code class="sig-name descname"><span class="pre">soft_classify</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">texts</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#tx2.wrapper.Wrapper.soft_classify" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the non-argmaxed final prediction layer outputs of the classification head.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>texts</strong> – An array of texts to predict on.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An Nxd array of arrays, N the number of entries to predict on and d the number of
categories.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.test_labels">
<code class="sig-name descname"><span class="pre">test_labels</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.test_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Collection of all class labels used during models testing process.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.test_texts">
<code class="sig-name descname"><span class="pre">test_texts</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.test_texts" title="Permalink to this definition">¶</a></dt>
<dd><p>Collection of all text entries used during models testing process.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.tokenizer">
<code class="sig-name descname"><span class="pre">tokenizer</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.tokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>The huggingface tokenizer to use for encoding text input.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.train_labels">
<code class="sig-name descname"><span class="pre">train_labels</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.train_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Collection of all class labels used during models training process.</p>
</dd></dl>

<dl class="py attribute">
<dt id="tx2.wrapper.Wrapper.train_texts">
<code class="sig-name descname"><span class="pre">train_texts</span></code><a class="headerlink" href="#tx2.wrapper.Wrapper.train_texts" title="Permalink to this definition">¶</a></dt>
<dd><p>Collection of all text entries used during models training process.</p>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="dashboard.html" class="btn btn-neutral float-right" title="Dashboard" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="dashboard_widgets.html" class="btn btn-neutral float-left" title="Dashboard Widgets" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2020, Nathan Martindale, Scott Stewart.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1 - Default Approach\n",
    "\n",
    "This notebook demonstrates how to use the TX2 dashboard with a sequence classification transformer using the default approach as described in the \"Basic Usage\" docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -q ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We enable logging to view the output from `wrapper.prepare()` further down in the notebook. (It's a long running function, and logs which step it's on.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "# import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import cuda\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example notebook, we use the 20 newsgroups dataset, which can be downloaded through sklearn via below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "train_data = fetch_20newsgroups(subset='train')\n",
    "test_data = fetch_20newsgroups(subset='test')\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Defined below is a simple sequence classification model with a variable for the language model itself `l1`. Since it is a BERT model, we take the sequence embedding from the `[CLS]` token (via `output_1[0][:, 0, :])`) and pipe that into the linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "        self.l2 = torch.nn.Linear(768, 20)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        output_1= self.l1(ids, mask)\n",
    "        output = self.l2(output_1[0][:, 0, :]) # use just the [CLS] output embedding\n",
    "        return output\n",
    "    \n",
    "model = BERTClass()\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some simplistic data cleaning, and putting all data into dataframes for the wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text[text.index(\"\\n\\n\")+2:]\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"    \", \" \")\n",
    "    text = text.replace(\"   \", \" \")\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_rows = []\n",
    "for i in range(len(train_data[\"data\"])):\n",
    "    row = {}\n",
    "    row[\"text\"] = clean_text(train_data[\"data\"][i])\n",
    "    row[\"target\"] = train_data['target'][i]\n",
    "    if row[\"text\"] == \"\" or row[\"text\"] == \" \": continue\n",
    "    train_rows.append(row)\n",
    "train_df = pd.DataFrame(train_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rows = []\n",
    "for i in range(len(test_data[\"data\"])):\n",
    "    row = {}\n",
    "    row[\"text\"] = clean_text(test_data[\"data\"][i])\n",
    "    row[\"target\"] = test_data['target'][i]\n",
    "    if row[\"text\"] == \"\" or row[\"text\"] == \" \": continue\n",
    "    test_rows.append(row)\n",
    "test_df = pd.DataFrame(test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "This section minimally trains the classification and language model - nothing fancy here, just to give the dashboard demo something to work with. Most of this is similar to the huggingface tutorial notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11296\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "class EncodedSet(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        print(self.len)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.data.text[index])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.target[index], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "train_set = EncodedSet(train_df, tokenizer, 256)\n",
    "test_set = EncodedSet(test_df[:1000], tokenizer, 256)\n",
    "\n",
    "train_params = {'batch_size': 16,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': 2,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "# put everything into data loaders\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "    loss_history = []\n",
    "    for _,data in tqdm(enumerate(train_loader, 0), total=len(train_loader), desc=f\"Epoch {epoch}\"):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask).squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, targets)\n",
    "        if _%100==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         torch.cuda.empty_cache()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b94bdea3894b4182b19b14f4284e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch 0'), FloatProgress(value=0.0, max=706.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  2.988447904586792\n",
      "Epoch: 0, Loss:  1.9380192756652832\n",
      "Epoch: 0, Loss:  0.7788337469100952\n",
      "Epoch: 0, Loss:  1.1525495052337646\n",
      "Epoch: 0, Loss:  0.9198087453842163\n",
      "Epoch: 0, Loss:  1.2806051969528198\n",
      "Epoch: 0, Loss:  0.41468989849090576\n",
      "Epoch: 0, Loss:  0.864919126033783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(1):\n",
    "    losses.extend(train(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapper uses an `encodings` dictionary for various labels/visualizations, and can be set up with something similar to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism': 0,\n",
       " 'comp.graphics': 1,\n",
       " 'comp.os.ms-windows.misc': 2,\n",
       " 'comp.sys.ibm.pc.hardware': 3,\n",
       " 'comp.sys.mac.hardware': 4,\n",
       " 'comp.windows.x': 5,\n",
       " 'misc.forsale': 6,\n",
       " 'rec.autos': 7,\n",
       " 'rec.motorcycles': 8,\n",
       " 'rec.sport.baseball': 9,\n",
       " 'rec.sport.hockey': 10,\n",
       " 'sci.crypt': 11,\n",
       " 'sci.electronics': 12,\n",
       " 'sci.med': 13,\n",
       " 'sci.space': 14,\n",
       " 'soc.religion.christian': 15,\n",
       " 'talk.politics.guns': 16,\n",
       " 'talk.politics.mideast': 17,\n",
       " 'talk.politics.misc': 18,\n",
       " 'talk.religion.misc': 19}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = {}\n",
    "for index, entry in enumerate(train_data[\"target_names\"]):\n",
    "    encodings[entry] = index\n",
    "encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TX2\n",
    "\n",
    "This section shows how to put everything into the TX2 wrapper to get the dashboard widget displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tx2.wrapper import Wrapper\n",
    "from tx2.dashboard import Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Cache path found\n",
      "INFO:root:Checking for cached predictions...\n",
      "INFO:root:Running classifier...\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "INFO:root:Saving predictions...\n",
      "INFO:root:Writing to data/predictions.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached embeddings...\n",
      "INFO:root:Embedding training and testing datasets\n",
      "INFO:root:Saving embeddings...\n",
      "INFO:root:Writing to data/embedding_training.json\n",
      "INFO:root:Writing to data/embedding_testing.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached projections...\n",
      "INFO:root:Training projector...\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n",
      "INFO:root:Applying projector to test dataset...\n",
      "INFO:root:Saving projections...\n",
      "INFO:root:Writing to data/projections_training.json\n",
      "INFO:root:Writing to data/projections_testing.json\n",
      "INFO:root:Writing to data/projector.pkl.gz\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached salience maps...\n",
      "INFO:root:Computing salience maps...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e2f40794834aff8d9c2bc595a05f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "INFO:root:Saving salience maps...\n",
      "INFO:root:Writing to data/salience.pkl.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached cluster profiles...\n",
      "INFO:root:Clustering projections...\n",
      "INFO:root:Saving cluster profiles...\n",
      "INFO:root:Writing to data/clusters.json\n",
      "INFO:root:Writing to data/cluster_profiles.pkl.gz\n",
      "INFO:root:Done!\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "INFO:root:Saving cluster labels...\n",
      "INFO:root:Writing to data/cluster_labels.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Saving cluster word counts...\n",
      "INFO:root:Writing to data/cluster_words.json\n",
      "INFO:root:Writing to data/cluster_class_words.json\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "wrapper = Wrapper(\n",
    "    train_df=train_df, \n",
    "    test_df=test_df[:2000], \n",
    "    encodings=encodings, \n",
    "    input_col_name=\"text\", \n",
    "    target_col_name=\"target\", \n",
    "    classifier=model, \n",
    "    language_model=model.l1, \n",
    "    tokenizer=tokenizer,\n",
    "    overwrite=True\n",
    ")\n",
    "wrapper.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: None. Using widget instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c11ed8d3c5284891848754c45aae8294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>UMAP Embedding Graph</h3>'), HBox(children=(Output(), VBox(childâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "import matplotlib.pyplot as plt\n",
    "dash = Dashboard(wrapper, show_wordclouds=True, unfocused_point_size=500)\n",
    "dash.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To play with different UMAP and DBSCAN arguments without having to recompute the entire `prepare()` function, you can use `recompute_projections` (which will recompute both the projections and visual clusterings) or `recompute_visual_clusterings` (which will only redo the clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper.recompute_visual_clusterings(\"KMeans\", clustering_args=dict(n_clusters=18))\n",
    "# wrapper.recompute_visual_clusterings(\"OPTICS\", clustering_args=dict())\n",
    "# wrapper.recompute_projections(umap_args=dict(min_dist=.2), dbscan_args=dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test or debug the classification model/see what raw outputs the viusualizations are getting, or create your own visualization tools, you can manually call the `classify()`, `soft_classify()`, `embed()` functions, or get access to any of the cached data as seen in the bottom cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.1463279724121094,\n",
       "  -0.300228089094162,\n",
       "  -0.28051361441612244,\n",
       "  -0.6380437612533569,\n",
       "  -0.15901462733745575,\n",
       "  -0.29577451944351196,\n",
       "  1.5137823820114136,\n",
       "  2.1028590202331543,\n",
       "  1.2697218656539917,\n",
       "  -0.14646291732788086,\n",
       "  -0.29848021268844604,\n",
       "  -0.2586304545402527,\n",
       "  0.7941807508468628,\n",
       "  -0.21853026747703552,\n",
       "  -0.19897815585136414,\n",
       "  -0.5845906734466553,\n",
       "  -0.11999855935573578,\n",
       "  -0.4378066062927246,\n",
       "  -0.5633319616317749,\n",
       "  -1.1456373929977417]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.soft_classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.3971732556819916,\n",
       "  0.470696359872818,\n",
       "  1.0190491676330566,\n",
       "  -0.10928857326507568,\n",
       "  -0.8119498491287231,\n",
       "  -0.3897707760334015,\n",
       "  0.418334037065506,\n",
       "  -0.5637258291244507,\n",
       "  0.41757652163505554,\n",
       "  -2.2069485187530518,\n",
       "  -0.47119277715682983,\n",
       "  0.7209391593933105,\n",
       "  -0.2846495509147644,\n",
       "  0.6587584018707275,\n",
       "  -0.448339581489563,\n",
       "  -0.3601205348968506,\n",
       "  0.0802217498421669,\n",
       "  -0.04097452759742737,\n",
       "  0.7199097275733948,\n",
       "  -0.0020491606555879116,\n",
       "  -0.016118593513965607,\n",
       "  -0.8801823854446411,\n",
       "  0.0636066347360611,\n",
       "  -1.0504319667816162,\n",
       "  -0.17375992238521576,\n",
       "  -0.1288786083459854,\n",
       "  1.2776012420654297,\n",
       "  0.05714423954486847,\n",
       "  0.06921711564064026,\n",
       "  -0.1060103103518486,\n",
       "  -0.09861809760332108,\n",
       "  0.23843257129192352,\n",
       "  -0.4275083839893341,\n",
       "  0.22584903240203857,\n",
       "  0.3246569335460663,\n",
       "  -0.0027319565415382385,\n",
       "  0.5189067721366882,\n",
       "  0.06162279099225998,\n",
       "  -0.30574148893356323,\n",
       "  0.1315179020166397,\n",
       "  -0.6550605893135071,\n",
       "  -0.21048308908939362,\n",
       "  -0.016489243134856224,\n",
       "  0.5050926208496094,\n",
       "  -0.15789170563220978,\n",
       "  0.2856685221195221,\n",
       "  0.19260083138942719,\n",
       "  -0.4416869878768921,\n",
       "  -0.8006548881530762,\n",
       "  0.6497362852096558,\n",
       "  0.15213099122047424,\n",
       "  -0.32631006836891174,\n",
       "  -0.21038006246089935,\n",
       "  1.3097037076950073,\n",
       "  0.6144656538963318,\n",
       "  -0.23925234377384186,\n",
       "  -0.8226991891860962,\n",
       "  0.0994003415107727,\n",
       "  0.02940535359084606,\n",
       "  0.4610029458999634,\n",
       "  -1.2703593969345093,\n",
       "  -0.7858265042304993,\n",
       "  -0.3255958557128906,\n",
       "  0.9535003900527954,\n",
       "  0.19980409741401672,\n",
       "  -0.06470319628715515,\n",
       "  0.32036980986595154,\n",
       "  -0.487687349319458,\n",
       "  -0.1356150209903717,\n",
       "  -0.47437530755996704,\n",
       "  1.0333387851715088,\n",
       "  1.1664752960205078,\n",
       "  -0.2371874898672104,\n",
       "  0.5244606733322144,\n",
       "  -0.40036317706108093,\n",
       "  -0.300952285528183,\n",
       "  -0.7414681911468506,\n",
       "  -0.6529873013496399,\n",
       "  0.575927734375,\n",
       "  0.4149334132671356,\n",
       "  -0.009485656395554543,\n",
       "  -0.020869256928563118,\n",
       "  -0.5545175671577454,\n",
       "  -0.3589154779911041,\n",
       "  0.03948427736759186,\n",
       "  0.5051050782203674,\n",
       "  -0.0014985266607254744,\n",
       "  0.2559675872325897,\n",
       "  0.2284368872642517,\n",
       "  -0.17078402638435364,\n",
       "  0.03857753798365593,\n",
       "  1.000693678855896,\n",
       "  -0.5884267687797546,\n",
       "  0.09718631207942963,\n",
       "  -0.6324357986450195,\n",
       "  -0.11674275249242783,\n",
       "  -0.02872936800122261,\n",
       "  0.608772873878479,\n",
       "  5.999786853790283,\n",
       "  -0.27892354130744934,\n",
       "  0.2952556312084198,\n",
       "  -1.1952513456344604,\n",
       "  0.27550750970840454,\n",
       "  0.02610066905617714,\n",
       "  0.4021878242492676,\n",
       "  0.17251577973365784,\n",
       "  -0.2099563032388687,\n",
       "  -0.416963130235672,\n",
       "  0.44203245639801025,\n",
       "  -0.32005706429481506,\n",
       "  0.5343884825706482,\n",
       "  0.26880693435668945,\n",
       "  0.8471499085426331,\n",
       "  0.4630865454673767,\n",
       "  0.5452868938446045,\n",
       "  0.02620093896985054,\n",
       "  -0.3541737496852875,\n",
       "  -0.5940802097320557,\n",
       "  -0.35237279534339905,\n",
       "  0.22578097879886627,\n",
       "  0.30391332507133484,\n",
       "  0.5679594874382019,\n",
       "  2.1338744163513184,\n",
       "  0.06669362634420395,\n",
       "  -0.01272185891866684,\n",
       "  0.18163199722766876,\n",
       "  -0.11955016851425171,\n",
       "  0.3791167140007019,\n",
       "  0.12667939066886902,\n",
       "  -0.5628840923309326,\n",
       "  -0.7786106467247009,\n",
       "  0.35037627816200256,\n",
       "  -1.2269892692565918,\n",
       "  0.4192075729370117,\n",
       "  0.03819536417722702,\n",
       "  0.2883046865463257,\n",
       "  -0.7588227391242981,\n",
       "  0.32594382762908936,\n",
       "  -1.4836369752883911,\n",
       "  0.6350479125976562,\n",
       "  -0.662093460559845,\n",
       "  -0.35530805587768555,\n",
       "  -0.4444424510002136,\n",
       "  -0.7571282386779785,\n",
       "  -0.8862985372543335,\n",
       "  3.215628147125244,\n",
       "  0.24456781148910522,\n",
       "  -0.16832368075847626,\n",
       "  0.09385016560554504,\n",
       "  -0.9575228095054626,\n",
       "  0.1993822306394577,\n",
       "  -0.46589457988739014,\n",
       "  -0.07053467631340027,\n",
       "  -0.5286352038383484,\n",
       "  0.3116041123867035,\n",
       "  -0.9103327989578247,\n",
       "  0.3413033187389374,\n",
       "  -0.03243489935994148,\n",
       "  0.1263151615858078,\n",
       "  0.2765403985977173,\n",
       "  -0.8224019408226013,\n",
       "  -0.09857688844203949,\n",
       "  -0.4187321960926056,\n",
       "  0.4636957347393036,\n",
       "  0.8235708475112915,\n",
       "  0.1843155324459076,\n",
       "  0.21566569805145264,\n",
       "  -0.7555273771286011,\n",
       "  -0.10975497961044312,\n",
       "  0.22652122378349304,\n",
       "  -0.029885804280638695,\n",
       "  0.09580004215240479,\n",
       "  -2.196744680404663,\n",
       "  0.5964869260787964,\n",
       "  -0.7330222725868225,\n",
       "  0.34116148948669434,\n",
       "  0.5229032039642334,\n",
       "  0.9602433443069458,\n",
       "  -0.47861814498901367,\n",
       "  -0.7748318314552307,\n",
       "  -0.6384207010269165,\n",
       "  0.1097271516919136,\n",
       "  -0.33549556136131287,\n",
       "  -0.964721143245697,\n",
       "  0.4686262309551239,\n",
       "  -0.6035564541816711,\n",
       "  -0.14246870577335358,\n",
       "  -0.6942863464355469,\n",
       "  0.450820654630661,\n",
       "  -1.3916305303573608,\n",
       "  0.060674622654914856,\n",
       "  -0.8739039301872253,\n",
       "  0.18665443360805511,\n",
       "  -0.23280780017375946,\n",
       "  1.1200075149536133,\n",
       "  -0.15878744423389435,\n",
       "  0.43971097469329834,\n",
       "  -0.6927487254142761,\n",
       "  -0.8977341055870056,\n",
       "  0.7799540758132935,\n",
       "  0.037204768508672714,\n",
       "  0.724344789981842,\n",
       "  -1.2613046169281006,\n",
       "  -0.016295861452817917,\n",
       "  0.8217275142669678,\n",
       "  -0.2684018909931183,\n",
       "  0.06307751685380936,\n",
       "  -0.34718331694602966,\n",
       "  0.7797661423683167,\n",
       "  -0.5119717717170715,\n",
       "  -0.5483874082565308,\n",
       "  -0.16564081609249115,\n",
       "  0.6537145376205444,\n",
       "  0.7665350437164307,\n",
       "  -0.20012064278125763,\n",
       "  -0.0876508578658104,\n",
       "  0.17695671319961548,\n",
       "  0.813839316368103,\n",
       "  -0.06997378915548325,\n",
       "  0.09416967630386353,\n",
       "  -1.0908793210983276,\n",
       "  0.6295972466468811,\n",
       "  -0.4537830352783203,\n",
       "  -1.2478724718093872,\n",
       "  0.294079065322876,\n",
       "  0.1373768150806427,\n",
       "  0.6788991689682007,\n",
       "  1.125543475151062,\n",
       "  0.5951461791992188,\n",
       "  -0.3998410701751709,\n",
       "  0.6640826463699341,\n",
       "  0.7281569838523865,\n",
       "  -0.09773435443639755,\n",
       "  0.418488472700119,\n",
       "  -0.041841838508844376,\n",
       "  -0.001569323823787272,\n",
       "  -0.823093831539154,\n",
       "  1.0453484058380127,\n",
       "  -0.6917029619216919,\n",
       "  -0.23138774931430817,\n",
       "  0.21660153567790985,\n",
       "  -0.7196123600006104,\n",
       "  -0.007752089761197567,\n",
       "  0.7061916589736938,\n",
       "  -0.20404723286628723,\n",
       "  -0.670464813709259,\n",
       "  0.6532381772994995,\n",
       "  0.4612659513950348,\n",
       "  0.7335848808288574,\n",
       "  -0.040323544293642044,\n",
       "  0.6264340877532959,\n",
       "  -0.19557522237300873,\n",
       "  -0.21875619888305664,\n",
       "  0.2310710996389389,\n",
       "  0.4417020082473755,\n",
       "  0.23381513357162476,\n",
       "  -0.5796152949333191,\n",
       "  -1.4812504053115845,\n",
       "  1.5552608966827393,\n",
       "  -0.33983534574508667,\n",
       "  0.2003147155046463,\n",
       "  -3.3989036083221436,\n",
       "  0.5582988262176514,\n",
       "  -0.047859907150268555,\n",
       "  -0.6530341506004333,\n",
       "  -0.1004737839102745,\n",
       "  0.36806055903434753,\n",
       "  0.5192065238952637,\n",
       "  0.28488972783088684,\n",
       "  -0.305002897977829,\n",
       "  0.5367359519004822,\n",
       "  0.1306954026222229,\n",
       "  -0.6584605574607849,\n",
       "  0.490054726600647,\n",
       "  0.5073525905609131,\n",
       "  1.5644162893295288,\n",
       "  0.10391681641340256,\n",
       "  -0.6013675928115845,\n",
       "  0.7139663100242615,\n",
       "  -0.0927668884396553,\n",
       "  -0.38929295539855957,\n",
       "  0.5143747925758362,\n",
       "  -1.4104162454605103,\n",
       "  0.8658251166343689,\n",
       "  -1.0619828701019287,\n",
       "  0.012368571944534779,\n",
       "  1.1857346296310425,\n",
       "  -0.5192322134971619,\n",
       "  -0.15331174433231354,\n",
       "  4.556219100952148,\n",
       "  0.990142285823822,\n",
       "  -0.24606625735759735,\n",
       "  -0.7099028825759888,\n",
       "  -0.6939857006072998,\n",
       "  -0.4238920211791992,\n",
       "  -0.16301463544368744,\n",
       "  -0.4943463206291199,\n",
       "  -0.9381731152534485,\n",
       "  -0.30323609709739685,\n",
       "  -0.06209513917565346,\n",
       "  0.518317461013794,\n",
       "  -0.14271791279315948,\n",
       "  -1.3343861103057861,\n",
       "  -0.10673241317272186,\n",
       "  -0.19176755845546722,\n",
       "  0.014479103498160839,\n",
       "  0.2139185070991516,\n",
       "  -0.33065974712371826,\n",
       "  -0.9095369577407837,\n",
       "  -1.3281683921813965,\n",
       "  -0.7764763832092285,\n",
       "  -0.1832127422094345,\n",
       "  -1.022486686706543,\n",
       "  0.31240129470825195,\n",
       "  -0.3609822690486908,\n",
       "  -1.1536760330200195,\n",
       "  -0.41820845007896423,\n",
       "  0.4483032524585724,\n",
       "  -0.9597943425178528,\n",
       "  -0.7328001260757446,\n",
       "  0.9726641774177551,\n",
       "  0.14579352736473083,\n",
       "  -0.2508618235588074,\n",
       "  0.5333257913589478,\n",
       "  -0.3259609043598175,\n",
       "  -0.2148035317659378,\n",
       "  0.8366449475288391,\n",
       "  -0.37897613644599915,\n",
       "  -0.9034290313720703,\n",
       "  0.3474297523498535,\n",
       "  -0.8896059393882751,\n",
       "  -0.5736075043678284,\n",
       "  -1.3184659481048584,\n",
       "  -0.07831631600856781,\n",
       "  -0.36355268955230713,\n",
       "  -0.20111235976219177,\n",
       "  -0.1914333701133728,\n",
       "  0.33169835805892944,\n",
       "  0.19670873880386353,\n",
       "  -0.41208574175834656,\n",
       "  0.8052976131439209,\n",
       "  0.8159383535385132,\n",
       "  -0.23577097058296204,\n",
       "  -0.5366538166999817,\n",
       "  -0.007553423289209604,\n",
       "  -0.18502511084079742,\n",
       "  -0.07163917273283005,\n",
       "  -0.5086471438407898,\n",
       "  0.9690049886703491,\n",
       "  0.01814972050487995,\n",
       "  0.6891355514526367,\n",
       "  -0.7513012290000916,\n",
       "  0.2963300049304962,\n",
       "  0.6940969228744507,\n",
       "  0.19943323731422424,\n",
       "  -0.5021061897277832,\n",
       "  -0.33885201811790466,\n",
       "  -0.22896800935268402,\n",
       "  0.11054869741201401,\n",
       "  -0.14976470172405243,\n",
       "  -0.2352144718170166,\n",
       "  -1.6294463872909546,\n",
       "  -0.09755533933639526,\n",
       "  0.3261662423610687,\n",
       "  0.49295926094055176,\n",
       "  -0.1666443943977356,\n",
       "  0.38573214411735535,\n",
       "  -0.05171434208750725,\n",
       "  0.35135963559150696,\n",
       "  0.6812463402748108,\n",
       "  1.1328548192977905,\n",
       "  1.0441099405288696,\n",
       "  -0.9232224225997925,\n",
       "  -0.0883190706372261,\n",
       "  0.6297357678413391,\n",
       "  0.06565497815608978,\n",
       "  0.23655958473682404,\n",
       "  0.779731810092926,\n",
       "  0.3546878397464752,\n",
       "  -0.04568107798695564,\n",
       "  -0.16754402220249176,\n",
       "  1.2570509910583496,\n",
       "  1.4059734344482422,\n",
       "  -0.10266635566949844,\n",
       "  0.10822535306215286,\n",
       "  -0.36496564745903015,\n",
       "  0.7647379040718079,\n",
       "  -0.07954777777194977,\n",
       "  -0.777786135673523,\n",
       "  0.1905612051486969,\n",
       "  0.5570499300956726,\n",
       "  -0.20796748995780945,\n",
       "  0.6961782574653625,\n",
       "  -0.8489677309989929,\n",
       "  0.03249737620353699,\n",
       "  0.2759780287742615,\n",
       "  -0.5976656675338745,\n",
       "  0.1762063056230545,\n",
       "  0.19761201739311218,\n",
       "  0.008663218468427658,\n",
       "  -0.3909410238265991,\n",
       "  -0.5905856490135193,\n",
       "  -0.055107008665800095,\n",
       "  -0.7291582822799683,\n",
       "  0.38162311911582947,\n",
       "  0.846189558506012,\n",
       "  0.011357286013662815,\n",
       "  0.46947821974754333,\n",
       "  -0.9987013936042786,\n",
       "  -0.09743867069482803,\n",
       "  0.26956090331077576,\n",
       "  -0.17458707094192505,\n",
       "  0.8510913848876953,\n",
       "  -0.16728228330612183,\n",
       "  0.49308714270591736,\n",
       "  0.1234985888004303,\n",
       "  0.8270443081855774,\n",
       "  0.09864086657762527,\n",
       "  -0.37950751185417175,\n",
       "  0.5513362288475037,\n",
       "  -0.4654078483581543,\n",
       "  0.33209219574928284,\n",
       "  0.3653344213962555,\n",
       "  -1.0633995532989502,\n",
       "  -0.1532888114452362,\n",
       "  -0.5717963576316833,\n",
       "  -0.09315291047096252,\n",
       "  -0.17211024463176727,\n",
       "  0.35484471917152405,\n",
       "  0.6911989450454712,\n",
       "  -0.5278744101524353,\n",
       "  0.6858874559402466,\n",
       "  0.5012654662132263,\n",
       "  0.39563095569610596,\n",
       "  -0.7225074172019958,\n",
       "  -0.017547283321619034,\n",
       "  1.1343913078308105,\n",
       "  -0.47271716594696045,\n",
       "  0.111111581325531,\n",
       "  4.868244171142578,\n",
       "  -0.13971970975399017,\n",
       "  -0.5627071857452393,\n",
       "  0.17109400033950806,\n",
       "  -0.11048872768878937,\n",
       "  -0.37305787205696106,\n",
       "  0.8091045618057251,\n",
       "  -0.3456593453884125,\n",
       "  0.8898681402206421,\n",
       "  0.17297261953353882,\n",
       "  -1.0873355865478516,\n",
       "  -0.2468375414609909,\n",
       "  0.2099384069442749,\n",
       "  0.4222891926765442,\n",
       "  -0.0005662949988618493,\n",
       "  0.41386878490448,\n",
       "  0.25230687856674194,\n",
       "  0.21968530118465424,\n",
       "  -0.059094592928886414,\n",
       "  -0.49472054839134216,\n",
       "  -0.07464473694562912,\n",
       "  -0.5650796890258789,\n",
       "  0.6628023982048035,\n",
       "  0.6752013564109802,\n",
       "  -0.077595554292202,\n",
       "  0.4699566066265106,\n",
       "  0.5195345282554626,\n",
       "  -0.25721436738967896,\n",
       "  -0.14263954758644104,\n",
       "  -0.17233015596866608,\n",
       "  -1.312987208366394,\n",
       "  -0.04942820593714714,\n",
       "  -0.9656829237937927,\n",
       "  0.2641325294971466,\n",
       "  0.2923591136932373,\n",
       "  -1.1503931283950806,\n",
       "  -0.1817985624074936,\n",
       "  -0.06835669279098511,\n",
       "  0.14009609818458557,\n",
       "  -0.19126078486442566,\n",
       "  0.4978142976760864,\n",
       "  -0.317483514547348,\n",
       "  0.28765901923179626,\n",
       "  -0.38195520639419556,\n",
       "  -0.34265515208244324,\n",
       "  -0.5644235014915466,\n",
       "  0.20541317760944366,\n",
       "  0.15982672572135925,\n",
       "  -0.9061552882194519,\n",
       "  0.08862221986055374,\n",
       "  0.23036034405231476,\n",
       "  0.006552771665155888,\n",
       "  -0.10772236436605453,\n",
       "  -0.7779274582862854,\n",
       "  0.5559783577919006,\n",
       "  0.06401374936103821,\n",
       "  -1.1714115142822266,\n",
       "  -0.10107716172933578,\n",
       "  -0.4967714846134186,\n",
       "  -0.6773089170455933,\n",
       "  0.033184345811605453,\n",
       "  -0.7879353761672974,\n",
       "  -0.3715662658214569,\n",
       "  0.5320107936859131,\n",
       "  0.3047660291194916,\n",
       "  -0.17260701954364777,\n",
       "  0.3643490970134735,\n",
       "  -0.12182267010211945,\n",
       "  -0.911752462387085,\n",
       "  -1.2075501680374146,\n",
       "  -0.6710047125816345,\n",
       "  0.8283918499946594,\n",
       "  -0.48735713958740234,\n",
       "  0.3639015555381775,\n",
       "  0.6532110571861267,\n",
       "  -0.4543096721172333,\n",
       "  -0.1772880256175995,\n",
       "  0.6310343146324158,\n",
       "  -0.02551097795367241,\n",
       "  -0.8647618293762207,\n",
       "  0.25337767601013184,\n",
       "  -0.36703065037727356,\n",
       "  0.6402071714401245,\n",
       "  -0.5112367868423462,\n",
       "  0.40968719124794006,\n",
       "  -0.19720880687236786,\n",
       "  0.28353333473205566,\n",
       "  0.11380470544099808,\n",
       "  0.255097895860672,\n",
       "  0.043786246329545975,\n",
       "  0.435888409614563,\n",
       "  0.17782263457775116,\n",
       "  0.5192757844924927,\n",
       "  -1.074534296989441,\n",
       "  1.008607029914856,\n",
       "  0.20192353427410126,\n",
       "  -1.1301355361938477,\n",
       "  0.04893862083554268,\n",
       "  0.06582291424274445,\n",
       "  0.2923429310321808,\n",
       "  -0.2593555450439453,\n",
       "  -0.024990150704979897,\n",
       "  -0.1729125827550888,\n",
       "  0.32293617725372314,\n",
       "  0.40720129013061523,\n",
       "  -0.2945764660835266,\n",
       "  -0.633236289024353,\n",
       "  0.2672315239906311,\n",
       "  0.17440691590309143,\n",
       "  0.23276610672473907,\n",
       "  -0.1222338154911995,\n",
       "  0.028300009667873383,\n",
       "  0.6097416877746582,\n",
       "  -0.3508535921573639,\n",
       "  0.19646865129470825,\n",
       "  0.4545448124408722,\n",
       "  1.4355937242507935,\n",
       "  -0.27688631415367126,\n",
       "  -2.368849277496338,\n",
       "  -0.3716489374637604,\n",
       "  0.8662447333335876,\n",
       "  -0.21407398581504822,\n",
       "  -0.30432629585266113,\n",
       "  -0.808773398399353,\n",
       "  0.5078791379928589,\n",
       "  -0.18090255558490753,\n",
       "  -0.23573125898838043,\n",
       "  0.31918179988861084,\n",
       "  -0.14455801248550415,\n",
       "  -0.5696445107460022,\n",
       "  -2.696706771850586,\n",
       "  1.024096131324768,\n",
       "  0.25732195377349854,\n",
       "  0.09269440919160843,\n",
       "  -0.20567835867404938,\n",
       "  -0.9619770646095276,\n",
       "  -0.9833052754402161,\n",
       "  -0.023941945284605026,\n",
       "  0.5012674927711487,\n",
       "  -0.35414034128189087,\n",
       "  -0.5794808864593506,\n",
       "  0.20038296282291412,\n",
       "  1.0533628463745117,\n",
       "  0.5319275259971619,\n",
       "  0.12186319380998611,\n",
       "  -0.4604150950908661,\n",
       "  -0.17177803814411163,\n",
       "  -0.7655747532844543,\n",
       "  -1.174493432044983,\n",
       "  -0.48665884137153625,\n",
       "  -0.023644156754016876,\n",
       "  -0.6329532861709595,\n",
       "  -0.2120586782693863,\n",
       "  -1.1213172674179077,\n",
       "  0.5827136635780334,\n",
       "  0.3992581367492676,\n",
       "  0.29144126176834106,\n",
       "  -0.217565655708313,\n",
       "  -0.005970419384539127,\n",
       "  -0.25766733288764954,\n",
       "  0.30963757634162903,\n",
       "  -0.15848210453987122,\n",
       "  -0.7986189126968384,\n",
       "  -1.314363956451416,\n",
       "  0.831502377986908,\n",
       "  -1.3639310598373413,\n",
       "  0.49112504720687866,\n",
       "  -0.2798286974430084,\n",
       "  1.0539456605911255,\n",
       "  -0.6095278263092041,\n",
       "  -0.30807313323020935,\n",
       "  -0.19091558456420898,\n",
       "  0.5788787603378296,\n",
       "  -0.45961061120033264,\n",
       "  0.5131098031997681,\n",
       "  0.08542437106370926,\n",
       "  0.2747405171394348,\n",
       "  -0.6174697279930115,\n",
       "  -0.7410240769386292,\n",
       "  -0.3363068401813507,\n",
       "  0.08262178301811218,\n",
       "  0.2563265562057495,\n",
       "  -0.9666109681129456,\n",
       "  0.28684002161026,\n",
       "  -0.2203558385372162,\n",
       "  -0.004392454866319895,\n",
       "  -0.014517661184072495,\n",
       "  -0.012074888683855534,\n",
       "  -0.40551769733428955,\n",
       "  0.012710844166576862,\n",
       "  -0.54047691822052,\n",
       "  0.01626221276819706,\n",
       "  -0.22761903703212738,\n",
       "  -0.8271237015724182,\n",
       "  -0.19688962399959564,\n",
       "  -0.4197487235069275,\n",
       "  0.228981152176857,\n",
       "  -0.3494047522544861,\n",
       "  -0.04467908293008804,\n",
       "  -0.0945054441690445,\n",
       "  1.199384331703186,\n",
       "  1.4658315181732178,\n",
       "  0.05080882087349892,\n",
       "  0.41904619336128235,\n",
       "  -1.0970734357833862,\n",
       "  0.635847270488739,\n",
       "  0.8842530250549316,\n",
       "  0.583173394203186,\n",
       "  -0.7960509657859802,\n",
       "  -0.45560094714164734,\n",
       "  -0.5630056858062744,\n",
       "  0.6319105625152588,\n",
       "  0.20913121104240417,\n",
       "  0.8819153904914856,\n",
       "  -0.7284677624702454,\n",
       "  0.41213780641555786,\n",
       "  0.08113426715135574,\n",
       "  0.29254719614982605,\n",
       "  -0.3970434367656708,\n",
       "  0.46505171060562134,\n",
       "  -0.5850357413291931,\n",
       "  0.508662223815918,\n",
       "  0.4746013283729553,\n",
       "  0.12526391446590424,\n",
       "  2.5555810928344727,\n",
       "  0.14097274839878082,\n",
       "  -0.5578893423080444,\n",
       "  0.340077668428421,\n",
       "  0.9179335236549377,\n",
       "  0.16507993638515472,\n",
       "  -0.5640605688095093,\n",
       "  0.5459606647491455,\n",
       "  0.5268398523330688,\n",
       "  -0.45171770453453064,\n",
       "  -0.3590623736381531,\n",
       "  -0.22513112425804138,\n",
       "  0.6122772097587585,\n",
       "  0.22925208508968353,\n",
       "  -0.4040921926498413,\n",
       "  0.14973606169223785,\n",
       "  -0.5142415761947632,\n",
       "  -0.005151640623807907,\n",
       "  1.086482048034668,\n",
       "  0.7488366961479187,\n",
       "  -0.014596913009881973,\n",
       "  -1.0310355424880981,\n",
       "  -0.2484271377325058,\n",
       "  -1.188968539237976,\n",
       "  0.24671778082847595,\n",
       "  -0.5373097658157349,\n",
       "  -0.23408155143260956,\n",
       "  0.023229246959090233,\n",
       "  0.7787467837333679,\n",
       "  -0.7677805423736572,\n",
       "  -0.19308263063430786,\n",
       "  0.19051721692085266,\n",
       "  0.3070622980594635,\n",
       "  2.2860898971557617,\n",
       "  -0.20098716020584106,\n",
       "  1.0700392723083496,\n",
       "  0.7643972039222717,\n",
       "  -0.5843115448951721,\n",
       "  0.2711540460586548,\n",
       "  0.01425707247108221,\n",
       "  -0.08587425947189331,\n",
       "  -0.34625014662742615,\n",
       "  -0.6953383684158325,\n",
       "  0.17756244540214539,\n",
       "  -0.7736137509346008,\n",
       "  -0.6527440547943115,\n",
       "  -1.5950125455856323,\n",
       "  -0.3874695897102356,\n",
       "  0.07154251635074615,\n",
       "  -0.5577548742294312,\n",
       "  1.1241533756256104,\n",
       "  0.31331852078437805,\n",
       "  0.2279359996318817,\n",
       "  1.2333343029022217,\n",
       "  0.8203938007354736,\n",
       "  1.0880849361419678,\n",
       "  0.05779898539185524,\n",
       "  -0.1258372962474823,\n",
       "  -1.1326446533203125,\n",
       "  -0.08584441989660263,\n",
       "  -0.6998984813690186,\n",
       "  0.09916241466999054,\n",
       "  -0.11500237137079239,\n",
       "  1.2789456844329834,\n",
       "  0.317303329706192,\n",
       "  -0.39280736446380615,\n",
       "  0.0012887553311884403,\n",
       "  -0.3585453927516937,\n",
       "  -0.15322881937026978,\n",
       "  -1.4113699197769165,\n",
       "  0.26937761902809143,\n",
       "  -0.4072323143482208,\n",
       "  -2.5227017402648926,\n",
       "  -0.9450284838676453,\n",
       "  -0.3997900187969208,\n",
       "  0.39018145203590393,\n",
       "  -0.27372369170188904,\n",
       "  0.2552291750907898,\n",
       "  0.3812241852283478,\n",
       "  -0.59743332862854,\n",
       "  0.01626066118478775,\n",
       "  0.216794952750206,\n",
       "  0.20154529809951782,\n",
       "  1.7274549007415771,\n",
       "  0.117507703602314,\n",
       "  -0.48137927055358887,\n",
       "  -0.9151120185852051,\n",
       "  -0.40103405714035034,\n",
       "  -0.6230593323707581,\n",
       "  -0.05733172222971916,\n",
       "  -0.08354838937520981,\n",
       "  0.6035528779029846,\n",
       "  -0.13091400265693665,\n",
       "  1.2049602270126343,\n",
       "  0.13966193795204163,\n",
       "  0.12139329314231873,\n",
       "  0.31019172072410583,\n",
       "  0.19222241640090942,\n",
       "  0.06472516059875488,\n",
       "  -0.15096928179264069,\n",
       "  -0.7447950839996338,\n",
       "  0.5694342255592346,\n",
       "  -0.804785430431366,\n",
       "  0.49406924843788147,\n",
       "  0.4241677224636078]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.embed([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cached data:\n",
    "# wrapper.embeddings_training\n",
    "# wrapper.embeddings_testing\n",
    "# wrapper.projector\n",
    "# wrapper.projections_training\n",
    "# wrapper.projections_testing\n",
    "# wrapper.salience_maps\n",
    "# wrapper.clusters\n",
    "# wrapper.cluster_profiles\n",
    "# wrapper.cluster_words_freqs\n",
    "# wrapper.cluster_class_word_sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1 - Default Approach\n",
    "\n",
    "This notebook demonstrates how to use the TX2 dashboard with a sequence classification transformer using the default approach as described in the \"Basic Usage\" docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -q ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We enable logging to view the output from `wrapper.prepare()` further down in the notebook. (It's a long running function, and logs which step it's on.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "# import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example notebook, we use the 20 newsgroups dataset, which can be downloaded through sklearn via below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "train_data = fetch_20newsgroups(subset='train')\n",
    "test_data = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Defined below is a simple sequence classification model with a variable for the language model itself `l1`. Since it is a BERT model, we take the sequence embedding from the `[CLS]` token (via `output_1[0][:, 0, :])`) and pipe that into the linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "        self.l2 = torch.nn.Linear(768, 20)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        output_1= self.l1(ids, mask)\n",
    "        output = self.l2(output_1[0][:, 0, :]) # use just the [CLS] output embedding\n",
    "        return output\n",
    "    \n",
    "model = BERTClass()\n",
    "model.to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some simplistic data cleaning, and putting all data into dataframes for the wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text[text.index(\"\\n\\n\")+2:]\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"    \", \" \")\n",
    "    text = text.replace(\"   \", \" \")\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_rows = []\n",
    "for i in range(len(train_data[\"data\"])):\n",
    "    row = {}\n",
    "    row[\"text\"] = clean_text(train_data[\"data\"][i])\n",
    "    row[\"target\"] = train_data['target'][i]\n",
    "    if row[\"text\"] == \"\" or row[\"text\"] == \" \": continue\n",
    "    train_rows.append(row)\n",
    "train_df = pd.DataFrame(train_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rows = []\n",
    "for i in range(len(test_data[\"data\"])):\n",
    "    row = {}\n",
    "    row[\"text\"] = clean_text(test_data[\"data\"][i])\n",
    "    row[\"target\"] = test_data['target'][i]\n",
    "    if row[\"text\"] == \"\" or row[\"text\"] == \" \": continue\n",
    "    test_rows.append(row)\n",
    "test_df = pd.DataFrame(test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "This section minimally trains the classification and language model - nothing fancy here, just to give the dashboard demo something to work with. Most of this is similar to the huggingface tutorial notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11296\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "class EncodedSet(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        print(self.len)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.data.text[index])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.target[index], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "train_set = EncodedSet(train_df, tokenizer, 256)\n",
    "test_set = EncodedSet(test_df[:1000], tokenizer, 256)\n",
    "\n",
    "train_params = {'batch_size': 16,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': 2,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "# put everything into data loaders\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "    loss_history = []\n",
    "    for _,data in tqdm(enumerate(train_loader, 0), total=len(train_loader), desc=f\"Epoch {epoch}\"):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask).squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, targets)\n",
    "        if _%100==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         torch.cuda.empty_cache()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcbfb3897034de8890a18a5f45c34a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/adapd_nlp_hf/lib/python3.8/site-packages/transformers-4.1.1-py3.8.egg/transformers/tokenization_utils_base.py:2173: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  3.0427584648132324\n",
      "Epoch: 0, Loss:  1.9246082305908203\n",
      "Epoch: 0, Loss:  1.3301795721054077\n",
      "Epoch: 0, Loss:  0.6518872976303101\n",
      "Epoch: 0, Loss:  0.8348802924156189\n",
      "Epoch: 0, Loss:  0.7776210308074951\n",
      "Epoch: 0, Loss:  0.3987298011779785\n",
      "Epoch: 0, Loss:  0.27758270502090454\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(1):\n",
    "    losses.extend(train(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapper uses an `encodings` dictionary for various labels/visualizations, and can be set up with something similar to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism': 0,\n",
       " 'comp.graphics': 1,\n",
       " 'comp.os.ms-windows.misc': 2,\n",
       " 'comp.sys.ibm.pc.hardware': 3,\n",
       " 'comp.sys.mac.hardware': 4,\n",
       " 'comp.windows.x': 5,\n",
       " 'misc.forsale': 6,\n",
       " 'rec.autos': 7,\n",
       " 'rec.motorcycles': 8,\n",
       " 'rec.sport.baseball': 9,\n",
       " 'rec.sport.hockey': 10,\n",
       " 'sci.crypt': 11,\n",
       " 'sci.electronics': 12,\n",
       " 'sci.med': 13,\n",
       " 'sci.space': 14,\n",
       " 'soc.religion.christian': 15,\n",
       " 'talk.politics.guns': 16,\n",
       " 'talk.politics.mideast': 17,\n",
       " 'talk.politics.misc': 18,\n",
       " 'talk.religion.misc': 19}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = {}\n",
    "for index, entry in enumerate(train_data[\"target_names\"]):\n",
    "    encodings[entry] = index\n",
    "encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TX2\n",
    "\n",
    "This section shows how to put everything into the TX2 wrapper to get the dashboard widget displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tx2.wrapper import Wrapper\n",
    "from tx2.dashboard import Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Checking for cached predictions...\n",
      "INFO:root:cached version 'data/predictions.json' found\n",
      "INFO:root:Checking for cached embeddings...\n",
      "INFO:root:cached version 'data/embedding_training.json' found\n",
      "INFO:root:cached version 'data/embedding_testing.json' found\n",
      "INFO:root:Checking for cached projections...\n",
      "INFO:root:cached version 'data/projections_training.json' found\n",
      "INFO:root:cached version 'data/projections_testing.json' found\n",
      "INFO:root:cached version 'data/projector.pkl.gz' found\n",
      "INFO:root:Checking for cached salience maps...\n",
      "INFO:root:cached version 'data/salience.pkl.gz' found\n",
      "INFO:root:Checking for cached cluster profiles...\n",
      "INFO:root:cached version 'data/cluster_profiles.pkl.gz' found\n",
      "INFO:root:cached version 'data/clusters.json' found\n",
      "INFO:root:cached version 'data/cluster_labels.json' found\n",
      "INFO:root:cached version 'data/cluster_words.json' found\n",
      "INFO:root:cached version 'data/cluster_class_words.json' found\n"
     ]
    }
   ],
   "source": [
    "wrapper = Wrapper(\n",
    "    train_df=train_df, \n",
    "    test_df=test_df[:2000], \n",
    "    encodings=encodings, \n",
    "    input_col_name=\"text\", \n",
    "    target_col_name=\"target\", \n",
    "    classifier=model, \n",
    "    language_model=model.l1, \n",
    "    tokenizer=tokenizer,\n",
    "    overwrite=False\n",
    ")\n",
    "wrapper.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf3034f17e94f3498179799a4e68a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>UMAP Embedding Graph</h3>'), HBox(children=(Output(), VBox(child…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/adapd_nlp_hf/lib/python3.8/site-packages/transformers-4.1.1-py3.8.egg/transformers/tokenization_utils_base.py:2173: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "dash = Dashboard(wrapper)\n",
    "dash.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To play with different UMAP and DBSCAN arguments without having to recompute the entire `prepare()` function, you can use `recompute_projections` (which will recompute both the projections and visual clusterings) or `recompute_visual_clusterings` (which will only redo the clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper.recompute_visual_clusterings(dbscan_args=dict())\n",
    "# wrapper.recompute_projections(umap_args=dict(min_dist=.2), dbscan_args=dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test or debug the classification model/see what raw outputs the viusualizations are getting, or create your own visualization tools, you can manually call the `classify()`, `soft_classify()`, `embed()` functions, or get access to any of the cached data as seen in the bottom cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.9905167818069458,\n",
       "  0.02280207723379135,\n",
       "  -0.7104247808456421,\n",
       "  -0.1466187685728073,\n",
       "  0.014081034809350967,\n",
       "  -0.44134095311164856,\n",
       "  1.3942747116088867,\n",
       "  2.6510210037231445,\n",
       "  2.26328444480896,\n",
       "  -0.7248047590255737,\n",
       "  -0.18305812776088715,\n",
       "  -1.2000950574874878,\n",
       "  0.41281259059906006,\n",
       "  0.07312041521072388,\n",
       "  0.10818176716566086,\n",
       "  -0.4958801567554474,\n",
       "  -0.7442573308944702,\n",
       "  -0.7798997759819031,\n",
       "  -1.0418503284454346,\n",
       "  -0.6585859060287476]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.soft_classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.24071310460567474,\n",
       "  -0.17693574726581573,\n",
       "  1.1926298141479492,\n",
       "  -0.21286188066005707,\n",
       "  -0.5541257858276367,\n",
       "  -0.11262716352939606,\n",
       "  0.380913108587265,\n",
       "  -0.8688269257545471,\n",
       "  0.6813204884529114,\n",
       "  -1.372365951538086,\n",
       "  0.06777114421129227,\n",
       "  0.5549997687339783,\n",
       "  0.722969114780426,\n",
       "  0.8163159489631653,\n",
       "  -0.46859559416770935,\n",
       "  -0.04362483695149422,\n",
       "  0.38890770077705383,\n",
       "  -0.8300358057022095,\n",
       "  1.0483708381652832,\n",
       "  0.7251316905021667,\n",
       "  0.9786590337753296,\n",
       "  -0.7416961193084717,\n",
       "  0.25983184576034546,\n",
       "  -0.7327815890312195,\n",
       "  -1.0317604541778564,\n",
       "  -0.2332402616739273,\n",
       "  0.09239533543586731,\n",
       "  0.6674163937568665,\n",
       "  0.9412500262260437,\n",
       "  -1.6647350788116455,\n",
       "  -0.301195353269577,\n",
       "  0.284109503030777,\n",
       "  0.3736993670463562,\n",
       "  1.1517614126205444,\n",
       "  0.22863119840621948,\n",
       "  -0.08315934985876083,\n",
       "  0.5433588027954102,\n",
       "  0.3460302948951721,\n",
       "  0.1866254210472107,\n",
       "  1.1284598112106323,\n",
       "  0.0030066806357353926,\n",
       "  -0.42831340432167053,\n",
       "  -0.5717208385467529,\n",
       "  -0.3800235688686371,\n",
       "  -0.8324670195579529,\n",
       "  0.02415243536233902,\n",
       "  -0.10801895707845688,\n",
       "  -0.0034215489868074656,\n",
       "  -1.257839560508728,\n",
       "  1.2086172103881836,\n",
       "  0.4446154534816742,\n",
       "  0.026766866445541382,\n",
       "  -0.5389540195465088,\n",
       "  1.3228793144226074,\n",
       "  -0.06398705393075943,\n",
       "  -1.0364104509353638,\n",
       "  -0.44259408116340637,\n",
       "  0.6313008069992065,\n",
       "  -0.3247602581977844,\n",
       "  0.3689504861831665,\n",
       "  -1.4333873987197876,\n",
       "  -0.5078980326652527,\n",
       "  -0.02743631973862648,\n",
       "  0.6096314787864685,\n",
       "  0.060526661574840546,\n",
       "  -0.30912086367607117,\n",
       "  0.5494920611381531,\n",
       "  -0.804806649684906,\n",
       "  0.21993157267570496,\n",
       "  -0.6379792094230652,\n",
       "  0.16529615223407745,\n",
       "  1.0268046855926514,\n",
       "  0.26382115483283997,\n",
       "  -0.03157562017440796,\n",
       "  0.6514278650283813,\n",
       "  -0.344282329082489,\n",
       "  -1.4787940979003906,\n",
       "  0.43083685636520386,\n",
       "  -0.39929690957069397,\n",
       "  0.8108477592468262,\n",
       "  -0.04035287722945213,\n",
       "  0.014017857611179352,\n",
       "  -0.7480288743972778,\n",
       "  0.14831705391407013,\n",
       "  -0.7801045179367065,\n",
       "  0.098896823823452,\n",
       "  1.084190845489502,\n",
       "  0.45742523670196533,\n",
       "  -0.5115889310836792,\n",
       "  0.129625141620636,\n",
       "  -0.009519253857433796,\n",
       "  0.9650083184242249,\n",
       "  -0.9642959237098694,\n",
       "  0.792474627494812,\n",
       "  0.39290037751197815,\n",
       "  -1.3323898315429688,\n",
       "  0.5132454037666321,\n",
       "  -0.00567831052467227,\n",
       "  3.3308000564575195,\n",
       "  -0.39353805780410767,\n",
       "  0.2471420019865036,\n",
       "  -0.8070154190063477,\n",
       "  0.11241370439529419,\n",
       "  -0.2221939116716385,\n",
       "  0.8121912479400635,\n",
       "  -0.09093667566776276,\n",
       "  -0.2240680754184723,\n",
       "  0.10506956279277802,\n",
       "  0.4975069761276245,\n",
       "  0.28200170397758484,\n",
       "  1.3157371282577515,\n",
       "  0.0100506991147995,\n",
       "  2.080609083175659,\n",
       "  0.00968933291733265,\n",
       "  0.5501589179039001,\n",
       "  -0.46085789799690247,\n",
       "  -0.7316078543663025,\n",
       "  0.38876378536224365,\n",
       "  -0.3022621273994446,\n",
       "  0.5826194286346436,\n",
       "  0.47986966371536255,\n",
       "  0.6451440453529358,\n",
       "  1.5574238300323486,\n",
       "  -0.25775226950645447,\n",
       "  -0.09250424057245255,\n",
       "  0.0021645554807037115,\n",
       "  0.4999306797981262,\n",
       "  0.6187347173690796,\n",
       "  0.5378291010856628,\n",
       "  -0.1773572713136673,\n",
       "  -1.435908555984497,\n",
       "  -0.08327437937259674,\n",
       "  -1.3801610469818115,\n",
       "  0.7277399897575378,\n",
       "  -0.5197007656097412,\n",
       "  0.5456405282020569,\n",
       "  -0.8782932758331299,\n",
       "  0.3078867793083191,\n",
       "  -1.961706280708313,\n",
       "  -0.1508183777332306,\n",
       "  -0.0023220982402563095,\n",
       "  -0.10553991049528122,\n",
       "  -0.1930173933506012,\n",
       "  -0.6027742624282837,\n",
       "  -0.3356451094150543,\n",
       "  1.939710021018982,\n",
       "  0.03912387415766716,\n",
       "  -0.15070916712284088,\n",
       "  0.4628516137599945,\n",
       "  -0.7121085524559021,\n",
       "  0.7279791831970215,\n",
       "  0.8908182978630066,\n",
       "  -0.40678057074546814,\n",
       "  0.7068625688552856,\n",
       "  -0.2909177839756012,\n",
       "  -1.1358051300048828,\n",
       "  -0.4169355630874634,\n",
       "  -1.0893644094467163,\n",
       "  0.34540319442749023,\n",
       "  1.4663259983062744,\n",
       "  -0.0020974616054445505,\n",
       "  0.32658520340919495,\n",
       "  -0.7650182843208313,\n",
       "  0.39594897627830505,\n",
       "  1.140541911125183,\n",
       "  -0.5521773099899292,\n",
       "  1.1303348541259766,\n",
       "  -0.8244548439979553,\n",
       "  0.4518759846687317,\n",
       "  1.168640375137329,\n",
       "  0.35577115416526794,\n",
       "  -0.2658759653568268,\n",
       "  -0.8245742917060852,\n",
       "  0.2461390644311905,\n",
       "  -0.31157779693603516,\n",
       "  0.11972787976264954,\n",
       "  1.308833122253418,\n",
       "  0.8915603756904602,\n",
       "  -0.6545803546905518,\n",
       "  -0.22857815027236938,\n",
       "  -0.91615891456604,\n",
       "  0.3684200048446655,\n",
       "  -0.042583826929330826,\n",
       "  -1.1277207136154175,\n",
       "  -0.024341663345694542,\n",
       "  -0.6698769330978394,\n",
       "  -0.19826681911945343,\n",
       "  -0.10148347914218903,\n",
       "  0.7394358515739441,\n",
       "  -0.9953992366790771,\n",
       "  1.1951794624328613,\n",
       "  -0.9890987277030945,\n",
       "  0.7052010893821716,\n",
       "  -0.8488146066665649,\n",
       "  0.9942099452018738,\n",
       "  -1.3536176681518555,\n",
       "  -0.05097337067127228,\n",
       "  -0.12761032581329346,\n",
       "  -0.9004177451133728,\n",
       "  0.5538495779037476,\n",
       "  0.260593980550766,\n",
       "  0.632462739944458,\n",
       "  -0.5822792053222656,\n",
       "  0.6037980318069458,\n",
       "  -0.06531764566898346,\n",
       "  0.34447145462036133,\n",
       "  -0.49279654026031494,\n",
       "  -0.05577324703335762,\n",
       "  0.6131393313407898,\n",
       "  0.6736758947372437,\n",
       "  -0.4140990376472473,\n",
       "  0.07839031517505646,\n",
       "  1.4067506790161133,\n",
       "  0.36902061104774475,\n",
       "  -0.22461135685443878,\n",
       "  -0.747319757938385,\n",
       "  -0.49615877866744995,\n",
       "  0.9120131134986877,\n",
       "  0.05533280968666077,\n",
       "  0.03024386614561081,\n",
       "  -1.0460107326507568,\n",
       "  0.19884173572063446,\n",
       "  -0.21346504986286163,\n",
       "  -0.8835188150405884,\n",
       "  0.9732685089111328,\n",
       "  -0.4621252715587616,\n",
       "  0.3361811339855194,\n",
       "  0.32131537795066833,\n",
       "  -0.3516024351119995,\n",
       "  -0.9148073792457581,\n",
       "  0.24553143978118896,\n",
       "  0.26864132285118103,\n",
       "  -0.4225359857082367,\n",
       "  -0.3468783497810364,\n",
       "  -0.3863164186477661,\n",
       "  -0.25660815834999084,\n",
       "  -1.2647662162780762,\n",
       "  1.445292353630066,\n",
       "  -1.2355436086654663,\n",
       "  -0.6532002687454224,\n",
       "  -0.12000484764575958,\n",
       "  -1.2019579410552979,\n",
       "  0.02877647988498211,\n",
       "  0.9215813279151917,\n",
       "  -0.11419204622507095,\n",
       "  -0.47535011172294617,\n",
       "  0.9029199481010437,\n",
       "  1.498902440071106,\n",
       "  1.526852011680603,\n",
       "  0.1326662003993988,\n",
       "  0.24148985743522644,\n",
       "  -0.283562570810318,\n",
       "  -0.07697027176618576,\n",
       "  0.09871453791856766,\n",
       "  1.5971715450286865,\n",
       "  0.34885019063949585,\n",
       "  -0.3182135224342346,\n",
       "  -1.6270757913589478,\n",
       "  1.8840569257736206,\n",
       "  -0.38290736079216003,\n",
       "  0.04410097375512123,\n",
       "  -2.4843263626098633,\n",
       "  0.8177360892295837,\n",
       "  0.4274751842021942,\n",
       "  -0.31526991724967957,\n",
       "  -0.36988088488578796,\n",
       "  0.09801016002893448,\n",
       "  -0.4200783669948578,\n",
       "  0.6587865352630615,\n",
       "  0.522516667842865,\n",
       "  0.8050791025161743,\n",
       "  0.8191269040107727,\n",
       "  -0.29560911655426025,\n",
       "  0.24895882606506348,\n",
       "  0.6002985835075378,\n",
       "  0.9454224705696106,\n",
       "  0.3482411801815033,\n",
       "  -1.425581693649292,\n",
       "  0.5362899303436279,\n",
       "  -0.1951301097869873,\n",
       "  -0.15212641656398773,\n",
       "  -0.8187902569770813,\n",
       "  -1.7978003025054932,\n",
       "  0.49223217368125916,\n",
       "  -0.9913426637649536,\n",
       "  0.21794694662094116,\n",
       "  0.3933628499507904,\n",
       "  -0.9378634095191956,\n",
       "  0.7108617424964905,\n",
       "  2.601684808731079,\n",
       "  0.8934894800186157,\n",
       "  -0.2624666690826416,\n",
       "  -0.5001202821731567,\n",
       "  -1.2314015626907349,\n",
       "  -0.18344703316688538,\n",
       "  -0.5272612571716309,\n",
       "  -0.7167021632194519,\n",
       "  -1.6599212884902954,\n",
       "  -0.09396151453256607,\n",
       "  0.06404105573892593,\n",
       "  -0.0995960682630539,\n",
       "  -0.6305285692214966,\n",
       "  -0.6407067775726318,\n",
       "  -0.13551032543182373,\n",
       "  0.02130725048482418,\n",
       "  -0.2629071772098541,\n",
       "  0.34776830673217773,\n",
       "  0.2575526833534241,\n",
       "  -0.2569634020328522,\n",
       "  -1.391105055809021,\n",
       "  0.5697622895240784,\n",
       "  0.015389123000204563,\n",
       "  -0.9793342351913452,\n",
       "  0.36443305015563965,\n",
       "  -0.4083814024925232,\n",
       "  -0.9888356328010559,\n",
       "  0.31293150782585144,\n",
       "  -0.2878013551235199,\n",
       "  -0.6208928823471069,\n",
       "  0.750720202922821,\n",
       "  -0.496304452419281,\n",
       "  -0.6437421441078186,\n",
       "  -0.961655855178833,\n",
       "  0.21021459996700287,\n",
       "  -0.386976420879364,\n",
       "  0.37917888164520264,\n",
       "  0.34330135583877563,\n",
       "  0.0017474750056862831,\n",
       "  -1.1300137042999268,\n",
       "  1.0592021942138672,\n",
       "  -0.4284314513206482,\n",
       "  -0.9053282737731934,\n",
       "  -1.1763423681259155,\n",
       "  -0.17530757188796997,\n",
       "  -0.8470163941383362,\n",
       "  -0.12555788457393646,\n",
       "  0.009850096888840199,\n",
       "  1.246782898902893,\n",
       "  0.3819248676300049,\n",
       "  -0.3635750114917755,\n",
       "  0.5842939019203186,\n",
       "  0.15841296315193176,\n",
       "  0.28639429807662964,\n",
       "  -0.7480193972587585,\n",
       "  0.5637019276618958,\n",
       "  0.21386602520942688,\n",
       "  -0.380877286195755,\n",
       "  -0.1489877551794052,\n",
       "  1.305141568183899,\n",
       "  -0.5612363815307617,\n",
       "  -0.19100485742092133,\n",
       "  -0.5777883529663086,\n",
       "  -0.9050561785697937,\n",
       "  -0.24686811864376068,\n",
       "  0.5547754764556885,\n",
       "  -0.011403980664908886,\n",
       "  -1.0301536321640015,\n",
       "  -0.42435580492019653,\n",
       "  -0.325914591550827,\n",
       "  0.5550440549850464,\n",
       "  0.321431964635849,\n",
       "  -0.7566438913345337,\n",
       "  0.8001003265380859,\n",
       "  -0.29169702529907227,\n",
       "  1.5475958585739136,\n",
       "  -0.40210098028182983,\n",
       "  1.1961256265640259,\n",
       "  0.26980218291282654,\n",
       "  -0.474200040102005,\n",
       "  0.639888346195221,\n",
       "  0.6015498638153076,\n",
       "  0.5212484002113342,\n",
       "  -0.6724298596382141,\n",
       "  0.2858758568763733,\n",
       "  0.1664474457502365,\n",
       "  -0.6048458814620972,\n",
       "  0.4434708058834076,\n",
       "  0.21763788163661957,\n",
       "  0.11817387491464615,\n",
       "  0.23865263164043427,\n",
       "  0.013114331290125847,\n",
       "  0.9654194116592407,\n",
       "  0.7201658487319946,\n",
       "  0.1338147222995758,\n",
       "  0.8106698989868164,\n",
       "  0.35735011100769043,\n",
       "  0.7665159106254578,\n",
       "  0.38869932293891907,\n",
       "  -0.35316023230552673,\n",
       "  -1.0724388360977173,\n",
       "  0.5526091456413269,\n",
       "  0.18219000101089478,\n",
       "  1.2483059167861938,\n",
       "  -0.6604795455932617,\n",
       "  0.7943456172943115,\n",
       "  0.6776332259178162,\n",
       "  -0.7275763154029846,\n",
       "  0.457915335893631,\n",
       "  -0.05890724062919617,\n",
       "  -0.2686671316623688,\n",
       "  -0.3169091045856476,\n",
       "  -1.0831149816513062,\n",
       "  -0.7564216256141663,\n",
       "  -0.06499912589788437,\n",
       "  0.9025612473487854,\n",
       "  1.1698827743530273,\n",
       "  -0.9507924914360046,\n",
       "  -0.3888797163963318,\n",
       "  -0.7807958126068115,\n",
       "  -0.7878463864326477,\n",
       "  -0.21076247096061707,\n",
       "  0.7965797185897827,\n",
       "  0.7430925965309143,\n",
       "  -0.44702887535095215,\n",
       "  0.5233803987503052,\n",
       "  -0.09159932285547256,\n",
       "  -0.6219528317451477,\n",
       "  -0.11371408402919769,\n",
       "  -1.607445240020752,\n",
       "  -0.047333747148513794,\n",
       "  -0.8689982295036316,\n",
       "  0.5338100790977478,\n",
       "  0.024033477529883385,\n",
       "  -1.0938721895217896,\n",
       "  0.3754313886165619,\n",
       "  -0.3499196767807007,\n",
       "  0.9134868383407593,\n",
       "  -0.1274322122335434,\n",
       "  0.4399060606956482,\n",
       "  -0.309312641620636,\n",
       "  -0.9982767701148987,\n",
       "  1.0127100944519043,\n",
       "  -0.5047388672828674,\n",
       "  -0.15445762872695923,\n",
       "  -0.04418860375881195,\n",
       "  -0.29805445671081543,\n",
       "  0.8872197866439819,\n",
       "  0.13125170767307281,\n",
       "  0.0777631476521492,\n",
       "  1.9896973371505737,\n",
       "  -0.7757524251937866,\n",
       "  -0.25395944714546204,\n",
       "  0.38620859384536743,\n",
       "  -1.287476658821106,\n",
       "  -0.6827999949455261,\n",
       "  0.13294072449207306,\n",
       "  -0.19844821095466614,\n",
       "  1.1531888246536255,\n",
       "  -0.2116539627313614,\n",
       "  -1.0354104042053223,\n",
       "  -0.5702685713768005,\n",
       "  -0.14501987397670746,\n",
       "  -0.7524058222770691,\n",
       "  -0.2868362069129944,\n",
       "  2.158731460571289,\n",
       "  1.0560014247894287,\n",
       "  0.025941947475075722,\n",
       "  -0.12822914123535156,\n",
       "  -1.2911717891693115,\n",
       "  -0.1487458348274231,\n",
       "  -1.4432035684585571,\n",
       "  1.455971598625183,\n",
       "  -0.4705709218978882,\n",
       "  -0.12464603781700134,\n",
       "  1.4558507204055786,\n",
       "  -1.0564254522323608,\n",
       "  -0.03956083580851555,\n",
       "  1.0642954111099243,\n",
       "  0.09865815937519073,\n",
       "  -0.7659777402877808,\n",
       "  -0.2199161946773529,\n",
       "  -0.8693947196006775,\n",
       "  -0.26987215876579285,\n",
       "  0.8832955956459045,\n",
       "  -0.7173595428466797,\n",
       "  -1.0368057489395142,\n",
       "  -0.0034604701213538647,\n",
       "  0.014377272687852383,\n",
       "  0.4214291274547577,\n",
       "  -0.14941947162151337,\n",
       "  -0.4601229131221771,\n",
       "  0.6707870364189148,\n",
       "  -1.5089019536972046,\n",
       "  -0.7372210621833801,\n",
       "  -0.0029031536541879177,\n",
       "  0.028272878378629684,\n",
       "  0.24788913130760193,\n",
       "  -0.7185034155845642,\n",
       "  0.27792438864707947,\n",
       "  0.4436070919036865,\n",
       "  -0.08419714868068695,\n",
       "  0.2453940510749817,\n",
       "  -0.9059706926345825,\n",
       "  0.9227755665779114,\n",
       "  0.23795819282531738,\n",
       "  -0.8771264553070068,\n",
       "  -0.447439968585968,\n",
       "  -0.6333416104316711,\n",
       "  -0.8543418645858765,\n",
       "  -0.2077428251504898,\n",
       "  -0.525843620300293,\n",
       "  0.5407851338386536,\n",
       "  0.1790015697479248,\n",
       "  0.5065639019012451,\n",
       "  0.41596749424934387,\n",
       "  0.561375081539154,\n",
       "  -0.7511054277420044,\n",
       "  -0.5876570343971252,\n",
       "  0.43516120314598083,\n",
       "  -0.468474805355072,\n",
       "  1.1849669218063354,\n",
       "  -0.47414642572402954,\n",
       "  -0.26253917813301086,\n",
       "  0.6592617630958557,\n",
       "  -1.3837568759918213,\n",
       "  0.014357239939272404,\n",
       "  1.0988911390304565,\n",
       "  -0.004614102188497782,\n",
       "  -1.2242337465286255,\n",
       "  0.5850694179534912,\n",
       "  0.40134498476982117,\n",
       "  0.007683336269110441,\n",
       "  -0.9945802092552185,\n",
       "  0.19662566483020782,\n",
       "  -0.4028741717338562,\n",
       "  0.19144970178604126,\n",
       "  -0.5140297412872314,\n",
       "  0.11983811110258102,\n",
       "  -0.5624880790710449,\n",
       "  0.7299923300743103,\n",
       "  -0.02109663374722004,\n",
       "  0.4789924621582031,\n",
       "  -1.7889089584350586,\n",
       "  -0.248149573802948,\n",
       "  0.4487215280532837,\n",
       "  0.3729196786880493,\n",
       "  0.7771294713020325,\n",
       "  -0.29698315262794495,\n",
       "  0.7570639848709106,\n",
       "  -1.2807481288909912,\n",
       "  0.3384176790714264,\n",
       "  -0.16224101185798645,\n",
       "  -0.11036704480648041,\n",
       "  0.7392228245735168,\n",
       "  0.9574378132820129,\n",
       "  0.29672834277153015,\n",
       "  0.7713276147842407,\n",
       "  -0.23272617161273956,\n",
       "  0.3910520076751709,\n",
       "  1.2581144571304321,\n",
       "  -0.18093803524971008,\n",
       "  -0.14362281560897827,\n",
       "  -0.8495132327079773,\n",
       "  0.4463654160499573,\n",
       "  0.07901313155889511,\n",
       "  2.0726678371429443,\n",
       "  -0.30736419558525085,\n",
       "  -1.6036045551300049,\n",
       "  -0.19668443500995636,\n",
       "  1.539383053779602,\n",
       "  -0.2023666948080063,\n",
       "  -0.8108084201812744,\n",
       "  -1.3408221006393433,\n",
       "  1.2182265520095825,\n",
       "  0.021885959431529045,\n",
       "  -0.7486647367477417,\n",
       "  -0.6375933885574341,\n",
       "  -0.3251648545265198,\n",
       "  0.274291068315506,\n",
       "  -1.4463120698928833,\n",
       "  -0.34800976514816284,\n",
       "  -0.5408284068107605,\n",
       "  0.09124353528022766,\n",
       "  0.3491334617137909,\n",
       "  -1.5436118841171265,\n",
       "  -0.6024878025054932,\n",
       "  -0.5464234948158264,\n",
       "  0.02858387678861618,\n",
       "  -0.2723196744918823,\n",
       "  -0.3031345307826996,\n",
       "  1.195302963256836,\n",
       "  0.8648862838745117,\n",
       "  0.49801313877105713,\n",
       "  0.2268785834312439,\n",
       "  -0.489719957113266,\n",
       "  -0.8814404010772705,\n",
       "  -0.8113216757774353,\n",
       "  -0.7085772156715393,\n",
       "  0.9745893478393555,\n",
       "  -0.9183006286621094,\n",
       "  -0.2471744269132614,\n",
       "  -0.14885523915290833,\n",
       "  -1.4371013641357422,\n",
       "  0.46641772985458374,\n",
       "  -0.05187712237238884,\n",
       "  0.7743442058563232,\n",
       "  0.6357895731925964,\n",
       "  -0.02611088752746582,\n",
       "  -0.3885965943336487,\n",
       "  -0.3114050626754761,\n",
       "  0.6284576654434204,\n",
       "  0.42053401470184326,\n",
       "  0.10385075211524963,\n",
       "  0.38388755917549133,\n",
       "  -0.5211057066917419,\n",
       "  0.10400450974702835,\n",
       "  -0.1357528269290924,\n",
       "  2.044893741607666,\n",
       "  0.021861184388399124,\n",
       "  -0.5189147591590881,\n",
       "  -0.22589416801929474,\n",
       "  -0.38594740629196167,\n",
       "  -0.6286699771881104,\n",
       "  0.4810660183429718,\n",
       "  0.3055514097213745,\n",
       "  1.5817468166351318,\n",
       "  -0.3645921051502228,\n",
       "  -1.3692913055419922,\n",
       "  -0.6973675489425659,\n",
       "  -0.24271956086158752,\n",
       "  0.45643484592437744,\n",
       "  -0.6488536596298218,\n",
       "  -0.12310010939836502,\n",
       "  0.05078740790486336,\n",
       "  -1.5059318542480469,\n",
       "  0.12444913387298584,\n",
       "  0.3571113646030426,\n",
       "  -0.14119218289852142,\n",
       "  -0.27387821674346924,\n",
       "  -0.04934265837073326,\n",
       "  0.5844067335128784,\n",
       "  0.6339367032051086,\n",
       "  -0.7085539698600769,\n",
       "  -0.3006832003593445,\n",
       "  0.042235031723976135,\n",
       "  -0.43708813190460205,\n",
       "  0.08744484931230545,\n",
       "  -0.32325515151023865,\n",
       "  0.6563643217086792,\n",
       "  0.8090295791625977,\n",
       "  1.3811559677124023,\n",
       "  0.20637696981430054,\n",
       "  -0.45401349663734436,\n",
       "  -1.618778944015503,\n",
       "  0.11819295585155487,\n",
       "  0.009137377142906189,\n",
       "  1.7730848789215088,\n",
       "  -0.9160861968994141,\n",
       "  0.01710035279393196,\n",
       "  -0.5712979435920715,\n",
       "  0.8321623206138611,\n",
       "  -0.4887062609195709,\n",
       "  0.15833567082881927,\n",
       "  -0.4353189468383789,\n",
       "  -0.7734658718109131,\n",
       "  0.39773622155189514,\n",
       "  -0.4086326062679291,\n",
       "  -1.5344854593276978,\n",
       "  1.3666139841079712,\n",
       "  -0.07436066120862961,\n",
       "  0.6669915914535522,\n",
       "  0.4388086199760437,\n",
       "  0.3903088867664337,\n",
       "  2.498131036758423,\n",
       "  -0.615705132484436,\n",
       "  0.2628917694091797,\n",
       "  1.024796962738037,\n",
       "  0.30708077549934387,\n",
       "  -0.17677195370197296,\n",
       "  0.12424485385417938,\n",
       "  0.6227591633796692,\n",
       "  0.254224956035614,\n",
       "  -0.18792806565761566,\n",
       "  -0.5789415836334229,\n",
       "  -0.5727983117103577,\n",
       "  0.1433456987142563,\n",
       "  0.4171510338783264,\n",
       "  -0.5723655223846436,\n",
       "  -0.6012026071548462,\n",
       "  -0.11510825157165527,\n",
       "  -0.8261401653289795,\n",
       "  0.13489001989364624,\n",
       "  -0.330075204372406,\n",
       "  -0.09195496886968613,\n",
       "  -1.1031988859176636,\n",
       "  -0.4369038939476013,\n",
       "  -0.6043456792831421,\n",
       "  -0.06861106306314468,\n",
       "  0.04495479539036751,\n",
       "  -0.43206876516342163,\n",
       "  -0.5453510284423828,\n",
       "  0.18985214829444885,\n",
       "  -0.042454224079847336,\n",
       "  -0.7799553871154785,\n",
       "  0.13446396589279175,\n",
       "  0.038829632103443146,\n",
       "  1.8671940565109253,\n",
       "  -0.5247596502304077,\n",
       "  1.4402191638946533,\n",
       "  0.5706843733787537,\n",
       "  -0.5169349312782288,\n",
       "  0.8408072590827942,\n",
       "  0.73622065782547,\n",
       "  -0.5492338538169861,\n",
       "  -0.5639576315879822,\n",
       "  -0.24296286702156067,\n",
       "  -0.17770588397979736,\n",
       "  -0.4815268814563751,\n",
       "  -1.0558220148086548,\n",
       "  -0.4725702702999115,\n",
       "  -0.2759077548980713,\n",
       "  0.05034189671278,\n",
       "  -1.9581531286239624,\n",
       "  0.9156426191329956,\n",
       "  0.5470014214515686,\n",
       "  -0.18059760332107544,\n",
       "  1.1081606149673462,\n",
       "  0.6394986510276794,\n",
       "  0.6408661603927612,\n",
       "  -0.36498263478279114,\n",
       "  -0.5890209674835205,\n",
       "  -0.25731343030929565,\n",
       "  -0.9088685512542725,\n",
       "  -1.0811845064163208,\n",
       "  -0.2983143627643585,\n",
       "  -0.8041056394577026,\n",
       "  1.4455057382583618,\n",
       "  -0.4880916476249695,\n",
       "  -0.3995687663555145,\n",
       "  -0.24308492243289948,\n",
       "  1.121293067932129,\n",
       "  0.6734001040458679,\n",
       "  -1.5321134328842163,\n",
       "  -0.8943764567375183,\n",
       "  0.18150284886360168,\n",
       "  -0.8721210956573486,\n",
       "  0.6683545708656311,\n",
       "  -0.6830829381942749,\n",
       "  0.2602817416191101,\n",
       "  -0.36006927490234375,\n",
       "  0.7154470086097717,\n",
       "  0.8537447452545166,\n",
       "  0.2913054823875427,\n",
       "  -0.06419043242931366,\n",
       "  0.5253223776817322,\n",
       "  0.65297931432724,\n",
       "  1.4479900598526,\n",
       "  -0.3762325048446655,\n",
       "  -0.6227120161056519,\n",
       "  -0.8206433057785034,\n",
       "  0.24956803023815155,\n",
       "  -1.2928141355514526,\n",
       "  -0.6635395288467407,\n",
       "  -0.09158678352832794,\n",
       "  0.8810451626777649,\n",
       "  -0.017739808186888695,\n",
       "  0.617761492729187,\n",
       "  0.367914080619812,\n",
       "  0.383075088262558,\n",
       "  0.5096514225006104,\n",
       "  0.043678585439920425,\n",
       "  -0.4892241358757019,\n",
       "  0.0768885686993599,\n",
       "  -0.23169654607772827,\n",
       "  -0.06884371489286423,\n",
       "  0.023900529369711876,\n",
       "  0.6978532075881958,\n",
       "  0.6845254898071289]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.embed([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cached data:\n",
    "# wrapper.embeddings_training\n",
    "# wrapper.embeddings_testing\n",
    "# wrapper.projector\n",
    "# wrapper.projections_training\n",
    "# wrapper.projections_testing\n",
    "# wrapper.salience_maps\n",
    "# wrapper.clusters\n",
    "# wrapper.cluster_profiles\n",
    "# wrapper.cluster_words_freqs\n",
    "# wrapper.cluster_class_word_sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

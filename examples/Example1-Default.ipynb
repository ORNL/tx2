{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1 - Default Approach\n",
    "\n",
    "This notebook demonstrates how to use the TX2 dashboard with a sequence classification transformer using the default approach as described in the \"Basic Usage\" docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -q ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We enable logging to view the output from `wrapper.prepare()` further down in the notebook. (It's a long running function, and logs which step it's on.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import cuda\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example notebook, we use the 20 newsgroups dataset, which can be downloaded through huggingfacevia below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration SetFit--20_newsgroups-f9362e018b6adf67\n",
      "Reusing dataset json (/Users/s6t/.cache/huggingface/datasets/SetFit___json/SetFit--20_newsgroups-f9362e018b6adf67/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n",
      "Using custom data configuration SetFit--20_newsgroups-f9362e018b6adf67\n",
      "Reusing dataset json (/Users/s6t/.cache/huggingface/datasets/SetFit___json/SetFit--20_newsgroups-f9362e018b6adf67/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# getting newsgroups data from huggingface\n",
    "train_data = pd.DataFrame(data=load_dataset(\"SetFit/20_newsgroups\", split=\"train\"))\n",
    "test_data = pd.DataFrame(data=load_dataset(\"SetFit/20_newsgroups\", split=\"test\"))\n",
    "\n",
    "# setting up pytorch device\n",
    "if cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.has_mps:\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Defined below is a simple sequence classification model with a variable for the language model itself `l1`. Since it is a BERT model, we take the sequence embedding from the `[CLS]` token (via `output_1[0][:, 0, :])`) and pipe that into the linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "        self.l2 = torch.nn.Linear(768, 20)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        output_1 = self.l1(ids, mask)\n",
    "        output = self.l2(output_1[0][:, 0, :])  # use just the [CLS] output embedding\n",
    "        return output\n",
    "\n",
    "\n",
    "model = BERTClass()\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some simplistic data cleaning, and putting all data into dataframes for the wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    # text = text[text.index(\"\\n\\n\") + 2 :]\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"    \", \" \")\n",
    "    text = text.replace(\"   \", \" \")\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you have Weitek's address/phone number? I'd...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye) DN...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>I have a (very old) Mac 512k and a Mac Plus, b...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>Wouldn't this require a hyper-sphere. In 3-spa...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>Stolen from Pasadena between 4:30 and 6:30 pm ...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      I was wondering if anyone out there could enli...      7   \n",
       "1      A fair number of brave souls who upgraded thei...      4   \n",
       "2      well folks, my mac plus finally gave up the gh...      4   \n",
       "3      Do you have Weitek's address/phone number? I'd...      1   \n",
       "4      From article <C5owCB.n3p@world.std.com>, by to...     14   \n",
       "...                                                  ...    ...   \n",
       "11309  DN> From: nyeda@cnsvax.uwec.edu (David Nye) DN...     13   \n",
       "11310  I have a (very old) Mac 512k and a Mac Plus, b...      4   \n",
       "11311  I just installed a DX2-66 CPU in a clone mothe...      3   \n",
       "11312  Wouldn't this require a hyper-sphere. In 3-spa...      1   \n",
       "11313  Stolen from Pasadena between 4:30 and 6:30 pm ...      8   \n",
       "\n",
       "                     label_text  \n",
       "0                     rec.autos  \n",
       "1         comp.sys.mac.hardware  \n",
       "2         comp.sys.mac.hardware  \n",
       "3                 comp.graphics  \n",
       "4                     sci.space  \n",
       "...                         ...  \n",
       "11309                   sci.med  \n",
       "11310     comp.sys.mac.hardware  \n",
       "11311  comp.sys.ibm.pc.hardware  \n",
       "11312             comp.graphics  \n",
       "11313           rec.motorcycles  \n",
       "\n",
       "[11014 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean long white space or extensive character returns\n",
    "train_data.text = train_data.text.apply(lambda x: clean_text(x))\n",
    "test_data.text = test_data.text.apply(lambda x: clean_text(x))\n",
    "\n",
    "# remove empty entries or trivially short ones\n",
    "train_cleaned = train_data[train_data[\"text\"].str.len() > 1]\n",
    "test_cleaned = test_data[test_data[\"text\"].str.len() > 1]\n",
    "train_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "This section minimally trains the classification and language model - nothing fancy here, just to give the dashboard demo something to work with. Most of this is similar to the huggingface tutorial notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11014\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "class EncodedSet(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        print(self.len)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.data.text[index])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            \"targets\": torch.tensor(self.data.label[index], dtype=torch.long),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "train_cleaned.reset_index(drop=True, inplace=True)\n",
    "test_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_set = EncodedSet(train_cleaned, tokenizer, 256)\n",
    "test_set = EncodedSet(test_cleaned[:1000], tokenizer, 256)\n",
    "\n",
    "train_params = {\"batch_size\": 16, \"shuffle\": True, \"num_workers\": 0}\n",
    "\n",
    "test_params = {\"batch_size\": 2, \"shuffle\": True, \"num_workers\": 0}\n",
    "\n",
    "# put everything into data loaders\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    loss_history = []\n",
    "    for _, data in tqdm(\n",
    "        enumerate(train_loader, start=0), total=len(train_loader), desc=f\"Epoch {epoch}\"\n",
    "    ):\n",
    "        ids = data[\"ids\"].to(device, dtype=torch.long)\n",
    "        mask = data[\"mask\"].to(device, dtype=torch.long)\n",
    "        targets = data[\"targets\"].to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(ids, mask).squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, targets)\n",
    "        if _ % 100 == 0:\n",
    "            print(f\"Epoch: {epoch}, Loss:  {loss.item()}\")\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #         torch.cuda.empty_cache()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83b8ed3114e4878868b9e085de61659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/689 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  3.0523223876953125\n",
      "Epoch: 0, Loss:  2.7332470417022705\n",
      "Epoch: 0, Loss:  1.9246597290039062\n",
      "Epoch: 0, Loss:  1.1634421348571777\n",
      "Epoch: 0, Loss:  0.9817249774932861\n",
      "Epoch: 0, Loss:  0.8750985860824585\n",
      "Epoch: 0, Loss:  1.3905093669891357\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(1):\n",
    "    losses.extend(train(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapper uses an `encodings` dictionary for various labels/visualizations, and can be set up with something similar to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism': 0,\n",
       " 'comp.graphics': 1,\n",
       " 'comp.os.ms-windows.misc': 2,\n",
       " 'comp.sys.ibm.pc.hardware': 3,\n",
       " 'comp.sys.mac.hardware': 4,\n",
       " 'comp.windows.x': 5,\n",
       " 'misc.forsale': 6,\n",
       " 'rec.autos': 7,\n",
       " 'rec.motorcycles': 8,\n",
       " 'rec.sport.baseball': 9,\n",
       " 'rec.sport.hockey': 10,\n",
       " 'sci.crypt': 11,\n",
       " 'sci.electronics': 12,\n",
       " 'sci.med': 13,\n",
       " 'sci.space': 14,\n",
       " 'soc.religion.christian': 15,\n",
       " 'talk.politics.guns': 16,\n",
       " 'talk.politics.mideast': 17,\n",
       " 'talk.politics.misc': 18,\n",
       " 'talk.religion.misc': 19}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = (\n",
    "    train_cleaned[[\"label\", \"label_text\"]]\n",
    "    .groupby([\"label_text\"])\n",
    "    .apply(lambda x: x[\"label\"].tolist()[0])\n",
    "    .to_dict()\n",
    ")\n",
    "encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TX2\n",
    "\n",
    "This section shows how to put everything into the TX2 wrapper to get the dashboard widget displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tx2.dashboard import Dashboard\n",
    "from tx2.wrapper import Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Cache path found\n",
      "INFO:root:Checking for cached predictions...\n",
      "INFO:root:Running classifier...\n",
      "INFO:root:Saving predictions...\n",
      "INFO:root:Writing to data/predictions.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached embeddings...\n",
      "INFO:root:Embedding training and testing datasets\n",
      "INFO:root:Saving embeddings...\n",
      "INFO:root:Writing to data/embedding_training.json\n",
      "INFO:root:Writing to data/embedding_testing.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached projections...\n",
      "INFO:root:Training projector...\n",
      "INFO:root:Applying projector to test dataset...\n",
      "INFO:root:Saving projections...\n",
      "INFO:root:Writing to data/projections_training.json\n",
      "INFO:root:Writing to data/projections_testing.json\n",
      "INFO:root:Writing to data/projector.pkl.gz\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached salience maps...\n",
      "INFO:root:Computing salience maps...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee49221fd40f40928043b76e86239bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving salience maps...\n",
      "INFO:root:Writing to data/salience.pkl.gz\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached cluster profiles...\n",
      "INFO:root:Clustering projections...\n",
      "INFO:root:Saving cluster profiles...\n",
      "INFO:root:Writing to data/clusters.json\n",
      "INFO:root:Writing to data/cluster_profiles.pkl.gz\n",
      "INFO:root:Done!\n",
      "INFO:root:Saving cluster labels...\n",
      "INFO:root:Writing to data/cluster_labels.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Saving cluster word counts...\n",
      "INFO:root:Writing to data/cluster_words.json\n",
      "INFO:root:Writing to data/cluster_class_words.json\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "wrapper = Wrapper(\n",
    "    train_texts=train_cleaned.text,\n",
    "    train_labels=train_cleaned.label,\n",
    "    test_texts=test_cleaned.text[:2000],\n",
    "    test_labels=test_cleaned.label[:2000],\n",
    "    encodings=encodings,\n",
    "    classifier=model,\n",
    "    language_model=model.l1,\n",
    "    tokenizer=tokenizer,\n",
    "    overwrite=True,\n",
    ")\n",
    "wrapper.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b0cac9044b40dfb394b0d7898b85c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>UMAP Embedding Graph</h3>'), HBox(children=(Output(), VBox(child…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dash = Dashboard(wrapper)\n",
    "dash.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To play with different UMAP and DBSCAN arguments without having to recompute the entire `prepare()` function, you can use `recompute_projections` (which will recompute both the projections and visual clusterings) or `recompute_visual_clusterings` (which will only redo the clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper.recompute_visual_clusterings(\"KMeans\", clustering_args=dict(n_clusters=18))\n",
    "# wrapper.recompute_visual_clusterings(\"OPTICS\", clustering_args=dict())\n",
    "# wrapper.recompute_projections(umap_args=dict(min_dist=.2), dbscan_args=dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test or debug the classification model/see what raw outputs the viusualizations are getting, or create your own visualization tools, you can manually call the `classify()`, `soft_classify()`, `embed()` functions, or get access to any of the cached data as seen in the bottom cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.08946020156145096,\n",
       "  0.21405138075351715,\n",
       "  -0.4607403874397278,\n",
       "  0.01164185255765915,\n",
       "  0.4523540139198303,\n",
       "  -1.0458922386169434,\n",
       "  0.22184935212135315,\n",
       "  1.5812029838562012,\n",
       "  1.4822856187820435,\n",
       "  0.3588578402996063,\n",
       "  0.061013542115688324,\n",
       "  -0.6977149844169617,\n",
       "  0.34074148535728455,\n",
       "  -0.5585644841194153,\n",
       "  -0.18628935515880585,\n",
       "  -0.9265161752700806,\n",
       "  0.2404371201992035,\n",
       "  -0.6049383878707886,\n",
       "  -1.1522669792175293,\n",
       "  -0.7357930541038513]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.soft_classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.2497406005859375,\n",
       "  0.9026437401771545,\n",
       "  -0.3430388569831848,\n",
       "  -0.43509605526924133,\n",
       "  -0.13553540408611298,\n",
       "  0.1561593860387802,\n",
       "  0.19396862387657166,\n",
       "  0.07807128131389618,\n",
       "  -0.00714879110455513,\n",
       "  -1.9946285486221313,\n",
       "  -0.13812898099422455,\n",
       "  0.3265349566936493,\n",
       "  0.09346793591976166,\n",
       "  0.5247447490692139,\n",
       "  -1.151289463043213,\n",
       "  0.5801931619644165,\n",
       "  0.495939165353775,\n",
       "  0.977996289730072,\n",
       "  0.656205952167511,\n",
       "  0.06874965131282806,\n",
       "  -0.25887614488601685,\n",
       "  -0.25453341007232666,\n",
       "  0.49154549837112427,\n",
       "  -0.7532821893692017,\n",
       "  0.1494058221578598,\n",
       "  -0.15004862844944,\n",
       "  0.12259159982204437,\n",
       "  0.8951445817947388,\n",
       "  0.2980200946331024,\n",
       "  -0.044018082320690155,\n",
       "  -0.21323153376579285,\n",
       "  0.6455697417259216,\n",
       "  -0.14402593672275543,\n",
       "  0.9693578481674194,\n",
       "  0.6352863311767578,\n",
       "  0.05371423810720444,\n",
       "  0.44283896684646606,\n",
       "  0.5356361865997314,\n",
       "  0.2094734162092209,\n",
       "  0.45343536138534546,\n",
       "  -0.7204819321632385,\n",
       "  0.37397611141204834,\n",
       "  0.30392831563949585,\n",
       "  -0.4317653477191925,\n",
       "  -0.06211601942777634,\n",
       "  -0.1726413518190384,\n",
       "  -0.1454830765724182,\n",
       "  -0.6951202154159546,\n",
       "  -0.4804590940475464,\n",
       "  0.6566651463508606,\n",
       "  -0.10511592775583267,\n",
       "  0.26306959986686707,\n",
       "  0.6718877553939819,\n",
       "  0.9543684124946594,\n",
       "  0.7344220280647278,\n",
       "  0.07847922295331955,\n",
       "  -0.5130994319915771,\n",
       "  0.26929813623428345,\n",
       "  -0.2181544303894043,\n",
       "  0.5737439393997192,\n",
       "  -0.48380720615386963,\n",
       "  -0.8093932271003723,\n",
       "  -0.2517170310020447,\n",
       "  0.5329638123512268,\n",
       "  0.13703016936779022,\n",
       "  -0.8743889331817627,\n",
       "  0.9632096290588379,\n",
       "  -0.9060430526733398,\n",
       "  -0.16672255098819733,\n",
       "  0.12678706645965576,\n",
       "  0.9411628842353821,\n",
       "  0.20569440722465515,\n",
       "  0.28396522998809814,\n",
       "  0.4080369472503662,\n",
       "  0.16623550653457642,\n",
       "  -0.6009697318077087,\n",
       "  -0.2444164752960205,\n",
       "  -0.6985670924186707,\n",
       "  -0.30167582631111145,\n",
       "  0.3488301634788513,\n",
       "  0.5472827553749084,\n",
       "  -0.832493782043457,\n",
       "  -1.0591480731964111,\n",
       "  -0.5625573992729187,\n",
       "  -0.16140571236610413,\n",
       "  -0.27229851484298706,\n",
       "  0.1186848059296608,\n",
       "  -0.2976513206958771,\n",
       "  0.16891314089298248,\n",
       "  -0.2594355344772339,\n",
       "  -0.15998870134353638,\n",
       "  0.38046014308929443,\n",
       "  -0.5161330103874207,\n",
       "  0.25898638367652893,\n",
       "  -0.30155983567237854,\n",
       "  0.17131763696670532,\n",
       "  -0.610597550868988,\n",
       "  0.4848669767379761,\n",
       "  4.282114505767822,\n",
       "  0.02856253646314144,\n",
       "  0.3083154559135437,\n",
       "  -0.7818760871887207,\n",
       "  0.6364359259605408,\n",
       "  0.3853375017642975,\n",
       "  0.20759877562522888,\n",
       "  0.1842038780450821,\n",
       "  -0.12745338678359985,\n",
       "  0.295379638671875,\n",
       "  0.9977033138275146,\n",
       "  -0.278652161359787,\n",
       "  1.1138490438461304,\n",
       "  -0.1584678292274475,\n",
       "  0.8373649716377258,\n",
       "  0.6496362090110779,\n",
       "  -0.4430842995643616,\n",
       "  -0.03964841365814209,\n",
       "  -0.0343593955039978,\n",
       "  0.637825608253479,\n",
       "  -1.0807757377624512,\n",
       "  0.09277080744504929,\n",
       "  0.027446303516626358,\n",
       "  1.0266450643539429,\n",
       "  1.4436023235321045,\n",
       "  -0.04964977130293846,\n",
       "  -0.8132820129394531,\n",
       "  0.21042075753211975,\n",
       "  0.21635498106479645,\n",
       "  0.2764439284801483,\n",
       "  0.5843998193740845,\n",
       "  -0.23884667456150055,\n",
       "  -0.4805583953857422,\n",
       "  0.1652584671974182,\n",
       "  -1.0059633255004883,\n",
       "  0.5628934502601624,\n",
       "  -0.2904050648212433,\n",
       "  0.2445390224456787,\n",
       "  -1.2795701026916504,\n",
       "  0.4116893708705902,\n",
       "  -1.6316007375717163,\n",
       "  -0.07354224473237991,\n",
       "  -0.3387816846370697,\n",
       "  0.22121724486351013,\n",
       "  0.33849310874938965,\n",
       "  -1.0356004238128662,\n",
       "  -1.0640619993209839,\n",
       "  1.474707007408142,\n",
       "  0.014207720756530762,\n",
       "  0.29106491804122925,\n",
       "  0.3229520320892334,\n",
       "  -1.0731538534164429,\n",
       "  0.6252557635307312,\n",
       "  -0.06947313249111176,\n",
       "  -0.43303337693214417,\n",
       "  0.26533043384552,\n",
       "  -0.24107208847999573,\n",
       "  -1.1115645170211792,\n",
       "  -0.06759563088417053,\n",
       "  -1.2441926002502441,\n",
       "  0.10085190832614899,\n",
       "  0.5845062732696533,\n",
       "  0.12933719158172607,\n",
       "  -0.1047665998339653,\n",
       "  -0.548240065574646,\n",
       "  0.3766937255859375,\n",
       "  0.7373452186584473,\n",
       "  -0.3100318908691406,\n",
       "  1.1963554620742798,\n",
       "  -0.9059703350067139,\n",
       "  -0.03618757799267769,\n",
       "  -0.2329295426607132,\n",
       "  -0.35466626286506653,\n",
       "  -0.8051060438156128,\n",
       "  -0.7731622457504272,\n",
       "  0.2614363431930542,\n",
       "  0.13792236149311066,\n",
       "  0.43555206060409546,\n",
       "  0.39873620867729187,\n",
       "  0.5130748152732849,\n",
       "  -0.937010645866394,\n",
       "  -0.10920368880033493,\n",
       "  -0.7491679191589355,\n",
       "  0.5404341220855713,\n",
       "  0.2796788811683655,\n",
       "  -0.9160516262054443,\n",
       "  0.021059609949588776,\n",
       "  0.03282371908426285,\n",
       "  0.11705794930458069,\n",
       "  -0.9825853705406189,\n",
       "  0.5198724269866943,\n",
       "  -0.5599492788314819,\n",
       "  0.6012288331985474,\n",
       "  -0.3323553800582886,\n",
       "  -0.6340078711509705,\n",
       "  -0.6671193242073059,\n",
       "  1.0712391138076782,\n",
       "  -0.7573907971382141,\n",
       "  -0.35385027527809143,\n",
       "  -0.07278771698474884,\n",
       "  0.16018018126487732,\n",
       "  0.883374035358429,\n",
       "  0.7200080156326294,\n",
       "  -0.44197162985801697,\n",
       "  -0.5915689468383789,\n",
       "  -0.20922410488128662,\n",
       "  1.0566891431808472,\n",
       "  -0.6187981367111206,\n",
       "  -0.24334672093391418,\n",
       "  0.07053664326667786,\n",
       "  0.9398119449615479,\n",
       "  0.5801951289176941,\n",
       "  -1.1782113313674927,\n",
       "  -0.5253762006759644,\n",
       "  0.2647154927253723,\n",
       "  0.20717428624629974,\n",
       "  0.09337814152240753,\n",
       "  -0.7885358333587646,\n",
       "  0.2861891984939575,\n",
       "  1.2431472539901733,\n",
       "  -0.15669521689414978,\n",
       "  0.0663815438747406,\n",
       "  -0.5140975117683411,\n",
       "  0.8523958325386047,\n",
       "  -0.22340691089630127,\n",
       "  0.2688446342945099,\n",
       "  0.39845946431159973,\n",
       "  -0.1472364068031311,\n",
       "  0.13643866777420044,\n",
       "  1.0271320343017578,\n",
       "  0.660244345664978,\n",
       "  0.22335943579673767,\n",
       "  0.42566412687301636,\n",
       "  0.1464601755142212,\n",
       "  -0.44528916478157043,\n",
       "  -0.4379764199256897,\n",
       "  0.04790693521499634,\n",
       "  -0.8030663728713989,\n",
       "  -0.5078229904174805,\n",
       "  0.8105318546295166,\n",
       "  -0.7831065654754639,\n",
       "  -0.8266531825065613,\n",
       "  -0.24695038795471191,\n",
       "  -1.5271539688110352,\n",
       "  0.35157710313796997,\n",
       "  0.20722714066505432,\n",
       "  -0.5503189563751221,\n",
       "  -1.013304591178894,\n",
       "  0.3550163209438324,\n",
       "  0.6139614582061768,\n",
       "  1.2653298377990723,\n",
       "  0.026155343279242516,\n",
       "  0.4243495464324951,\n",
       "  0.08042774349451065,\n",
       "  -0.3511931896209717,\n",
       "  -0.4352383017539978,\n",
       "  0.8591681718826294,\n",
       "  -0.24482659995555878,\n",
       "  0.2691824436187744,\n",
       "  -1.3294144868850708,\n",
       "  0.9536230564117432,\n",
       "  -0.48720496892929077,\n",
       "  0.6524789929389954,\n",
       "  -1.8401650190353394,\n",
       "  1.3663569688796997,\n",
       "  0.1958991289138794,\n",
       "  -0.743607759475708,\n",
       "  0.26503416895866394,\n",
       "  0.29543203115463257,\n",
       "  0.08001500368118286,\n",
       "  0.4371069371700287,\n",
       "  0.5395896434783936,\n",
       "  1.4110411405563354,\n",
       "  0.2667922079563141,\n",
       "  -0.4686458706855774,\n",
       "  -0.24043592810630798,\n",
       "  0.24535788595676422,\n",
       "  0.6678487658500671,\n",
       "  -0.8474165797233582,\n",
       "  -0.9079629778862,\n",
       "  0.1629919707775116,\n",
       "  -0.7293888926506042,\n",
       "  -0.44138017296791077,\n",
       "  -0.0178049486130476,\n",
       "  -1.0267850160598755,\n",
       "  -0.004083525389432907,\n",
       "  0.17701967060565948,\n",
       "  0.3923996090888977,\n",
       "  1.3039873838424683,\n",
       "  -0.38561347126960754,\n",
       "  0.48405709862709045,\n",
       "  2.6631572246551514,\n",
       "  0.32467398047447205,\n",
       "  -0.44876745343208313,\n",
       "  0.3453965187072754,\n",
       "  -1.573259949684143,\n",
       "  0.3113430142402649,\n",
       "  -0.2597573399543762,\n",
       "  -0.19789257645606995,\n",
       "  -0.34403690695762634,\n",
       "  -0.39535027742385864,\n",
       "  -0.29220741987228394,\n",
       "  0.29338815808296204,\n",
       "  -0.3486540615558624,\n",
       "  -0.9185724258422852,\n",
       "  -0.5257797241210938,\n",
       "  -0.8929550647735596,\n",
       "  -0.1748628318309784,\n",
       "  0.3229857087135315,\n",
       "  -0.17589795589447021,\n",
       "  -0.29534515738487244,\n",
       "  -0.08642847090959549,\n",
       "  -0.6951135993003845,\n",
       "  -0.5466284155845642,\n",
       "  -0.5484750270843506,\n",
       "  -0.266277015209198,\n",
       "  -0.7430201172828674,\n",
       "  -0.8472917079925537,\n",
       "  -0.3357376754283905,\n",
       "  -0.2830771207809448,\n",
       "  -0.665255069732666,\n",
       "  -0.2188366800546646,\n",
       "  0.8880307674407959,\n",
       "  -0.1539306789636612,\n",
       "  -0.6076106429100037,\n",
       "  -0.003951421473175287,\n",
       "  -0.4932085871696472,\n",
       "  0.23340201377868652,\n",
       "  0.1055436059832573,\n",
       "  -0.014390096068382263,\n",
       "  -1.1175187826156616,\n",
       "  0.21608474850654602,\n",
       "  -0.06132081151008606,\n",
       "  0.12640729546546936,\n",
       "  -0.7395039796829224,\n",
       "  0.614001452922821,\n",
       "  -0.5076892375946045,\n",
       "  0.06776086986064911,\n",
       "  -0.28075265884399414,\n",
       "  0.49439942836761475,\n",
       "  0.2437467873096466,\n",
       "  -0.2941382825374603,\n",
       "  0.8821576237678528,\n",
       "  0.8531175255775452,\n",
       "  0.356637567281723,\n",
       "  0.30220186710357666,\n",
       "  -0.45326942205429077,\n",
       "  -0.15429624915122986,\n",
       "  0.19775213301181793,\n",
       "  -0.4277159571647644,\n",
       "  0.7057393193244934,\n",
       "  0.5062514543533325,\n",
       "  0.8807631731033325,\n",
       "  0.21121647953987122,\n",
       "  -0.40372681617736816,\n",
       "  0.10763733088970184,\n",
       "  0.0750497505068779,\n",
       "  -0.9446396231651306,\n",
       "  -0.2454497516155243,\n",
       "  -0.7266937494277954,\n",
       "  -0.8168723583221436,\n",
       "  0.1739603728055954,\n",
       "  -0.11882849037647247,\n",
       "  -0.8527023196220398,\n",
       "  0.29454469680786133,\n",
       "  0.5618753433227539,\n",
       "  0.6535902619361877,\n",
       "  -0.806208610534668,\n",
       "  0.0699109137058258,\n",
       "  0.4101719558238983,\n",
       "  0.10015406459569931,\n",
       "  0.3252992033958435,\n",
       "  0.5561956763267517,\n",
       "  0.06067539006471634,\n",
       "  -0.5685184597969055,\n",
       "  0.23652583360671997,\n",
       "  0.08302675932645798,\n",
       "  0.3315936326980591,\n",
       "  0.1512337028980255,\n",
       "  0.8083544969558716,\n",
       "  0.20200583338737488,\n",
       "  0.10205234587192535,\n",
       "  -0.29626691341400146,\n",
       "  0.45285093784332275,\n",
       "  1.2385599613189697,\n",
       "  0.26306232810020447,\n",
       "  0.22072377800941467,\n",
       "  0.3380759060382843,\n",
       "  0.375476598739624,\n",
       "  -0.15495625138282776,\n",
       "  -0.15548095107078552,\n",
       "  -0.12633931636810303,\n",
       "  0.09718189388513565,\n",
       "  -1.4196683168411255,\n",
       "  0.4520779252052307,\n",
       "  -0.7821336388587952,\n",
       "  0.25577205419540405,\n",
       "  0.6924266219139099,\n",
       "  0.08256836235523224,\n",
       "  -0.45326048135757446,\n",
       "  0.9638402462005615,\n",
       "  -0.6720045804977417,\n",
       "  -0.4865664541721344,\n",
       "  -0.6850411891937256,\n",
       "  -0.5974511504173279,\n",
       "  -0.339423805475235,\n",
       "  0.4137343466281891,\n",
       "  -0.41720426082611084,\n",
       "  -0.30693069100379944,\n",
       "  0.261432409286499,\n",
       "  -0.9115179777145386,\n",
       "  -0.8839336633682251,\n",
       "  -0.003666874021291733,\n",
       "  -0.13276717066764832,\n",
       "  -0.528918445110321,\n",
       "  -0.40136227011680603,\n",
       "  1.1604714393615723,\n",
       "  -0.07143961638212204,\n",
       "  -0.18300841748714447,\n",
       "  -0.33758124709129333,\n",
       "  0.23183995485305786,\n",
       "  0.0029161758720874786,\n",
       "  -0.6145302057266235,\n",
       "  -0.013988174498081207,\n",
       "  0.25835615396499634,\n",
       "  -0.9213484525680542,\n",
       "  0.8312129378318787,\n",
       "  -0.4230627417564392,\n",
       "  0.3689846694469452,\n",
       "  -0.5837460160255432,\n",
       "  0.24971120059490204,\n",
       "  0.034749578684568405,\n",
       "  -0.49389544129371643,\n",
       "  0.9643048644065857,\n",
       "  -0.22038905322551727,\n",
       "  0.4877050518989563,\n",
       "  -0.2648436725139618,\n",
       "  -0.42031487822532654,\n",
       "  0.11353036761283875,\n",
       "  -0.5935594439506531,\n",
       "  0.10108065605163574,\n",
       "  2.9244894981384277,\n",
       "  -1.0364066362380981,\n",
       "  -0.6201778054237366,\n",
       "  0.12172900885343552,\n",
       "  -0.4160168468952179,\n",
       "  -0.5719836950302124,\n",
       "  -0.45573538541793823,\n",
       "  -0.3297232985496521,\n",
       "  0.35722652077674866,\n",
       "  -0.12375004589557648,\n",
       "  -0.5453096032142639,\n",
       "  -0.09739653766155243,\n",
       "  -0.24507832527160645,\n",
       "  -0.41680556535720825,\n",
       "  0.2964765727519989,\n",
       "  -0.3635806441307068,\n",
       "  -0.13051429390907288,\n",
       "  0.49752041697502136,\n",
       "  0.4783852696418762,\n",
       "  -1.0080891847610474,\n",
       "  0.5987672209739685,\n",
       "  -1.0554412603378296,\n",
       "  0.5019717216491699,\n",
       "  0.5331138968467712,\n",
       "  0.49271729588508606,\n",
       "  1.2407965660095215,\n",
       "  -0.5975744724273682,\n",
       "  -0.016075581312179565,\n",
       "  0.4506988823413849,\n",
       "  -0.0011326968669891357,\n",
       "  -0.7435451149940491,\n",
       "  0.6518589854240417,\n",
       "  -0.31493398547172546,\n",
       "  0.06699123978614807,\n",
       "  -0.3216995596885681,\n",
       "  0.1444035768508911,\n",
       "  -0.39015331864356995,\n",
       "  -0.0727311223745346,\n",
       "  0.49043527245521545,\n",
       "  0.1061471700668335,\n",
       "  1.0559509992599487,\n",
       "  -0.323696106672287,\n",
       "  0.9293591380119324,\n",
       "  -0.6744362115859985,\n",
       "  1.3252027034759521,\n",
       "  0.3817467987537384,\n",
       "  0.8646162748336792,\n",
       "  1.5901001691818237,\n",
       "  -1.0070645809173584,\n",
       "  0.2849081754684448,\n",
       "  0.6248517036437988,\n",
       "  0.24473482370376587,\n",
       "  -0.01811252534389496,\n",
       "  -0.37890559434890747,\n",
       "  0.5467057824134827,\n",
       "  -0.1349496841430664,\n",
       "  -0.8153740167617798,\n",
       "  -0.4114840030670166,\n",
       "  0.028218120336532593,\n",
       "  -0.5256627798080444,\n",
       "  -0.27606201171875,\n",
       "  -0.15540280938148499,\n",
       "  0.16688479483127594,\n",
       "  -0.0756547823548317,\n",
       "  0.34848180413246155,\n",
       "  -1.0037106275558472,\n",
       "  1.1598325967788696,\n",
       "  -0.3023877739906311,\n",
       "  -1.1258480548858643,\n",
       "  -0.09658212214708328,\n",
       "  -0.8536214232444763,\n",
       "  0.30581986904144287,\n",
       "  -0.669428288936615,\n",
       "  0.2401140183210373,\n",
       "  0.7465099096298218,\n",
       "  -0.5307685136795044,\n",
       "  -0.17231455445289612,\n",
       "  0.6234670281410217,\n",
       "  0.5696824193000793,\n",
       "  -0.4053250551223755,\n",
       "  -0.10405412316322327,\n",
       "  0.18287070095539093,\n",
       "  -0.17690853774547577,\n",
       "  -1.0516568422317505,\n",
       "  0.8398142457008362,\n",
       "  -0.08873729407787323,\n",
       "  0.5262771844863892,\n",
       "  -0.3681975305080414,\n",
       "  -0.06479905545711517,\n",
       "  0.7528418302536011,\n",
       "  0.5327396988868713,\n",
       "  0.6175398230552673,\n",
       "  -0.017656348645687103,\n",
       "  -0.702060878276825,\n",
       "  0.31189948320388794,\n",
       "  -0.1725182831287384,\n",
       "  0.2846231758594513,\n",
       "  0.503352165222168,\n",
       "  0.4976852238178253,\n",
       "  0.5146524906158447,\n",
       "  0.208304762840271,\n",
       "  0.1412694901227951,\n",
       "  0.47756287455558777,\n",
       "  -0.5289222598075867,\n",
       "  0.3491041362285614,\n",
       "  0.17730218172073364,\n",
       "  0.4308933615684509,\n",
       "  -0.3531426787376404,\n",
       "  0.1122465431690216,\n",
       "  0.39045822620391846,\n",
       "  0.44666311144828796,\n",
       "  -0.6423218846321106,\n",
       "  0.4735361635684967,\n",
       "  -0.005238264799118042,\n",
       "  0.2639751732349396,\n",
       "  0.7044358849525452,\n",
       "  1.3386567831039429,\n",
       "  0.1892034113407135,\n",
       "  -5.1187334060668945,\n",
       "  -0.2802905738353729,\n",
       "  0.5704172253608704,\n",
       "  -0.6658915877342224,\n",
       "  0.11005019396543503,\n",
       "  -0.3926388621330261,\n",
       "  0.08487461507320404,\n",
       "  -0.21781137585639954,\n",
       "  -0.6406549215316772,\n",
       "  -0.5807806849479675,\n",
       "  0.3028171956539154,\n",
       "  -0.33297932147979736,\n",
       "  -1.4365122318267822,\n",
       "  0.5919943451881409,\n",
       "  0.02747342549264431,\n",
       "  0.4858914017677307,\n",
       "  0.46589112281799316,\n",
       "  -1.4947746992111206,\n",
       "  -1.1334160566329956,\n",
       "  0.18918076157569885,\n",
       "  -0.2520759701728821,\n",
       "  -0.22796840965747833,\n",
       "  -0.04190567880868912,\n",
       "  0.13170132040977478,\n",
       "  0.42469996213912964,\n",
       "  0.5955138802528381,\n",
       "  0.20242787897586823,\n",
       "  -1.152153730392456,\n",
       "  -0.9290999174118042,\n",
       "  -0.5344143509864807,\n",
       "  -0.057835523039102554,\n",
       "  -0.00656433030962944,\n",
       "  -0.32322949171066284,\n",
       "  -1.2178276777267456,\n",
       "  -0.010938637889921665,\n",
       "  -0.42344602942466736,\n",
       "  0.6793654561042786,\n",
       "  -0.11731598526239395,\n",
       "  0.707410991191864,\n",
       "  -1.5162239074707031,\n",
       "  -0.1688016802072525,\n",
       "  0.06166587769985199,\n",
       "  0.44226446747779846,\n",
       "  0.7812404632568359,\n",
       "  -0.1404929757118225,\n",
       "  -1.0472403764724731,\n",
       "  0.3726389706134796,\n",
       "  -1.2813212871551514,\n",
       "  0.8554126620292664,\n",
       "  -0.19818343222141266,\n",
       "  1.985427975654602,\n",
       "  -0.20694561302661896,\n",
       "  -0.3350623548030853,\n",
       "  -0.7285792827606201,\n",
       "  0.009923338890075684,\n",
       "  -0.07739480584859848,\n",
       "  0.623576283454895,\n",
       "  0.8210734724998474,\n",
       "  0.21959136426448822,\n",
       "  -0.1726721078157425,\n",
       "  -0.768150806427002,\n",
       "  0.533028781414032,\n",
       "  -0.03190094232559204,\n",
       "  0.1835547387599945,\n",
       "  -0.2777918875217438,\n",
       "  1.0132797956466675,\n",
       "  -0.17393812537193298,\n",
       "  -0.20116060972213745,\n",
       "  0.2648809254169464,\n",
       "  -0.4183659255504608,\n",
       "  -0.6099915504455566,\n",
       "  -0.09401607513427734,\n",
       "  -0.312875896692276,\n",
       "  0.616475522518158,\n",
       "  -0.1109623908996582,\n",
       "  -1.1401156187057495,\n",
       "  -0.3200076222419739,\n",
       "  -0.18736502528190613,\n",
       "  0.316556841135025,\n",
       "  -0.14620190858840942,\n",
       "  -0.7090320587158203,\n",
       "  -0.14163854718208313,\n",
       "  0.7744441032409668,\n",
       "  0.3420192003250122,\n",
       "  -0.4378485381603241,\n",
       "  -0.1478443145751953,\n",
       "  -1.5177887678146362,\n",
       "  0.4279709458351135,\n",
       "  0.1269213706254959,\n",
       "  0.7464088201522827,\n",
       "  -0.15988445281982422,\n",
       "  0.1776764690876007,\n",
       "  -0.6736024618148804,\n",
       "  0.5981425642967224,\n",
       "  -0.3815162777900696,\n",
       "  1.0513951778411865,\n",
       "  -0.05363510549068451,\n",
       "  0.32001444697380066,\n",
       "  -0.420204222202301,\n",
       "  0.45040208101272583,\n",
       "  -0.44995221495628357,\n",
       "  0.47855597734451294,\n",
       "  -0.5770126581192017,\n",
       "  0.07612475752830505,\n",
       "  0.8437450528144836,\n",
       "  0.11906471103429794,\n",
       "  2.482593059539795,\n",
       "  -0.4314247667789459,\n",
       "  -0.7141699194908142,\n",
       "  0.8002942204475403,\n",
       "  0.29123950004577637,\n",
       "  0.6032019853591919,\n",
       "  -0.8436142802238464,\n",
       "  1.0552576780319214,\n",
       "  0.7440494894981384,\n",
       "  -0.03196564316749573,\n",
       "  -0.3952881693840027,\n",
       "  -0.11742829531431198,\n",
       "  0.48424994945526123,\n",
       "  0.707356870174408,\n",
       "  -0.2081030011177063,\n",
       "  -0.4323160648345947,\n",
       "  0.42789754271507263,\n",
       "  -0.29158642888069153,\n",
       "  0.3253275752067566,\n",
       "  0.3272192180156708,\n",
       "  0.26311206817626953,\n",
       "  -1.6021960973739624,\n",
       "  0.2893352508544922,\n",
       "  -1.1299208402633667,\n",
       "  0.4510824680328369,\n",
       "  -0.25622087717056274,\n",
       "  -0.31849634647369385,\n",
       "  0.010174494236707687,\n",
       "  -0.5744556188583374,\n",
       "  -0.46226993203163147,\n",
       "  0.07701548933982849,\n",
       "  -0.14324970543384552,\n",
       "  -0.5461023449897766,\n",
       "  1.899539589881897,\n",
       "  -0.5319087505340576,\n",
       "  1.1645642518997192,\n",
       "  -0.03703124448657036,\n",
       "  -0.7420564293861389,\n",
       "  0.8149370551109314,\n",
       "  0.19326403737068176,\n",
       "  0.10473877936601639,\n",
       "  -0.7804917693138123,\n",
       "  -1.1981713771820068,\n",
       "  0.23124346137046814,\n",
       "  -0.5025481581687927,\n",
       "  -0.030638262629508972,\n",
       "  -0.5151250958442688,\n",
       "  -0.6329156160354614,\n",
       "  1.1529018878936768,\n",
       "  -0.3299287259578705,\n",
       "  0.38985952734947205,\n",
       "  0.0977943018078804,\n",
       "  -0.5914117693901062,\n",
       "  1.7792489528656006,\n",
       "  1.1428217887878418,\n",
       "  0.6274932026863098,\n",
       "  0.9697943925857544,\n",
       "  -0.176686629652977,\n",
       "  -0.4999571144580841,\n",
       "  -0.23148271441459656,\n",
       "  -1.4594571590423584,\n",
       "  -0.029115214943885803,\n",
       "  -0.21233411133289337,\n",
       "  0.8401691913604736,\n",
       "  -0.33904844522476196,\n",
       "  -0.993118166923523,\n",
       "  0.03526660054922104,\n",
       "  0.11491888761520386,\n",
       "  -0.7683132290840149,\n",
       "  -1.340542197227478,\n",
       "  -0.2736678719520569,\n",
       "  0.1265931874513626,\n",
       "  -1.3363491296768188,\n",
       "  0.19215409457683563,\n",
       "  0.08453962206840515,\n",
       "  0.7881649136543274,\n",
       "  -0.6722521185874939,\n",
       "  -0.4371601343154907,\n",
       "  0.6491544246673584,\n",
       "  -0.4928474426269531,\n",
       "  0.2619180679321289,\n",
       "  0.4868338108062744,\n",
       "  1.105341911315918,\n",
       "  0.1306888461112976,\n",
       "  0.04267241805791855,\n",
       "  -0.08650246262550354,\n",
       "  -0.7427990436553955,\n",
       "  -0.7342424988746643,\n",
       "  -0.26144757866859436,\n",
       "  -0.13026675581932068,\n",
       "  -0.2657982110977173,\n",
       "  0.41216498613357544,\n",
       "  -0.8568971157073975,\n",
       "  0.8738709092140198,\n",
       "  -0.3610984981060028,\n",
       "  0.6834150552749634,\n",
       "  0.7616091370582581,\n",
       "  0.020362593233585358,\n",
       "  -0.2504279315471649,\n",
       "  -0.25209930539131165,\n",
       "  0.02184072695672512,\n",
       "  0.987784743309021,\n",
       "  -0.3602578043937683,\n",
       "  0.7540001273155212,\n",
       "  0.3443681299686432]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.embed([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cached data:\n",
    "# wrapper.embeddings_training\n",
    "# wrapper.embeddings_testing\n",
    "# wrapper.projector\n",
    "# wrapper.projections_training\n",
    "# wrapper.projections_testing\n",
    "# wrapper.salience_maps\n",
    "# wrapper.clusters\n",
    "# wrapper.cluster_profiles\n",
    "# wrapper.cluster_words_freqs\n",
    "# wrapper.cluster_class_word_sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

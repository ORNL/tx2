{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1 - Default Approach\n",
    "\n",
    "This notebook demonstrates how to use the TX2 dashboard with a sequence classification transformer using the default approach as described in the \"Basic Usage\" docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -q ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We enable logging to view the output from `wrapper.prepare()` further down in the notebook. (It's a long running function, and logs which step it's on.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "# import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import cuda\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example notebook, we use the 20 newsgroups dataset, which can be downloaded through sklearn via below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "train_data = fetch_20newsgroups(subset='train')\n",
    "test_data = fetch_20newsgroups(subset='test')\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Defined below is a simple sequence classification model with a variable for the language model itself `l1`. Since it is a BERT model, we take the sequence embedding from the `[CLS]` token (via `output_1[0][:, 0, :])`) and pipe that into the linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "        self.l2 = torch.nn.Linear(768, 20)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        output_1= self.l1(ids, mask)\n",
    "        output = self.l2(output_1[0][:, 0, :]) # use just the [CLS] output embedding\n",
    "        return output\n",
    "    \n",
    "model = BERTClass()\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some simplistic data cleaning, and putting all data into dataframes for the wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text[text.index(\"\\n\\n\")+2:]\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"    \", \" \")\n",
    "    text = text.replace(\"   \", \" \")\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_rows = []\n",
    "for i in range(len(train_data[\"data\"])):\n",
    "    row = {}\n",
    "    row[\"text\"] = clean_text(train_data[\"data\"][i])\n",
    "    row[\"target\"] = train_data['target'][i]\n",
    "    if row[\"text\"] == \"\" or row[\"text\"] == \" \": continue\n",
    "    train_rows.append(row)\n",
    "train_df = pd.DataFrame(train_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rows = []\n",
    "for i in range(len(test_data[\"data\"])):\n",
    "    row = {}\n",
    "    row[\"text\"] = clean_text(test_data[\"data\"][i])\n",
    "    row[\"target\"] = test_data['target'][i]\n",
    "    if row[\"text\"] == \"\" or row[\"text\"] == \" \": continue\n",
    "    test_rows.append(row)\n",
    "test_df = pd.DataFrame(test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "This section minimally trains the classification and language model - nothing fancy here, just to give the dashboard demo something to work with. Most of this is similar to the huggingface tutorial notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11296\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "class EncodedSet(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        print(self.len)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.data.text[index])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.target[index], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "train_set = EncodedSet(train_df, tokenizer, 256)\n",
    "test_set = EncodedSet(test_df[:1000], tokenizer, 256)\n",
    "\n",
    "train_params = {'batch_size': 16,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': 2,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "# put everything into data loaders\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "    loss_history = []\n",
    "    for _,data in tqdm(enumerate(train_loader, 0), total=len(train_loader), desc=f\"Epoch {epoch}\"):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask).squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, targets)\n",
    "        if _%100==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         torch.cuda.empty_cache()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34245696ebef43588de8c3327121752c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch 0'), FloatProgress(value=0.0, max=706.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  3.024453639984131\n",
      "Epoch: 0, Loss:  1.8459928035736084\n",
      "Epoch: 0, Loss:  1.296995997428894\n",
      "Epoch: 0, Loss:  0.9327334761619568\n",
      "Epoch: 0, Loss:  0.8128281831741333\n",
      "Epoch: 0, Loss:  0.4568077325820923\n",
      "Epoch: 0, Loss:  0.41762369871139526\n",
      "Epoch: 0, Loss:  0.7839687466621399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(1):\n",
    "    losses.extend(train(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapper uses an `encodings` dictionary for various labels/visualizations, and can be set up with something similar to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism': 0,\n",
       " 'comp.graphics': 1,\n",
       " 'comp.os.ms-windows.misc': 2,\n",
       " 'comp.sys.ibm.pc.hardware': 3,\n",
       " 'comp.sys.mac.hardware': 4,\n",
       " 'comp.windows.x': 5,\n",
       " 'misc.forsale': 6,\n",
       " 'rec.autos': 7,\n",
       " 'rec.motorcycles': 8,\n",
       " 'rec.sport.baseball': 9,\n",
       " 'rec.sport.hockey': 10,\n",
       " 'sci.crypt': 11,\n",
       " 'sci.electronics': 12,\n",
       " 'sci.med': 13,\n",
       " 'sci.space': 14,\n",
       " 'soc.religion.christian': 15,\n",
       " 'talk.politics.guns': 16,\n",
       " 'talk.politics.mideast': 17,\n",
       " 'talk.politics.misc': 18,\n",
       " 'talk.religion.misc': 19}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = {}\n",
    "for index, entry in enumerate(train_data[\"target_names\"]):\n",
    "    encodings[entry] = index\n",
    "encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TX2\n",
    "\n",
    "This section shows how to put everything into the TX2 wrapper to get the dashboard widget displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tx2.wrapper import Wrapper\n",
    "from tx2.dashboard import Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Cache path found\n",
      "INFO:root:Checking for cached predictions...\n",
      "INFO:root:Running classifier...\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "INFO:root:Saving predictions...\n",
      "INFO:root:Writing to data/predictions.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached embeddings...\n",
      "INFO:root:Embedding training and testing datasets\n",
      "INFO:root:Saving embeddings...\n",
      "INFO:root:Writing to data/embedding_training.json\n",
      "INFO:root:Writing to data/embedding_testing.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached projections...\n",
      "INFO:root:Training projector...\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n",
      "INFO:root:Applying projector to test dataset...\n",
      "INFO:root:Saving projections...\n",
      "INFO:root:Writing to data/projections_training.json\n",
      "INFO:root:Writing to data/projections_testing.json\n",
      "INFO:root:Writing to data/projector.pkl.gz\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached salience maps...\n",
      "INFO:root:Computing salience maps...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddb0c6e382ef4679a8ebebf9a5af1288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "INFO:root:Saving salience maps...\n",
      "INFO:root:Writing to data/salience.pkl.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached cluster profiles...\n",
      "INFO:root:Clustering projections...\n",
      "INFO:root:Saving cluster profiles...\n",
      "INFO:root:Writing to data/clusters.json\n",
      "INFO:root:Writing to data/cluster_profiles.pkl.gz\n",
      "INFO:root:Done!\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "INFO:root:Saving cluster labels...\n",
      "INFO:root:Writing to data/cluster_labels.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Saving cluster word counts...\n",
      "INFO:root:Writing to data/cluster_words.json\n",
      "INFO:root:Writing to data/cluster_class_words.json\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "wrapper = Wrapper(\n",
    "    train_df=train_df, \n",
    "    test_df=test_df[:2000], \n",
    "    encodings=encodings, \n",
    "    input_col_name=\"text\", \n",
    "    target_col_name=\"target\", \n",
    "    classifier=model, \n",
    "    language_model=model.l1, \n",
    "    tokenizer=tokenizer,\n",
    "    overwrite=True\n",
    ")\n",
    "wrapper.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838f814453ed44358dfa16bae0040ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>UMAP Embedding Graph</h3>'), HBox(children=(Output(), VBox(child…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "import matplotlib.pyplot as plt\n",
    "dash = Dashboard(wrapper)\n",
    "dash.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To play with different UMAP and DBSCAN arguments without having to recompute the entire `prepare()` function, you can use `recompute_projections` (which will recompute both the projections and visual clusterings) or `recompute_visual_clusterings` (which will only redo the clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper.recompute_visual_clusterings(\"KMeans\", clustering_args=dict(n_clusters=18))\n",
    "# wrapper.recompute_visual_clusterings(\"OPTICS\", clustering_args=dict())\n",
    "# wrapper.recompute_projections(umap_args=dict(min_dist=.2), dbscan_args=dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test or debug the classification model/see what raw outputs the viusualizations are getting, or create your own visualization tools, you can manually call the `classify()`, `soft_classify()`, `embed()` functions, or get access to any of the cached data as seen in the bottom cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.1467856168746948,\n",
       "  0.10263477265834808,\n",
       "  -0.0855865553021431,\n",
       "  -0.517762303352356,\n",
       "  0.6577524542808533,\n",
       "  -0.7899132966995239,\n",
       "  1.7592031955718994,\n",
       "  2.2232558727264404,\n",
       "  1.2816895246505737,\n",
       "  -0.9080365300178528,\n",
       "  -0.2610422372817993,\n",
       "  -0.8389397263526917,\n",
       "  1.399346947669983,\n",
       "  -0.4710550904273987,\n",
       "  0.5613362789154053,\n",
       "  -0.6309848427772522,\n",
       "  -0.03432488813996315,\n",
       "  -0.44631820917129517,\n",
       "  -0.4614395499229431,\n",
       "  -1.2576179504394531]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.soft_classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6442223787307739,\n",
       "  0.5272770524024963,\n",
       "  0.5174990892410278,\n",
       "  0.1452854424715042,\n",
       "  -0.6251925826072693,\n",
       "  0.47028040885925293,\n",
       "  -0.11281606554985046,\n",
       "  0.0495697557926178,\n",
       "  -0.2050808072090149,\n",
       "  -1.4842872619628906,\n",
       "  -0.7153332829475403,\n",
       "  0.5572931170463562,\n",
       "  -0.3223772644996643,\n",
       "  1.3300362825393677,\n",
       "  -0.631582498550415,\n",
       "  -0.20691530406475067,\n",
       "  0.30130264163017273,\n",
       "  0.29122862219810486,\n",
       "  0.6335329413414001,\n",
       "  0.2613733112812042,\n",
       "  -0.125350221991539,\n",
       "  -0.18150776624679565,\n",
       "  0.5325058698654175,\n",
       "  -0.7309507131576538,\n",
       "  -0.9613048434257507,\n",
       "  -1.0169148445129395,\n",
       "  -0.007540167775005102,\n",
       "  0.6323205828666687,\n",
       "  0.8848828673362732,\n",
       "  -0.721879780292511,\n",
       "  -0.613106906414032,\n",
       "  1.1132451295852661,\n",
       "  -0.23794245719909668,\n",
       "  0.4406245946884155,\n",
       "  0.13005083799362183,\n",
       "  0.09354928880929947,\n",
       "  0.9109054207801819,\n",
       "  0.9978392720222473,\n",
       "  -0.028482912108302116,\n",
       "  0.5141044855117798,\n",
       "  0.6985797882080078,\n",
       "  -0.6424423456192017,\n",
       "  -0.13114303350448608,\n",
       "  0.09262330085039139,\n",
       "  -0.3110906779766083,\n",
       "  0.5458361506462097,\n",
       "  0.10661135613918304,\n",
       "  -1.814909815788269,\n",
       "  -0.059832554310560226,\n",
       "  0.03779563680291176,\n",
       "  -0.1075839027762413,\n",
       "  0.11371773481369019,\n",
       "  1.1801093816757202,\n",
       "  1.2352595329284668,\n",
       "  -0.034164853394031525,\n",
       "  0.04752243310213089,\n",
       "  -1.138902187347412,\n",
       "  0.807319700717926,\n",
       "  -0.2760551869869232,\n",
       "  0.6003335118293762,\n",
       "  -0.12163454294204712,\n",
       "  -0.5056201815605164,\n",
       "  -1.185613751411438,\n",
       "  1.294834017753601,\n",
       "  0.6243889927864075,\n",
       "  -0.020818091928958893,\n",
       "  1.1943669319152832,\n",
       "  -1.3177928924560547,\n",
       "  0.5180186033248901,\n",
       "  -0.6668258309364319,\n",
       "  1.0030848979949951,\n",
       "  0.7661738991737366,\n",
       "  -0.10816548019647598,\n",
       "  0.4434041380882263,\n",
       "  0.8261352181434631,\n",
       "  0.08772501349449158,\n",
       "  -0.551997721195221,\n",
       "  -0.20856498181819916,\n",
       "  -0.6060886383056641,\n",
       "  0.3822774589061737,\n",
       "  0.8219532370567322,\n",
       "  -0.22569763660430908,\n",
       "  -1.1313843727111816,\n",
       "  0.44902634620666504,\n",
       "  0.9927670359611511,\n",
       "  0.6857467889785767,\n",
       "  0.23209047317504883,\n",
       "  -0.026983628049492836,\n",
       "  0.13247910141944885,\n",
       "  -0.49607014656066895,\n",
       "  -0.107235386967659,\n",
       "  -0.11013605445623398,\n",
       "  -0.9021209478378296,\n",
       "  0.22701150178909302,\n",
       "  0.4215598702430725,\n",
       "  -1.1146875619888306,\n",
       "  -0.4149302542209625,\n",
       "  0.5076683759689331,\n",
       "  3.5316293239593506,\n",
       "  -0.44372308254241943,\n",
       "  0.23347845673561096,\n",
       "  -0.8857001662254333,\n",
       "  0.7422317266464233,\n",
       "  -0.29152169823646545,\n",
       "  0.4027479887008667,\n",
       "  0.203171506524086,\n",
       "  -0.05231144279241562,\n",
       "  0.15402080118656158,\n",
       "  0.09071910381317139,\n",
       "  -0.6820850372314453,\n",
       "  0.6798831820487976,\n",
       "  0.793561577796936,\n",
       "  1.1884371042251587,\n",
       "  0.35241642594337463,\n",
       "  -0.3568735122680664,\n",
       "  -0.611261248588562,\n",
       "  -0.2622424066066742,\n",
       "  -0.21458519995212555,\n",
       "  -0.941228985786438,\n",
       "  0.2330590784549713,\n",
       "  0.06207755580544472,\n",
       "  0.6225147843360901,\n",
       "  2.440272092819214,\n",
       "  -0.31231823563575745,\n",
       "  -0.9397153854370117,\n",
       "  0.02912776730954647,\n",
       "  -0.11109981685876846,\n",
       "  0.5413268804550171,\n",
       "  0.6598861217498779,\n",
       "  -0.42644429206848145,\n",
       "  -0.6040667295455933,\n",
       "  0.17884354293346405,\n",
       "  -1.2100293636322021,\n",
       "  1.3944684267044067,\n",
       "  0.20903411507606506,\n",
       "  0.21741072833538055,\n",
       "  -1.896873116493225,\n",
       "  -0.9497299790382385,\n",
       "  -1.3679969310760498,\n",
       "  -0.007924358360469341,\n",
       "  -0.6791979074478149,\n",
       "  -0.09611542522907257,\n",
       "  0.03886808082461357,\n",
       "  -0.8196547031402588,\n",
       "  -0.6000286936759949,\n",
       "  2.200234889984131,\n",
       "  0.06696692109107971,\n",
       "  0.1369335651397705,\n",
       "  0.9791948795318604,\n",
       "  -0.45114147663116455,\n",
       "  -0.20816665887832642,\n",
       "  0.4383714497089386,\n",
       "  -0.1172369047999382,\n",
       "  -0.18148170411586761,\n",
       "  0.7877936959266663,\n",
       "  -0.37017473578453064,\n",
       "  -0.10826543718576431,\n",
       "  0.016885027289390564,\n",
       "  0.2056790292263031,\n",
       "  0.731696605682373,\n",
       "  0.08052670210599899,\n",
       "  -0.6024026870727539,\n",
       "  -0.8301726579666138,\n",
       "  0.5229904651641846,\n",
       "  1.3884998559951782,\n",
       "  -0.15479329228401184,\n",
       "  0.9317473769187927,\n",
       "  -0.7849276661872864,\n",
       "  0.02004840224981308,\n",
       "  -0.0909041240811348,\n",
       "  0.028205547481775284,\n",
       "  -0.36067911982536316,\n",
       "  -0.2508499026298523,\n",
       "  0.45791128277778625,\n",
       "  -0.5646107196807861,\n",
       "  0.5738145112991333,\n",
       "  0.928717315196991,\n",
       "  0.19294734299182892,\n",
       "  -0.5908320546150208,\n",
       "  0.055262643843889236,\n",
       "  -1.2556651830673218,\n",
       "  0.26712772250175476,\n",
       "  -0.032546889036893845,\n",
       "  -1.1406899690628052,\n",
       "  0.7012975811958313,\n",
       "  0.36078035831451416,\n",
       "  0.13695383071899414,\n",
       "  -0.26105886697769165,\n",
       "  1.3646053075790405,\n",
       "  -0.14310035109519958,\n",
       "  0.8127425312995911,\n",
       "  -0.3113515079021454,\n",
       "  -0.671088457107544,\n",
       "  -1.0821447372436523,\n",
       "  0.9082791209220886,\n",
       "  -0.2738223671913147,\n",
       "  -0.4335639476776123,\n",
       "  0.024407951161265373,\n",
       "  -0.808210015296936,\n",
       "  0.18695589900016785,\n",
       "  -0.054370928555727005,\n",
       "  0.18032224476337433,\n",
       "  -0.7416344285011292,\n",
       "  -0.038188714534044266,\n",
       "  0.7066138982772827,\n",
       "  -0.5040982365608215,\n",
       "  -0.49095404148101807,\n",
       "  0.4482382833957672,\n",
       "  0.6594018340110779,\n",
       "  0.12697938084602356,\n",
       "  -1.0049704313278198,\n",
       "  -0.11103232949972153,\n",
       "  0.7166714668273926,\n",
       "  0.49473175406455994,\n",
       "  -0.904757559299469,\n",
       "  -0.0005464968271553516,\n",
       "  0.2734466791152954,\n",
       "  0.9735432863235474,\n",
       "  0.3534949719905853,\n",
       "  0.00995532888919115,\n",
       "  -0.2429163008928299,\n",
       "  0.7286690473556519,\n",
       "  -0.9661068320274353,\n",
       "  -1.0796929597854614,\n",
       "  0.13006384670734406,\n",
       "  -0.32988297939300537,\n",
       "  0.3638930022716522,\n",
       "  0.32300126552581787,\n",
       "  -0.12869969010353088,\n",
       "  0.18974272906780243,\n",
       "  0.2546771764755249,\n",
       "  0.3101297914981842,\n",
       "  -0.6909493207931519,\n",
       "  -0.4634658694267273,\n",
       "  0.10921287536621094,\n",
       "  0.14757360517978668,\n",
       "  -0.9456568956375122,\n",
       "  0.18660852313041687,\n",
       "  -1.1365896463394165,\n",
       "  -1.1459994316101074,\n",
       "  -0.9479702115058899,\n",
       "  -0.7227487564086914,\n",
       "  -0.4771977663040161,\n",
       "  -0.0973948985338211,\n",
       "  -0.3660663962364197,\n",
       "  -0.04850691184401512,\n",
       "  0.8407264947891235,\n",
       "  0.47241073846817017,\n",
       "  1.3523614406585693,\n",
       "  0.02602509781718254,\n",
       "  0.9497327208518982,\n",
       "  0.12112961709499359,\n",
       "  -0.3426962196826935,\n",
       "  -0.36467793583869934,\n",
       "  0.5138802528381348,\n",
       "  -0.5078504681587219,\n",
       "  -0.7999711036682129,\n",
       "  -0.9431231617927551,\n",
       "  1.71736478805542,\n",
       "  -0.5955586433410645,\n",
       "  0.1074863001704216,\n",
       "  -2.750762939453125,\n",
       "  0.9108591079711914,\n",
       "  0.7659335136413574,\n",
       "  -0.7510921955108643,\n",
       "  -0.592379093170166,\n",
       "  -0.008292310871183872,\n",
       "  -0.09387413412332535,\n",
       "  0.915873110294342,\n",
       "  0.39122167229652405,\n",
       "  1.097987413406372,\n",
       "  0.33315643668174744,\n",
       "  -0.019341226667165756,\n",
       "  -0.29648783802986145,\n",
       "  1.273199439048767,\n",
       "  1.7513972520828247,\n",
       "  -0.21413032710552216,\n",
       "  -0.725227952003479,\n",
       "  0.39862126111984253,\n",
       "  -1.0453381538391113,\n",
       "  -0.1688234806060791,\n",
       "  -0.5771868824958801,\n",
       "  -1.161362648010254,\n",
       "  0.4832974374294281,\n",
       "  -0.42741671204566956,\n",
       "  0.23727445304393768,\n",
       "  1.1301895380020142,\n",
       "  -0.9869024157524109,\n",
       "  0.4115866720676422,\n",
       "  2.5880489349365234,\n",
       "  1.1127588748931885,\n",
       "  -0.4206337034702301,\n",
       "  -0.10128340125083923,\n",
       "  -0.6997855305671692,\n",
       "  -0.5188930630683899,\n",
       "  -0.05102649703621864,\n",
       "  -0.2303648591041565,\n",
       "  -1.0792306661605835,\n",
       "  -0.3703194558620453,\n",
       "  -0.12223206460475922,\n",
       "  0.6198743581771851,\n",
       "  -0.029445050284266472,\n",
       "  -0.5982032418251038,\n",
       "  0.15094202756881714,\n",
       "  -0.6824845671653748,\n",
       "  0.3215722441673279,\n",
       "  0.7921936511993408,\n",
       "  0.1796543002128601,\n",
       "  -0.5553330183029175,\n",
       "  -0.44178321957588196,\n",
       "  0.43293407559394836,\n",
       "  0.16172385215759277,\n",
       "  -0.5389161705970764,\n",
       "  -0.4693670868873596,\n",
       "  -0.5537382960319519,\n",
       "  -0.9048457741737366,\n",
       "  -0.17619240283966064,\n",
       "  -0.19775305688381195,\n",
       "  -1.57151460647583,\n",
       "  -0.03250129893422127,\n",
       "  0.32053664326667786,\n",
       "  0.444691002368927,\n",
       "  -0.9183549880981445,\n",
       "  -0.3513409495353699,\n",
       "  -0.7816749215126038,\n",
       "  -0.09553063660860062,\n",
       "  -0.5572178363800049,\n",
       "  -0.4902718663215637,\n",
       "  -0.9294980764389038,\n",
       "  -0.38756194710731506,\n",
       "  -0.4264164865016937,\n",
       "  -0.8162689208984375,\n",
       "  0.3075862526893616,\n",
       "  0.20481368899345398,\n",
       "  -0.012722943909466267,\n",
       "  0.783967912197113,\n",
       "  0.9416475296020508,\n",
       "  0.155770942568779,\n",
       "  -0.17915022373199463,\n",
       "  -0.055927034467458725,\n",
       "  1.3521301746368408,\n",
       "  0.683516800403595,\n",
       "  0.7132198214530945,\n",
       "  -0.9098610877990723,\n",
       "  -0.32817792892456055,\n",
       "  0.6293855905532837,\n",
       "  0.3804208040237427,\n",
       "  -0.9072960615158081,\n",
       "  -0.002997030271217227,\n",
       "  -0.002228979952633381,\n",
       "  0.8610918521881104,\n",
       "  -0.2823982238769531,\n",
       "  0.11909594386816025,\n",
       "  -0.17478403449058533,\n",
       "  0.606712818145752,\n",
       "  -0.18022093176841736,\n",
       "  -1.0563595294952393,\n",
       "  -0.29697686433792114,\n",
       "  -0.4216165244579315,\n",
       "  0.15893185138702393,\n",
       "  -0.09669137001037598,\n",
       "  -1.2249950170516968,\n",
       "  0.5448018908500671,\n",
       "  0.05884494259953499,\n",
       "  0.9215872883796692,\n",
       "  -0.2671624720096588,\n",
       "  1.197993278503418,\n",
       "  -0.10596435517072678,\n",
       "  -0.47450491786003113,\n",
       "  0.6253198385238647,\n",
       "  0.6675016283988953,\n",
       "  0.19642528891563416,\n",
       "  -0.2976926565170288,\n",
       "  0.7319687604904175,\n",
       "  0.917747974395752,\n",
       "  -0.0794195681810379,\n",
       "  0.583622932434082,\n",
       "  1.194432258605957,\n",
       "  -0.30098018050193787,\n",
       "  -0.7716295719146729,\n",
       "  -0.0543237179517746,\n",
       "  0.9260046482086182,\n",
       "  0.36870500445365906,\n",
       "  -0.5441519021987915,\n",
       "  0.07094218581914902,\n",
       "  0.09695450961589813,\n",
       "  0.5812699794769287,\n",
       "  -0.04993939399719238,\n",
       "  -0.30557766556739807,\n",
       "  0.034535232931375504,\n",
       "  1.46196711063385,\n",
       "  -0.6310383081436157,\n",
       "  0.7704393267631531,\n",
       "  -0.7468145489692688,\n",
       "  0.728536069393158,\n",
       "  -0.6558223962783813,\n",
       "  -0.195652037858963,\n",
       "  0.033684685826301575,\n",
       "  1.1172914505004883,\n",
       "  0.3822000026702881,\n",
       "  -1.3807363510131836,\n",
       "  -1.1030360460281372,\n",
       "  -1.0989409685134888,\n",
       "  -0.09849578887224197,\n",
       "  0.6476103067398071,\n",
       "  0.6808071136474609,\n",
       "  0.005944705102592707,\n",
       "  0.7897719740867615,\n",
       "  -0.9220189452171326,\n",
       "  -0.8500006794929504,\n",
       "  0.7506179213523865,\n",
       "  -0.20273245871067047,\n",
       "  -0.40152987837791443,\n",
       "  -0.2169194519519806,\n",
       "  1.1027735471725464,\n",
       "  -0.24628829956054688,\n",
       "  -0.03216749429702759,\n",
       "  -0.0335136353969574,\n",
       "  -0.12849798798561096,\n",
       "  -0.19086451828479767,\n",
       "  -0.9576085209846497,\n",
       "  -0.23946070671081543,\n",
       "  0.2644850015640259,\n",
       "  -0.8644396662712097,\n",
       "  0.3719765841960907,\n",
       "  -0.4449842870235443,\n",
       "  0.16528910398483276,\n",
       "  -0.8489787578582764,\n",
       "  0.48674723505973816,\n",
       "  -0.27434492111206055,\n",
       "  -0.3605539798736572,\n",
       "  0.8129286766052246,\n",
       "  0.4501646161079407,\n",
       "  -0.2807903289794922,\n",
       "  -0.2623158395290375,\n",
       "  -0.18861553072929382,\n",
       "  0.3044925332069397,\n",
       "  0.20458418130874634,\n",
       "  0.0030758981592953205,\n",
       "  1.985403299331665,\n",
       "  -0.31964847445487976,\n",
       "  -1.3344403505325317,\n",
       "  -0.6954230666160583,\n",
       "  -0.07380464673042297,\n",
       "  0.046312350779771805,\n",
       "  -0.30182933807373047,\n",
       "  -0.520477294921875,\n",
       "  0.22320613265037537,\n",
       "  -0.24949021637439728,\n",
       "  -0.9437673091888428,\n",
       "  0.8925955295562744,\n",
       "  0.10768843442201614,\n",
       "  -1.3563567399978638,\n",
       "  0.5435506701469421,\n",
       "  0.7725588083267212,\n",
       "  0.5291070342063904,\n",
       "  0.31031957268714905,\n",
       "  1.161251187324524,\n",
       "  -0.8125572800636292,\n",
       "  -0.17778891324996948,\n",
       "  -0.8622523546218872,\n",
       "  1.119123935699463,\n",
       "  -0.06903088092803955,\n",
       "  -0.0658857673406601,\n",
       "  1.0603278875350952,\n",
       "  -0.4962882399559021,\n",
       "  0.030175117775797844,\n",
       "  0.63840252161026,\n",
       "  -0.5540105700492859,\n",
       "  -1.3808966875076294,\n",
       "  0.4920780062675476,\n",
       "  -0.7915369272232056,\n",
       "  0.36989283561706543,\n",
       "  -0.09007905423641205,\n",
       "  -0.861923336982727,\n",
       "  0.0404096394777298,\n",
       "  -0.23845742642879486,\n",
       "  -0.13413169980049133,\n",
       "  0.618579089641571,\n",
       "  0.6765503883361816,\n",
       "  -0.6152834296226501,\n",
       "  0.35026296973228455,\n",
       "  -1.5417882204055786,\n",
       "  -0.25870922207832336,\n",
       "  -0.26906439661979675,\n",
       "  0.6451425552368164,\n",
       "  0.016301481053233147,\n",
       "  -0.8515692949295044,\n",
       "  0.5128507018089294,\n",
       "  -0.14861451089382172,\n",
       "  0.2044965922832489,\n",
       "  -0.09364397823810577,\n",
       "  -1.4604132175445557,\n",
       "  0.9031239748001099,\n",
       "  0.5420270562171936,\n",
       "  -0.26944878697395325,\n",
       "  -0.14679884910583496,\n",
       "  -0.639218270778656,\n",
       "  -1.2449761629104614,\n",
       "  0.15288610756397247,\n",
       "  0.06940620392560959,\n",
       "  -0.23598749935626984,\n",
       "  0.5601279139518738,\n",
       "  0.838300347328186,\n",
       "  -0.059641581028699875,\n",
       "  0.6914483904838562,\n",
       "  -0.293467253446579,\n",
       "  -1.0982422828674316,\n",
       "  -0.33939388394355774,\n",
       "  0.09230291843414307,\n",
       "  0.7485690116882324,\n",
       "  -0.18953019380569458,\n",
       "  -1.0902029275894165,\n",
       "  1.023882269859314,\n",
       "  -0.8400040864944458,\n",
       "  0.6580894589424133,\n",
       "  0.1657571643590927,\n",
       "  -0.09973151981830597,\n",
       "  -0.38059088587760925,\n",
       "  0.06699095666408539,\n",
       "  0.8870284557342529,\n",
       "  0.6914406418800354,\n",
       "  -0.6713696122169495,\n",
       "  0.7844108939170837,\n",
       "  0.7696825265884399,\n",
       "  0.707099974155426,\n",
       "  0.19046089053153992,\n",
       "  0.024385392665863037,\n",
       "  0.15214753150939941,\n",
       "  -0.7543367743492126,\n",
       "  0.05598034709692001,\n",
       "  1.0789601802825928,\n",
       "  -0.48968926072120667,\n",
       "  0.6626056432723999,\n",
       "  0.07818055152893066,\n",
       "  0.1209540069103241,\n",
       "  0.5192166566848755,\n",
       "  0.8797186613082886,\n",
       "  0.17412100732326508,\n",
       "  -1.312371015548706,\n",
       "  -0.3306565284729004,\n",
       "  0.8958712220191956,\n",
       "  0.4013867974281311,\n",
       "  0.18024283647537231,\n",
       "  0.2761519253253937,\n",
       "  0.5729942917823792,\n",
       "  0.22203752398490906,\n",
       "  0.8644202947616577,\n",
       "  0.7726375460624695,\n",
       "  0.5305643677711487,\n",
       "  -0.6732543706893921,\n",
       "  -0.5150704979896545,\n",
       "  -0.4348229765892029,\n",
       "  -0.071381576359272,\n",
       "  0.15529967844486237,\n",
       "  0.21716153621673584,\n",
       "  -0.29257234930992126,\n",
       "  -3.6434481143951416,\n",
       "  0.021318523213267326,\n",
       "  0.7682971358299255,\n",
       "  -0.9308005571365356,\n",
       "  -0.3599865734577179,\n",
       "  -1.005075216293335,\n",
       "  -0.3222581744194031,\n",
       "  0.40174031257629395,\n",
       "  -0.0366385355591774,\n",
       "  -0.057168424129486084,\n",
       "  -0.7989599108695984,\n",
       "  0.11721114069223404,\n",
       "  -1.9747214317321777,\n",
       "  1.5149857997894287,\n",
       "  -1.2105181217193604,\n",
       "  -0.35344937443733215,\n",
       "  0.3235199451446533,\n",
       "  -1.521743655204773,\n",
       "  -0.870359480381012,\n",
       "  0.12680286169052124,\n",
       "  0.15229663252830505,\n",
       "  -0.7289148569107056,\n",
       "  -0.21398070454597473,\n",
       "  0.2656293511390686,\n",
       "  1.2198950052261353,\n",
       "  0.852301299571991,\n",
       "  0.0866154208779335,\n",
       "  -1.0427452325820923,\n",
       "  -1.2096258401870728,\n",
       "  -0.6594535708427429,\n",
       "  -0.03136611357331276,\n",
       "  -0.11210626363754272,\n",
       "  -0.22366410493850708,\n",
       "  -0.8498741984367371,\n",
       "  -0.6782684326171875,\n",
       "  -0.8248249292373657,\n",
       "  -0.0468512699007988,\n",
       "  -0.23837170004844666,\n",
       "  0.6372668743133545,\n",
       "  -1.0607273578643799,\n",
       "  -0.06972534954547882,\n",
       "  -0.3033193349838257,\n",
       "  -0.6047070026397705,\n",
       "  -0.0575781986117363,\n",
       "  0.10975963622331619,\n",
       "  -0.6632202863693237,\n",
       "  0.17041270434856415,\n",
       "  -0.9891549348831177,\n",
       "  1.1055939197540283,\n",
       "  0.4013749957084656,\n",
       "  2.0100574493408203,\n",
       "  0.5626628994941711,\n",
       "  -0.5138229727745056,\n",
       "  -0.8989236950874329,\n",
       "  -0.006868243217468262,\n",
       "  -0.9255782961845398,\n",
       "  -0.056565165519714355,\n",
       "  0.9012472033500671,\n",
       "  -0.2549077272415161,\n",
       "  -1.3557720184326172,\n",
       "  -0.6209745407104492,\n",
       "  0.644982635974884,\n",
       "  0.4760807156562805,\n",
       "  0.33721795678138733,\n",
       "  0.14105722308158875,\n",
       "  -0.017035163938999176,\n",
       "  -0.20360495150089264,\n",
       "  0.061802685260772705,\n",
       "  0.2573544681072235,\n",
       "  -0.21593283116817474,\n",
       "  -0.2721818685531616,\n",
       "  0.38170528411865234,\n",
       "  0.366003155708313,\n",
       "  1.063750982284546,\n",
       "  0.3589254319667816,\n",
       "  -1.212326169013977,\n",
       "  0.009596954099833965,\n",
       "  -0.12296214699745178,\n",
       "  -0.8969438076019287,\n",
       "  0.055995091795921326,\n",
       "  -0.294986367225647,\n",
       "  0.6045962572097778,\n",
       "  0.45946428179740906,\n",
       "  1.3411898612976074,\n",
       "  -0.13981346786022186,\n",
       "  0.23366861045360565,\n",
       "  -1.5434588193893433,\n",
       "  -0.024080097675323486,\n",
       "  0.22947365045547485,\n",
       "  0.34531494975090027,\n",
       "  0.1511876881122589,\n",
       "  -0.7507236003875732,\n",
       "  -0.6766616106033325,\n",
       "  0.08061010390520096,\n",
       "  0.25674039125442505,\n",
       "  0.40110617876052856,\n",
       "  -0.052230384200811386,\n",
       "  -0.24617192149162292,\n",
       "  -0.0714457556605339,\n",
       "  0.12095373868942261,\n",
       "  -0.42755165696144104,\n",
       "  -0.1655987948179245,\n",
       "  0.5001259446144104,\n",
       "  0.3148525059223175,\n",
       "  0.881973922252655,\n",
       "  0.44026800990104675,\n",
       "  1.561780333518982,\n",
       "  -0.4177166819572449,\n",
       "  -0.16150212287902832,\n",
       "  0.3980178236961365,\n",
       "  1.1563910245895386,\n",
       "  -0.16962240636348724,\n",
       "  0.11418316513299942,\n",
       "  0.7304338812828064,\n",
       "  0.6352993249893188,\n",
       "  0.6112101078033447,\n",
       "  -0.6753864288330078,\n",
       "  0.03000931814312935,\n",
       "  0.6800994277000427,\n",
       "  0.08987680822610855,\n",
       "  -0.8147761225700378,\n",
       "  -0.3536507487297058,\n",
       "  -0.809332549571991,\n",
       "  -0.09724855422973633,\n",
       "  0.30469319224357605,\n",
       "  0.9999681115150452,\n",
       "  0.7502970695495605,\n",
       "  -1.1736268997192383,\n",
       "  -0.4435928165912628,\n",
       "  -1.2133525609970093,\n",
       "  -0.5186405181884766,\n",
       "  -0.3644637167453766,\n",
       "  -0.0285326037555933,\n",
       "  -0.022568242624402046,\n",
       "  -0.06104715168476105,\n",
       "  -0.9528456926345825,\n",
       "  -0.31958892941474915,\n",
       "  -0.29329854249954224,\n",
       "  0.02057892456650734,\n",
       "  1.1133973598480225,\n",
       "  -0.32646510004997253,\n",
       "  0.8457550406455994,\n",
       "  0.8957306146621704,\n",
       "  -0.8510086536407471,\n",
       "  1.3246235847473145,\n",
       "  0.3590533435344696,\n",
       "  0.09600044786930084,\n",
       "  -0.12302599102258682,\n",
       "  -0.5216644406318665,\n",
       "  -0.12329092621803284,\n",
       "  -0.6933248043060303,\n",
       "  -0.4684765040874481,\n",
       "  -0.9636923670768738,\n",
       "  -0.0873458981513977,\n",
       "  0.5445379614830017,\n",
       "  -1.0748881101608276,\n",
       "  0.23085375130176544,\n",
       "  0.2704280614852905,\n",
       "  0.3069050908088684,\n",
       "  0.8494688868522644,\n",
       "  0.5552734732627869,\n",
       "  0.7395075559616089,\n",
       "  -0.15224243700504303,\n",
       "  0.28336095809936523,\n",
       "  -0.8693317770957947,\n",
       "  -0.7979372143745422,\n",
       "  -0.9660102128982544,\n",
       "  0.5005931854248047,\n",
       "  0.0443563312292099,\n",
       "  1.5857415199279785,\n",
       "  0.1456996500492096,\n",
       "  -1.157252311706543,\n",
       "  0.4515206813812256,\n",
       "  0.5020897388458252,\n",
       "  -0.27710118889808655,\n",
       "  -1.0843809843063354,\n",
       "  -0.42459362745285034,\n",
       "  0.28556615114212036,\n",
       "  -1.5687110424041748,\n",
       "  0.35334065556526184,\n",
       "  0.0038087659049779177,\n",
       "  0.7373806834220886,\n",
       "  -0.3165213167667389,\n",
       "  0.5680923461914062,\n",
       "  1.1393163204193115,\n",
       "  -0.12226785719394684,\n",
       "  -0.46514591574668884,\n",
       "  0.3417750895023346,\n",
       "  0.8642324209213257,\n",
       "  0.21819446980953217,\n",
       "  0.07662896066904068,\n",
       "  0.3818473219871521,\n",
       "  -0.08502228558063507,\n",
       "  0.45269331336021423,\n",
       "  -0.4315239489078522,\n",
       "  -0.40478166937828064,\n",
       "  -0.9733419418334961,\n",
       "  -0.15643659234046936,\n",
       "  -0.7819911241531372,\n",
       "  -0.11129588633775711,\n",
       "  0.45884934067726135,\n",
       "  0.7262991666793823,\n",
       "  0.5697076320648193,\n",
       "  -0.33262690901756287,\n",
       "  -1.3486146926879883,\n",
       "  0.036737553775310516,\n",
       "  0.3159314692020416,\n",
       "  0.042122166603803635,\n",
       "  -1.1118617057800293,\n",
       "  0.4085380733013153,\n",
       "  0.7037781476974487]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.embed([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cached data:\n",
    "# wrapper.embeddings_training\n",
    "# wrapper.embeddings_testing\n",
    "# wrapper.projector\n",
    "# wrapper.projections_training\n",
    "# wrapper.projections_testing\n",
    "# wrapper.salience_maps\n",
    "# wrapper.clusters\n",
    "# wrapper.cluster_profiles\n",
    "# wrapper.cluster_words_freqs\n",
    "# wrapper.cluster_class_word_sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

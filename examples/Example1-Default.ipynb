{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1 - Default Approach\n",
    "\n",
    "This notebook demonstrates how to use the TX2 dashboard with a sequence classification transformer using the default approach as described in the \"Basic Usage\" docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -q ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We enable logging to view the output from `wrapper.prepare()` further down in the notebook. (It's a long running function, and logs which step it's on.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import cuda\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example notebook, we use the 20 newsgroups dataset, which can be downloaded through sklearn via below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration SetFit--20_newsgroups-f9362e018b6adf67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/SetFit--20_newsgroups to /home/81n/.cache/huggingface/datasets/SetFit___json/SetFit--20_newsgroups-f9362e018b6adf67/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae28c77456ba47fa95b2776d470ce042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c24c33414a6e4cdcaf615d48b3f3a6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/14.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be3fa59ba7d46afab106f4024d2dac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e37aa600914109a25a102dce0ee2ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/81n/.cache/huggingface/datasets/SetFit___json/SetFit--20_newsgroups-f9362e018b6adf67/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration SetFit--20_newsgroups-f9362e018b6adf67\n",
      "Reusing dataset json (/home/81n/.cache/huggingface/datasets/SetFit___json/SetFit--20_newsgroups-f9362e018b6adf67/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# getting newsgroups data from huggingface\n",
    "train_data = pd.DataFrame(\n",
    "    data=load_dataset(\"SetFit/20_newsgroups\", split=\"train\")\n",
    ")\n",
    "test_data = pd.DataFrame(\n",
    "    data=load_dataset(\"SetFit/20_newsgroups\", split=\"test\")\n",
    ")\n",
    "\n",
    "# setting up pytorch device\n",
    "if cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.has_mps:\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Defined below is a simple sequence classification model with a variable for the language model itself `l1`. Since it is a BERT model, we take the sequence embedding from the `[CLS]` token (via `output_1[0][:, 0, :])`) and pipe that into the linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8cf6e0d21744c9bebd126e5719b489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1f2ef88f6346ea9d93a94d5b9ac02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/416M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a083a421fc340fd8483ed708db76945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da196b7199e9480889ee5c2a8a9e7525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822759eb1ee34dd6b47c47279a472b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "        self.l2 = torch.nn.Linear(768, 20)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        output_1 = self.l1(ids, mask)\n",
    "        output = self.l2(output_1[0][:, 0, :])  # use just the [CLS] output embedding\n",
    "        return output\n",
    "\n",
    "\n",
    "model = BERTClass()\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some simplistic data cleaning, and putting all data into dataframes for the wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    # text = text[text.index(\"\\n\\n\") + 2 :]\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"    \", \" \")\n",
    "    text = text.replace(\"   \", \" \")\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you have Weitek's address/phone number? I'd...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye) DN...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>I have a (very old) Mac 512k and a Mac Plus, b...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>Wouldn't this require a hyper-sphere. In 3-spa...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>Stolen from Pasadena between 4:30 and 6:30 pm ...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      I was wondering if anyone out there could enli...      7   \n",
       "1      A fair number of brave souls who upgraded thei...      4   \n",
       "2      well folks, my mac plus finally gave up the gh...      4   \n",
       "3      Do you have Weitek's address/phone number? I'd...      1   \n",
       "4      From article <C5owCB.n3p@world.std.com>, by to...     14   \n",
       "...                                                  ...    ...   \n",
       "11309  DN> From: nyeda@cnsvax.uwec.edu (David Nye) DN...     13   \n",
       "11310  I have a (very old) Mac 512k and a Mac Plus, b...      4   \n",
       "11311  I just installed a DX2-66 CPU in a clone mothe...      3   \n",
       "11312  Wouldn't this require a hyper-sphere. In 3-spa...      1   \n",
       "11313  Stolen from Pasadena between 4:30 and 6:30 pm ...      8   \n",
       "\n",
       "                     label_text  \n",
       "0                     rec.autos  \n",
       "1         comp.sys.mac.hardware  \n",
       "2         comp.sys.mac.hardware  \n",
       "3                 comp.graphics  \n",
       "4                     sci.space  \n",
       "...                         ...  \n",
       "11309                   sci.med  \n",
       "11310     comp.sys.mac.hardware  \n",
       "11311  comp.sys.ibm.pc.hardware  \n",
       "11312             comp.graphics  \n",
       "11313           rec.motorcycles  \n",
       "\n",
       "[11014 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean long white space or extensive character returns\n",
    "train_data.text = train_data.text.apply(lambda x: clean_text(x))\n",
    "test_data.text = test_data.text.apply(lambda x: clean_text(x))\n",
    "\n",
    "# remove empty entries or trivially short ones\n",
    "train_cleaned = train_data[train_data['text'].str.len() > 1]\n",
    "test_cleaned = test_data[test_data['text'].str.len() > 1]\n",
    "train_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "This section minimally trains the classification and language model - nothing fancy here, just to give the dashboard demo something to work with. Most of this is similar to the huggingface tutorial notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11014\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "class EncodedSet(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        print(self.len)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.data.text[index])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            \"targets\": torch.tensor(self.data.label[index], dtype=torch.long),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "train_cleaned.reset_index(drop=True, inplace=True)\n",
    "test_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_set = EncodedSet(train_cleaned, tokenizer, 256)\n",
    "test_set = EncodedSet(test_cleaned[:1000], tokenizer, 256)\n",
    "\n",
    "train_params = {\"batch_size\": 16, \"shuffle\": True, \"num_workers\": 0}\n",
    "\n",
    "test_params = {\"batch_size\": 2, \"shuffle\": True, \"num_workers\": 0}\n",
    "\n",
    "# put everything into data loaders\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    loss_history = []\n",
    "    for _, data in tqdm(\n",
    "        enumerate(train_loader, start=0), total=len(train_loader), desc=f\"Epoch {epoch}\"\n",
    "    ):\n",
    "        ids = data[\"ids\"].to(device, dtype=torch.long)\n",
    "        mask = data[\"mask\"].to(device, dtype=torch.long)\n",
    "        targets = data[\"targets\"].to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(ids, mask).squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, targets)\n",
    "        if _ % 100 == 0:\n",
    "            print(f\"Epoch: {epoch}, Loss:  {loss.item()}\")\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #         torch.cuda.empty_cache()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95c93100a61493f889e3d5734235b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/689 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  3.0136256217956543\n",
      "Epoch: 0, Loss:  1.6124145984649658\n",
      "Epoch: 0, Loss:  1.3765950202941895\n",
      "Epoch: 0, Loss:  0.92493736743927\n",
      "Epoch: 0, Loss:  1.0201209783554077\n",
      "Epoch: 0, Loss:  1.1414399147033691\n",
      "Epoch: 0, Loss:  1.0390430688858032\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(1):\n",
    "    losses.extend(train(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapper uses an `encodings` dictionary for various labels/visualizations, and can be set up with something similar to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism': 0,\n",
       " 'comp.graphics': 1,\n",
       " 'comp.os.ms-windows.misc': 2,\n",
       " 'comp.sys.ibm.pc.hardware': 3,\n",
       " 'comp.sys.mac.hardware': 4,\n",
       " 'comp.windows.x': 5,\n",
       " 'misc.forsale': 6,\n",
       " 'rec.autos': 7,\n",
       " 'rec.motorcycles': 8,\n",
       " 'rec.sport.baseball': 9,\n",
       " 'rec.sport.hockey': 10,\n",
       " 'sci.crypt': 11,\n",
       " 'sci.electronics': 12,\n",
       " 'sci.med': 13,\n",
       " 'sci.space': 14,\n",
       " 'soc.religion.christian': 15,\n",
       " 'talk.politics.guns': 16,\n",
       " 'talk.politics.mideast': 17,\n",
       " 'talk.politics.misc': 18,\n",
       " 'talk.religion.misc': 19}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = train_cleaned[[\"label\", \"label_text\"]].groupby(['label_text']).apply(lambda x: x['label'].tolist()[0]).to_dict()\n",
    "encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TX2\n",
    "\n",
    "This section shows how to put everything into the TX2 wrapper to get the dashboard widget displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tx2.dashboard import Dashboard\n",
    "from tx2.wrapper import Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Cache path not found, creating...\n",
      "INFO:root:Checking for cached predictions...\n",
      "INFO:root:Running classifier...\n",
      "INFO:root:Saving predictions...\n",
      "INFO:root:Writing to data/predictions.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached embeddings...\n",
      "INFO:root:Embedding training and testing datasets\n",
      "INFO:root:Saving embeddings...\n",
      "INFO:root:Writing to data/embedding_training.json\n",
      "INFO:root:Writing to data/embedding_testing.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached projections...\n",
      "INFO:root:Training projector...\n",
      "INFO:root:Applying projector to test dataset...\n",
      "/home/81n/micromamba/envs/tx2/lib/python3.9/site-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n",
      "INFO:root:Saving projections...\n",
      "INFO:root:Writing to data/projections_training.json\n",
      "INFO:root:Writing to data/projections_testing.json\n",
      "INFO:root:Writing to data/projector.pkl.gz\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached salience maps...\n",
      "INFO:root:Computing salience maps...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8004bd2d6d4ab080ebf9e941e3b48d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving salience maps...\n",
      "INFO:root:Writing to data/salience.pkl.gz\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached cluster profiles...\n",
      "INFO:root:Clustering projections...\n",
      "INFO:root:Saving cluster profiles...\n",
      "INFO:root:Writing to data/clusters.json\n",
      "INFO:root:Writing to data/cluster_profiles.pkl.gz\n",
      "INFO:root:Done!\n",
      "INFO:root:Saving cluster labels...\n",
      "INFO:root:Writing to data/cluster_labels.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Saving cluster word counts...\n",
      "INFO:root:Writing to data/cluster_words.json\n",
      "INFO:root:Writing to data/cluster_class_words.json\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "wrapper = Wrapper(\n",
    "    train_texts=train_data.text,\n",
    "    train_labels=train_data.label,\n",
    "    test_texts=test_data.text[:2000],\n",
    "    test_labels=test_data.label[:2000],\n",
    "    encodings=encodings,\n",
    "    classifier=model,\n",
    "    language_model=model.l1,\n",
    "    tokenizer=tokenizer,\n",
    "    overwrite=False,\n",
    ")\n",
    "wrapper.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, display\n",
    "with dash.out_projection_scatter:\n",
    "    clear_output(wait=True)\n",
    "    display(dash.current_figures[\"umap\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash.out_projection_scatter.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c703fd565b949848b3ec1fa8b650427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>UMAP Embedding Graph</h3>'), HBox(children=(Output(), VBox(child…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dash = Dashboard(wrapper)\n",
    "dash.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To play with different UMAP and DBSCAN arguments without having to recompute the entire `prepare()` function, you can use `recompute_projections` (which will recompute both the projections and visual clusterings) or `recompute_visual_clusterings` (which will only redo the clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper.recompute_visual_clusterings(\"KMeans\", clustering_args=dict(n_clusters=18))\n",
    "# wrapper.recompute_visual_clusterings(\"OPTICS\", clustering_args=dict())\n",
    "# wrapper.recompute_projections(umap_args=dict(min_dist=.2), dbscan_args=dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test or debug the classification model/see what raw outputs the viusualizations are getting, or create your own visualization tools, you can manually call the `classify()`, `soft_classify()`, `embed()` functions, or get access to any of the cached data as seen in the bottom cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.8078917264938354,\n",
       "  0.568716824054718,\n",
       "  -0.19390958547592163,\n",
       "  0.03506672382354736,\n",
       "  0.5997799038887024,\n",
       "  -0.15630200505256653,\n",
       "  0.3562496602535248,\n",
       "  1.5066196918487549,\n",
       "  1.337870717048645,\n",
       "  0.12109793722629547,\n",
       "  -0.2588321566581726,\n",
       "  -0.36532601714134216,\n",
       "  0.846497118473053,\n",
       "  -0.4600551724433899,\n",
       "  0.8319088220596313,\n",
       "  -1.1919726133346558,\n",
       "  -0.17896556854248047,\n",
       "  -0.36397162079811096,\n",
       "  -0.6458845734596252,\n",
       "  -0.12576475739479065]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.soft_classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.25644156336784363,\n",
       "  0.05025826767086983,\n",
       "  0.3956014811992645,\n",
       "  -0.0006179641932249069,\n",
       "  -1.1145391464233398,\n",
       "  0.060205645859241486,\n",
       "  -0.18108679354190826,\n",
       "  0.4423906207084656,\n",
       "  0.23583434522151947,\n",
       "  -1.6318483352661133,\n",
       "  -0.2251821756362915,\n",
       "  0.045889925211668015,\n",
       "  0.19605259597301483,\n",
       "  0.6170377731323242,\n",
       "  -0.29179584980010986,\n",
       "  -0.33993247151374817,\n",
       "  0.4368723928928375,\n",
       "  -0.5554522275924683,\n",
       "  0.5128957033157349,\n",
       "  -0.05109744891524315,\n",
       "  0.10730648040771484,\n",
       "  -0.5966005325317383,\n",
       "  0.5387629866600037,\n",
       "  -0.20739209651947021,\n",
       "  -0.8192044496536255,\n",
       "  -0.40263602137565613,\n",
       "  0.12051111459732056,\n",
       "  0.1956312656402588,\n",
       "  -0.5781459212303162,\n",
       "  -0.12045631557703018,\n",
       "  -1.0074450969696045,\n",
       "  0.6666457653045654,\n",
       "  -0.7306155562400818,\n",
       "  -0.20743919909000397,\n",
       "  -0.2551681697368622,\n",
       "  -0.1203124076128006,\n",
       "  0.8768701553344727,\n",
       "  0.49868568778038025,\n",
       "  -0.6971737742424011,\n",
       "  0.4595204293727875,\n",
       "  0.12442173063755035,\n",
       "  0.38815537095069885,\n",
       "  0.4095039963722229,\n",
       "  -0.1629936844110489,\n",
       "  -0.43195924162864685,\n",
       "  0.3422238826751709,\n",
       "  0.16226041316986084,\n",
       "  -0.01957789435982704,\n",
       "  0.2261938899755478,\n",
       "  0.7205305695533752,\n",
       "  -0.24970406293869019,\n",
       "  -0.11935115605592728,\n",
       "  0.34300661087036133,\n",
       "  0.9284223318099976,\n",
       "  0.004869821947067976,\n",
       "  -0.7413934469223022,\n",
       "  -1.0450752973556519,\n",
       "  0.23483818769454956,\n",
       "  -0.3101024627685547,\n",
       "  -0.3993748426437378,\n",
       "  -0.3976714015007019,\n",
       "  -0.3821149468421936,\n",
       "  0.3045708239078522,\n",
       "  0.3741775453090668,\n",
       "  -0.043161917477846146,\n",
       "  -0.6947659254074097,\n",
       "  0.6551030874252319,\n",
       "  -1.2847414016723633,\n",
       "  0.07127746939659119,\n",
       "  -0.3245471119880676,\n",
       "  0.41040918231010437,\n",
       "  0.4302099943161011,\n",
       "  0.48478758335113525,\n",
       "  1.2506115436553955,\n",
       "  0.3208630383014679,\n",
       "  -0.8691138029098511,\n",
       "  -0.02054212987422943,\n",
       "  0.2970663905143738,\n",
       "  -0.09146575629711151,\n",
       "  0.8745388388633728,\n",
       "  0.3971932530403137,\n",
       "  -0.0966946929693222,\n",
       "  -0.753350555896759,\n",
       "  -0.21771977841854095,\n",
       "  0.047942958772182465,\n",
       "  0.4718913733959198,\n",
       "  0.5517805218696594,\n",
       "  0.06834511458873749,\n",
       "  0.4449607729911804,\n",
       "  0.17565129697322845,\n",
       "  -0.08005797117948532,\n",
       "  0.6615118980407715,\n",
       "  -0.6143907308578491,\n",
       "  0.17750027775764465,\n",
       "  -0.6160739660263062,\n",
       "  0.25144684314727783,\n",
       "  -0.9739533066749573,\n",
       "  -0.12157941609621048,\n",
       "  5.647593975067139,\n",
       "  -0.26264604926109314,\n",
       "  0.5002361536026001,\n",
       "  -0.13218168914318085,\n",
       "  -0.06981970369815826,\n",
       "  -0.3829984664916992,\n",
       "  0.18023891746997833,\n",
       "  -0.645516574382782,\n",
       "  0.019754480570554733,\n",
       "  0.2998684048652649,\n",
       "  0.1747765988111496,\n",
       "  0.4707682728767395,\n",
       "  0.8336208462715149,\n",
       "  0.3452686071395874,\n",
       "  0.9674947261810303,\n",
       "  -0.7222485542297363,\n",
       "  0.13564971089363098,\n",
       "  -0.2344748079776764,\n",
       "  -0.03574765473604202,\n",
       "  0.0144277885556221,\n",
       "  0.6558825373649597,\n",
       "  -0.8562361001968384,\n",
       "  -0.17697757482528687,\n",
       "  0.23429308831691742,\n",
       "  1.3633214235305786,\n",
       "  0.9547172784805298,\n",
       "  -0.2748308479785919,\n",
       "  0.012126203626394272,\n",
       "  0.06674829870462418,\n",
       "  0.14361077547073364,\n",
       "  0.8861850500106812,\n",
       "  0.06629897654056549,\n",
       "  -0.850845456123352,\n",
       "  -0.07189075648784637,\n",
       "  -0.7673569917678833,\n",
       "  0.502817690372467,\n",
       "  -0.7067413330078125,\n",
       "  0.12819567322731018,\n",
       "  -0.005329616367816925,\n",
       "  -0.263927161693573,\n",
       "  -1.30559241771698,\n",
       "  -0.05757864564657211,\n",
       "  -0.6022903919219971,\n",
       "  -0.43090665340423584,\n",
       "  -0.23931379616260529,\n",
       "  -0.12010233104228973,\n",
       "  -0.5409030318260193,\n",
       "  3.0906641483306885,\n",
       "  0.0646066963672638,\n",
       "  -0.41538238525390625,\n",
       "  -0.2025146335363388,\n",
       "  -0.5501013994216919,\n",
       "  0.5180913209915161,\n",
       "  -0.16142171621322632,\n",
       "  0.0129318255931139,\n",
       "  -0.24232929944992065,\n",
       "  0.3473705053329468,\n",
       "  -1.0342381000518799,\n",
       "  -0.09135591983795166,\n",
       "  0.011062875390052795,\n",
       "  0.4274753928184509,\n",
       "  0.6709742546081543,\n",
       "  -0.9223946928977966,\n",
       "  -0.8509780168533325,\n",
       "  -0.7286284565925598,\n",
       "  0.20449461042881012,\n",
       "  1.0081658363342285,\n",
       "  -0.4569377899169922,\n",
       "  0.645577609539032,\n",
       "  -0.030864976346492767,\n",
       "  0.016457922756671906,\n",
       "  0.4808220863342285,\n",
       "  -0.04608096182346344,\n",
       "  0.20278553664684296,\n",
       "  -1.7115448713302612,\n",
       "  0.723202109336853,\n",
       "  -0.2668520510196686,\n",
       "  0.23299920558929443,\n",
       "  0.8456499576568604,\n",
       "  0.6793952584266663,\n",
       "  -0.32741081714630127,\n",
       "  -0.5826032757759094,\n",
       "  -0.5686144232749939,\n",
       "  1.1244580745697021,\n",
       "  0.3490816354751587,\n",
       "  0.3358885645866394,\n",
       "  -0.11726851761341095,\n",
       "  -0.035094037652015686,\n",
       "  0.2246820032596588,\n",
       "  0.06261258572340012,\n",
       "  0.3218977749347687,\n",
       "  -1.2854045629501343,\n",
       "  0.12201813608407974,\n",
       "  -0.679476797580719,\n",
       "  -0.7264739871025085,\n",
       "  -0.2596823573112488,\n",
       "  1.2830406427383423,\n",
       "  -0.41245847940444946,\n",
       "  -0.6458428502082825,\n",
       "  -0.05519036576151848,\n",
       "  -0.5638009905815125,\n",
       "  0.5755535960197449,\n",
       "  0.5155218243598938,\n",
       "  0.14493179321289062,\n",
       "  -0.6854264140129089,\n",
       "  0.29301372170448303,\n",
       "  0.4740029275417328,\n",
       "  -0.4113174378871918,\n",
       "  -0.018190227448940277,\n",
       "  -0.7307013273239136,\n",
       "  0.37852680683135986,\n",
       "  -0.7957192063331604,\n",
       "  -0.7818591594696045,\n",
       "  0.23328232765197754,\n",
       "  0.1699877232313156,\n",
       "  0.3504483103752136,\n",
       "  -0.5486716032028198,\n",
       "  -0.3305797874927521,\n",
       "  -0.3856732249259949,\n",
       "  0.29183655977249146,\n",
       "  -0.17405609786510468,\n",
       "  0.1601392924785614,\n",
       "  -0.7138389348983765,\n",
       "  0.22486375272274017,\n",
       "  -0.6020961403846741,\n",
       "  0.07489398866891861,\n",
       "  0.5140491127967834,\n",
       "  0.286072701215744,\n",
       "  0.2337629497051239,\n",
       "  0.31606367230415344,\n",
       "  -0.22920387983322144,\n",
       "  -0.1786281019449234,\n",
       "  0.34396517276763916,\n",
       "  0.3220999836921692,\n",
       "  -0.26765525341033936,\n",
       "  -0.9405930042266846,\n",
       "  0.15470227599143982,\n",
       "  -0.47341257333755493,\n",
       "  -1.1267067193984985,\n",
       "  0.2442772090435028,\n",
       "  -0.25589218735694885,\n",
       "  -0.40243715047836304,\n",
       "  0.168643519282341,\n",
       "  -0.19921563565731049,\n",
       "  0.486203670501709,\n",
       "  0.13945850729942322,\n",
       "  0.35891109704971313,\n",
       "  -0.22001883387565613,\n",
       "  0.4480551481246948,\n",
       "  -0.08542478829622269,\n",
       "  0.871106743812561,\n",
       "  -0.721924901008606,\n",
       "  1.192520022392273,\n",
       "  0.07432956248521805,\n",
       "  -0.04386904090642929,\n",
       "  -0.28369203209877014,\n",
       "  0.3854692578315735,\n",
       "  0.5223925113677979,\n",
       "  -0.7680489420890808,\n",
       "  -1.8905638456344604,\n",
       "  0.7310205698013306,\n",
       "  -0.7379121780395508,\n",
       "  0.37412822246551514,\n",
       "  -2.718850612640381,\n",
       "  0.6349981427192688,\n",
       "  0.3271360397338867,\n",
       "  0.3880844712257385,\n",
       "  -0.07424101233482361,\n",
       "  0.16480858623981476,\n",
       "  0.7031632661819458,\n",
       "  0.2086462527513504,\n",
       "  0.4928814172744751,\n",
       "  0.7072532176971436,\n",
       "  0.4261431396007538,\n",
       "  -0.594775915145874,\n",
       "  0.28140610456466675,\n",
       "  0.006514802575111389,\n",
       "  0.5751946568489075,\n",
       "  0.8135932683944702,\n",
       "  -0.11158131062984467,\n",
       "  0.8994316458702087,\n",
       "  -0.00015070289373397827,\n",
       "  0.14883387088775635,\n",
       "  0.17674316465854645,\n",
       "  -1.5136500597000122,\n",
       "  0.44663023948669434,\n",
       "  -1.07187819480896,\n",
       "  0.16120469570159912,\n",
       "  1.0000255107879639,\n",
       "  -0.6466372013092041,\n",
       "  0.3579213619232178,\n",
       "  4.260185718536377,\n",
       "  0.7698650360107422,\n",
       "  -0.4042350649833679,\n",
       "  -0.41941702365875244,\n",
       "  -0.6484227180480957,\n",
       "  0.1348210871219635,\n",
       "  -0.163124680519104,\n",
       "  -0.28610920906066895,\n",
       "  -0.08006260544061661,\n",
       "  0.03988403081893921,\n",
       "  0.4371781051158905,\n",
       "  -0.3915947675704956,\n",
       "  -0.040291137993335724,\n",
       "  -0.6769677400588989,\n",
       "  -0.1356041580438614,\n",
       "  0.16048313677310944,\n",
       "  -0.5546846985816956,\n",
       "  -0.03602255508303642,\n",
       "  -0.11045994609594345,\n",
       "  -1.1858034133911133,\n",
       "  -0.0823487639427185,\n",
       "  0.22091583907604218,\n",
       "  0.12991966307163239,\n",
       "  -1.2505830526351929,\n",
       "  0.09225920587778091,\n",
       "  -0.6852620840072632,\n",
       "  -0.5847108960151672,\n",
       "  -0.7917568683624268,\n",
       "  -0.14511461555957794,\n",
       "  -0.9073776602745056,\n",
       "  -0.2506016790866852,\n",
       "  0.4803312420845032,\n",
       "  0.5407255291938782,\n",
       "  -0.5490725040435791,\n",
       "  -0.2373286485671997,\n",
       "  -0.0666477307677269,\n",
       "  -0.7016091346740723,\n",
       "  -0.8915734887123108,\n",
       "  -0.8172820806503296,\n",
       "  -0.3893674612045288,\n",
       "  0.002425483427941799,\n",
       "  -0.43798109889030457,\n",
       "  0.2113819420337677,\n",
       "  -0.721756637096405,\n",
       "  -0.5147771239280701,\n",
       "  -0.28577694296836853,\n",
       "  -0.040717191994190216,\n",
       "  -0.39632943272590637,\n",
       "  0.12070774286985397,\n",
       "  -0.015822745859622955,\n",
       "  -0.6575095653533936,\n",
       "  0.33351048827171326,\n",
       "  0.09864495694637299,\n",
       "  -0.38477784395217896,\n",
       "  -0.6551359295845032,\n",
       "  -0.2959405183792114,\n",
       "  0.3690391778945923,\n",
       "  -0.021351374685764313,\n",
       "  -0.08049985021352768,\n",
       "  0.6265580654144287,\n",
       "  -0.3021177351474762,\n",
       "  -0.13537457585334778,\n",
       "  -0.43812063336372375,\n",
       "  -0.4759998321533203,\n",
       "  0.5764377117156982,\n",
       "  -0.34065717458724976,\n",
       "  0.1964295506477356,\n",
       "  -0.7265886068344116,\n",
       "  -0.43584752082824707,\n",
       "  -0.26762232184410095,\n",
       "  0.346100389957428,\n",
       "  -0.8810541033744812,\n",
       "  -1.794575572013855,\n",
       "  0.6704483032226562,\n",
       "  0.09867484122514725,\n",
       "  1.6992732286453247,\n",
       "  -0.07318118214607239,\n",
       "  0.5696635246276855,\n",
       "  -0.2516343295574188,\n",
       "  -0.5363125205039978,\n",
       "  0.4257631301879883,\n",
       "  0.01524382270872593,\n",
       "  0.9303223490715027,\n",
       "  0.04384002089500427,\n",
       "  -0.11615665256977081,\n",
       "  0.07854422926902771,\n",
       "  -0.8457926511764526,\n",
       "  -0.20121295750141144,\n",
       "  0.9639276266098022,\n",
       "  -0.11197031289339066,\n",
       "  -0.5365676283836365,\n",
       "  -0.28205469250679016,\n",
       "  1.4378337860107422,\n",
       "  0.6599831581115723,\n",
       "  0.04943544790148735,\n",
       "  0.23980045318603516,\n",
       "  0.332236111164093,\n",
       "  0.3385636806488037,\n",
       "  -0.0006502047181129456,\n",
       "  -0.45937538146972656,\n",
       "  -0.09839357435703278,\n",
       "  0.27182355523109436,\n",
       "  -1.073818325996399,\n",
       "  1.1451027393341064,\n",
       "  -0.8009123802185059,\n",
       "  -0.5865856409072876,\n",
       "  0.3615948557853699,\n",
       "  -0.9313921332359314,\n",
       "  0.41242700815200806,\n",
       "  0.942383348941803,\n",
       "  -0.2582260072231293,\n",
       "  -0.5883636474609375,\n",
       "  -0.847122311592102,\n",
       "  -0.5818436741828918,\n",
       "  -0.457069993019104,\n",
       "  0.8495709896087646,\n",
       "  1.0186938047409058,\n",
       "  0.21964645385742188,\n",
       "  0.11620460450649261,\n",
       "  -1.4371263980865479,\n",
       "  0.03857804089784622,\n",
       "  0.6416101455688477,\n",
       "  -0.5959024429321289,\n",
       "  0.2730901539325714,\n",
       "  0.027054009959101677,\n",
       "  0.06234019249677658,\n",
       "  0.652457594871521,\n",
       "  0.3544621169567108,\n",
       "  -0.0175851471722126,\n",
       "  0.14924713969230652,\n",
       "  0.45195552706718445,\n",
       "  -0.24722063541412354,\n",
       "  0.6891570687294006,\n",
       "  0.6173927187919617,\n",
       "  -0.40245315432548523,\n",
       "  0.1574268937110901,\n",
       "  -0.27300697565078735,\n",
       "  0.6945862174034119,\n",
       "  -0.8148016929626465,\n",
       "  0.39230191707611084,\n",
       "  0.2300199568271637,\n",
       "  -1.2006713151931763,\n",
       "  0.014067324809730053,\n",
       "  0.3811090588569641,\n",
       "  0.18222960829734802,\n",
       "  -0.11220822483301163,\n",
       "  -0.39016249775886536,\n",
       "  0.2493487149477005,\n",
       "  -0.5543976426124573,\n",
       "  0.28606340289115906,\n",
       "  5.144036293029785,\n",
       "  -0.9414266347885132,\n",
       "  0.5482051968574524,\n",
       "  0.049146611243486404,\n",
       "  -0.3651546835899353,\n",
       "  -0.1492900252342224,\n",
       "  0.6963645815849304,\n",
       "  -0.3067261576652527,\n",
       "  1.3993927240371704,\n",
       "  -1.0512089729309082,\n",
       "  -0.8703387379646301,\n",
       "  -0.3038650155067444,\n",
       "  0.23761127889156342,\n",
       "  -0.06491028517484665,\n",
       "  0.4721486270427704,\n",
       "  1.5704295635223389,\n",
       "  0.030077656731009483,\n",
       "  0.23521852493286133,\n",
       "  -0.06840630620718002,\n",
       "  -0.8896175622940063,\n",
       "  0.48432663083076477,\n",
       "  -0.09954936057329178,\n",
       "  0.9508160352706909,\n",
       "  0.07434657216072083,\n",
       "  0.8500774502754211,\n",
       "  0.9328088164329529,\n",
       "  -0.6275721192359924,\n",
       "  0.38888019323349,\n",
       "  -0.3148004710674286,\n",
       "  -0.5840315222740173,\n",
       "  -1.104787826538086,\n",
       "  -0.09658439457416534,\n",
       "  -0.7887950539588928,\n",
       "  -0.23210342228412628,\n",
       "  -0.4508841335773468,\n",
       "  0.26333579421043396,\n",
       "  0.5027321577072144,\n",
       "  0.20861199498176575,\n",
       "  0.17155100405216217,\n",
       "  0.4986850619316101,\n",
       "  0.4423651695251465,\n",
       "  0.23062506318092346,\n",
       "  0.6157056093215942,\n",
       "  -1.077101707458496,\n",
       "  -0.45755550265312195,\n",
       "  0.22165799140930176,\n",
       "  -0.05942535400390625,\n",
       "  0.29648712277412415,\n",
       "  -0.5675221085548401,\n",
       "  0.7690242528915405,\n",
       "  0.7381222248077393,\n",
       "  0.4267502427101135,\n",
       "  0.3705907464027405,\n",
       "  -0.7291672825813293,\n",
       "  0.3428519070148468,\n",
       "  0.3222658932209015,\n",
       "  -0.6354100704193115,\n",
       "  -0.8408442139625549,\n",
       "  0.132204070687294,\n",
       "  -0.7089999914169312,\n",
       "  -0.3679675757884979,\n",
       "  -0.4833904206752777,\n",
       "  -0.1413300335407257,\n",
       "  -0.7568960785865784,\n",
       "  0.5857890844345093,\n",
       "  -0.2133646309375763,\n",
       "  0.6341451406478882,\n",
       "  -0.3417121171951294,\n",
       "  -0.6948821544647217,\n",
       "  -0.4840843379497528,\n",
       "  -0.46836137771606445,\n",
       "  0.5828283429145813,\n",
       "  -0.5540608763694763,\n",
       "  0.24251633882522583,\n",
       "  0.7413865327835083,\n",
       "  -0.49460023641586304,\n",
       "  0.8133664727210999,\n",
       "  -0.010412853211164474,\n",
       "  0.583729088306427,\n",
       "  -0.9623287916183472,\n",
       "  -0.41521841287612915,\n",
       "  0.06442585587501526,\n",
       "  0.5471698641777039,\n",
       "  -0.5277522206306458,\n",
       "  0.541534960269928,\n",
       "  -0.14176404476165771,\n",
       "  0.27036774158477783,\n",
       "  -0.6822999715805054,\n",
       "  0.3071098029613495,\n",
       "  -0.012028183788061142,\n",
       "  0.3733072280883789,\n",
       "  0.23339471220970154,\n",
       "  0.16690751910209656,\n",
       "  -0.6958951950073242,\n",
       "  -0.09459894895553589,\n",
       "  -0.5000478029251099,\n",
       "  0.18491388857364655,\n",
       "  0.09200097620487213,\n",
       "  0.6983276605606079,\n",
       "  0.11168903112411499,\n",
       "  -0.36907175183296204,\n",
       "  0.24005168676376343,\n",
       "  -0.2117835134267807,\n",
       "  0.3078182339668274,\n",
       "  -0.06878943741321564,\n",
       "  0.20096167922019958,\n",
       "  0.9122723937034607,\n",
       "  0.2904692590236664,\n",
       "  0.6281402707099915,\n",
       "  0.012985263019800186,\n",
       "  0.8330205678939819,\n",
       "  0.29039669036865234,\n",
       "  -0.5989810824394226,\n",
       "  -0.8606698513031006,\n",
       "  0.18255342543125153,\n",
       "  0.27814924716949463,\n",
       "  0.8200922012329102,\n",
       "  -0.5631585717201233,\n",
       "  -4.057558059692383,\n",
       "  -0.18167045712471008,\n",
       "  0.5759173631668091,\n",
       "  0.25281238555908203,\n",
       "  -0.2059740424156189,\n",
       "  -0.9815065860748291,\n",
       "  -0.39471322298049927,\n",
       "  0.7024868130683899,\n",
       "  0.1747990995645523,\n",
       "  0.026705965399742126,\n",
       "  0.5143028497695923,\n",
       "  -0.5869421362876892,\n",
       "  -1.7939549684524536,\n",
       "  0.38073205947875977,\n",
       "  -0.2551078498363495,\n",
       "  0.40930551290512085,\n",
       "  1.0115572214126587,\n",
       "  -1.035270094871521,\n",
       "  -0.5841737985610962,\n",
       "  0.8370832800865173,\n",
       "  -0.0955728068947792,\n",
       "  0.1816484034061432,\n",
       "  -0.1508783996105194,\n",
       "  1.186710000038147,\n",
       "  0.7332356572151184,\n",
       "  0.1770283430814743,\n",
       "  -0.225612074136734,\n",
       "  -0.4233172833919525,\n",
       "  -0.6998142600059509,\n",
       "  -0.6454427242279053,\n",
       "  -0.4312061071395874,\n",
       "  0.3545384109020233,\n",
       "  -0.04025327041745186,\n",
       "  -0.7313323616981506,\n",
       "  0.00537613732740283,\n",
       "  -1.0094170570373535,\n",
       "  0.2240288257598877,\n",
       "  -0.1215323656797409,\n",
       "  0.4036792814731598,\n",
       "  -1.273858666419983,\n",
       "  -0.23522934317588806,\n",
       "  -0.2517191171646118,\n",
       "  0.27886122465133667,\n",
       "  1.10750150680542,\n",
       "  -0.17175927758216858,\n",
       "  -0.0008716285228729248,\n",
       "  -0.18047185242176056,\n",
       "  -1.2453126907348633,\n",
       "  0.011495241895318031,\n",
       "  -0.22788836061954498,\n",
       "  1.1483337879180908,\n",
       "  -0.12425412237644196,\n",
       "  -0.7174071073532104,\n",
       "  -0.7574536800384521,\n",
       "  -0.3397440016269684,\n",
       "  -0.01638958975672722,\n",
       "  0.4292876720428467,\n",
       "  -0.024894965812563896,\n",
       "  0.22361469268798828,\n",
       "  -0.9180154800415039,\n",
       "  -1.0229231119155884,\n",
       "  -0.14771640300750732,\n",
       "  0.13392196595668793,\n",
       "  -0.6112468242645264,\n",
       "  -0.3492777943611145,\n",
       "  0.2627032995223999,\n",
       "  -1.0649433135986328,\n",
       "  0.03076404333114624,\n",
       "  0.49684518575668335,\n",
       "  -0.016333846375346184,\n",
       "  -0.5193030834197998,\n",
       "  0.02776031568646431,\n",
       "  -0.13934653997421265,\n",
       "  -0.3089778423309326,\n",
       "  -0.18045853078365326,\n",
       "  0.05772601440548897,\n",
       "  -0.20325179398059845,\n",
       "  -0.6142693758010864,\n",
       "  -0.5040712356567383,\n",
       "  0.4480403661727905,\n",
       "  -0.6573156714439392,\n",
       "  -0.1735425442457199,\n",
       "  0.8363425135612488,\n",
       "  1.1328368186950684,\n",
       "  0.6810753345489502,\n",
       "  -0.27493372559547424,\n",
       "  -0.20595815777778625,\n",
       "  1.0825769901275635,\n",
       "  0.40437817573547363,\n",
       "  0.4620671272277832,\n",
       "  -0.5889600515365601,\n",
       "  -0.5391936898231506,\n",
       "  -0.20078539848327637,\n",
       "  0.5322681069374084,\n",
       "  -0.6602774858474731,\n",
       "  0.9538031816482544,\n",
       "  0.047514431178569794,\n",
       "  -0.034556224942207336,\n",
       "  0.37911126017570496,\n",
       "  0.0011480776593089104,\n",
       "  -0.44094306230545044,\n",
       "  0.1357254534959793,\n",
       "  0.303112268447876,\n",
       "  0.09383435547351837,\n",
       "  0.27823612093925476,\n",
       "  -0.2497386336326599,\n",
       "  3.0345137119293213,\n",
       "  0.01705070212483406,\n",
       "  -0.13136903941631317,\n",
       "  0.7500060200691223,\n",
       "  0.15110203623771667,\n",
       "  -0.1472575068473816,\n",
       "  -0.5081629753112793,\n",
       "  0.7216286063194275,\n",
       "  0.9648243188858032,\n",
       "  0.3797145485877991,\n",
       "  -0.5966607332229614,\n",
       "  -0.17631390690803528,\n",
       "  0.08477377146482468,\n",
       "  0.4767456650733948,\n",
       "  -0.07696881890296936,\n",
       "  0.5272647142410278,\n",
       "  0.24922902882099152,\n",
       "  -0.24406836926937103,\n",
       "  0.6570707559585571,\n",
       "  0.1915206015110016,\n",
       "  0.17666520178318024,\n",
       "  -0.27192366123199463,\n",
       "  -0.9405379295349121,\n",
       "  -0.3906886875629425,\n",
       "  0.3810890316963196,\n",
       "  -0.35568591952323914,\n",
       "  -0.3053544759750366,\n",
       "  -0.09557478874921799,\n",
       "  -0.32510292530059814,\n",
       "  -0.5963735580444336,\n",
       "  -0.37358707189559937,\n",
       "  -0.16857896745204926,\n",
       "  -0.0488431490957737,\n",
       "  1.600579857826233,\n",
       "  -0.3391406536102295,\n",
       "  1.1078141927719116,\n",
       "  0.05744899809360504,\n",
       "  -0.48197007179260254,\n",
       "  0.5307243466377258,\n",
       "  -0.16752228140830994,\n",
       "  0.17219498753547668,\n",
       "  -0.16402292251586914,\n",
       "  -0.22376199066638947,\n",
       "  0.72885662317276,\n",
       "  -0.8609786033630371,\n",
       "  -0.202337846159935,\n",
       "  -0.9522570371627808,\n",
       "  -0.12486504018306732,\n",
       "  -0.25601816177368164,\n",
       "  -1.3811450004577637,\n",
       "  0.024251893162727356,\n",
       "  0.8138234615325928,\n",
       "  -0.29983440041542053,\n",
       "  1.3132091760635376,\n",
       "  0.5539436936378479,\n",
       "  0.6413220763206482,\n",
       "  -0.39331570267677307,\n",
       "  -0.12706512212753296,\n",
       "  -0.6578530669212341,\n",
       "  -0.23463119566440582,\n",
       "  -0.45822983980178833,\n",
       "  0.3049227297306061,\n",
       "  -0.05830498784780502,\n",
       "  0.2438778579235077,\n",
       "  -0.6644927263259888,\n",
       "  -0.26957473158836365,\n",
       "  0.8380864262580872,\n",
       "  0.007811382412910461,\n",
       "  -0.23750053346157074,\n",
       "  -1.0825380086898804,\n",
       "  -0.14720669388771057,\n",
       "  -0.1377631276845932,\n",
       "  -1.9290459156036377,\n",
       "  0.6956657767295837,\n",
       "  0.36789676547050476,\n",
       "  0.22678862512111664,\n",
       "  -0.39257970452308655,\n",
       "  0.1241421177983284,\n",
       "  0.9879322052001953,\n",
       "  -0.2857673168182373,\n",
       "  -0.14640134572982788,\n",
       "  -0.07348136603832245,\n",
       "  -0.4181461036205292,\n",
       "  1.9572339057922363,\n",
       "  -0.04109593480825424,\n",
       "  -0.8151010274887085,\n",
       "  -0.9274318814277649,\n",
       "  -0.674893319606781,\n",
       "  -0.6198323369026184,\n",
       "  -0.34534698724746704,\n",
       "  -0.5861241221427917,\n",
       "  -0.2874497175216675,\n",
       "  -0.17478421330451965,\n",
       "  1.5974280834197998,\n",
       "  -0.0037996170576661825,\n",
       "  0.08582842350006104,\n",
       "  0.8424530029296875,\n",
       "  -0.3219620883464813,\n",
       "  -0.12723904848098755,\n",
       "  0.3975282311439514,\n",
       "  0.168587788939476,\n",
       "  0.4286402463912964,\n",
       "  -0.39664918184280396,\n",
       "  1.0361697673797607,\n",
       "  0.42172956466674805]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.embed([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cached data:\n",
    "# wrapper.embeddings_training\n",
    "# wrapper.embeddings_testing\n",
    "# wrapper.projector\n",
    "# wrapper.projections_training\n",
    "# wrapper.projections_testing\n",
    "# wrapper.salience_maps\n",
    "# wrapper.clusters\n",
    "# wrapper.cluster_profiles\n",
    "# wrapper.cluster_words_freqs\n",
    "# wrapper.cluster_class_word_sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

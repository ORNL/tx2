{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1 - Default Approach\n",
    "\n",
    "This notebook demonstrates how to use the TX2 dashboard with a sequence classification transformer using the default approach as described in the \"Basic Usage\" docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -q ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We enable logging to view the output from `wrapper.prepare()` further down in the notebook. (It's a long running function, and logs which step it's on.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import cuda\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example notebook, we use the 20 newsgroups dataset, which can be downloaded through sklearn via below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "train_data = fetch_20newsgroups(subset='train')\n",
    "test_data = fetch_20newsgroups(subset='test')\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Defined below is a simple sequence classification model with a variable for the language model itself `l1`. Since it is a BERT model, we take the sequence embedding from the `[CLS]` token (via `output_1[0][:, 0, :])`) and pipe that into the linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "        self.l2 = torch.nn.Linear(768, 20)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        output_1= self.l1(ids, mask)\n",
    "        output = self.l2(output_1[0][:, 0, :]) # use just the [CLS] output embedding\n",
    "        return output\n",
    "    \n",
    "model = BERTClass()\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some simplistic data cleaning, and putting all data into dataframes for the wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text[text.index(\"\\n\\n\")+2:]\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"    \", \" \")\n",
    "    text = text.replace(\"   \", \" \")\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_rows = []\n",
    "for i in range(len(train_data[\"data\"])):\n",
    "    row = {}\n",
    "    row[\"text\"] = clean_text(train_data[\"data\"][i])\n",
    "    row[\"target\"] = train_data['target'][i]\n",
    "    if row[\"text\"] == \"\" or row[\"text\"] == \" \": continue\n",
    "    train_rows.append(row)\n",
    "train_df = pd.DataFrame(train_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rows = []\n",
    "for i in range(len(test_data[\"data\"])):\n",
    "    row = {}\n",
    "    row[\"text\"] = clean_text(test_data[\"data\"][i])\n",
    "    row[\"target\"] = test_data['target'][i]\n",
    "    if row[\"text\"] == \"\" or row[\"text\"] == \" \": continue\n",
    "    test_rows.append(row)\n",
    "test_df = pd.DataFrame(test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "This section minimally trains the classification and language model - nothing fancy here, just to give the dashboard demo something to work with. Most of this is similar to the huggingface tutorial notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11296\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "class EncodedSet(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        print(self.len)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.data.text[index])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.target[index], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "train_set = EncodedSet(train_df, tokenizer, 256)\n",
    "test_set = EncodedSet(test_df[:1000], tokenizer, 256)\n",
    "\n",
    "train_params = {'batch_size': 16,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': 2,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "# put everything into data loaders\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "    loss_history = []\n",
    "    for _,data in tqdm(enumerate(train_loader, 0), total=len(train_loader), desc=f\"Epoch {epoch}\"):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask).squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, targets)\n",
    "        if _%100==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         torch.cuda.empty_cache()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a752eb50572d485eb8b00773bf968445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2173: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  3.092602014541626\n",
      "Epoch: 0, Loss:  2.555644989013672\n",
      "Epoch: 0, Loss:  0.8512181043624878\n",
      "Epoch: 0, Loss:  1.1629348993301392\n",
      "Epoch: 0, Loss:  0.6235500574111938\n",
      "Epoch: 0, Loss:  0.5858071446418762\n",
      "Epoch: 0, Loss:  0.5932454466819763\n",
      "Epoch: 0, Loss:  0.8548232913017273\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(1):\n",
    "    losses.extend(train(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapper uses an `encodings` dictionary for various labels/visualizations, and can be set up with something similar to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism': 0,\n",
       " 'comp.graphics': 1,\n",
       " 'comp.os.ms-windows.misc': 2,\n",
       " 'comp.sys.ibm.pc.hardware': 3,\n",
       " 'comp.sys.mac.hardware': 4,\n",
       " 'comp.windows.x': 5,\n",
       " 'misc.forsale': 6,\n",
       " 'rec.autos': 7,\n",
       " 'rec.motorcycles': 8,\n",
       " 'rec.sport.baseball': 9,\n",
       " 'rec.sport.hockey': 10,\n",
       " 'sci.crypt': 11,\n",
       " 'sci.electronics': 12,\n",
       " 'sci.med': 13,\n",
       " 'sci.space': 14,\n",
       " 'soc.religion.christian': 15,\n",
       " 'talk.politics.guns': 16,\n",
       " 'talk.politics.mideast': 17,\n",
       " 'talk.politics.misc': 18,\n",
       " 'talk.religion.misc': 19}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = {}\n",
    "for index, entry in enumerate(train_data[\"target_names\"]):\n",
    "    encodings[entry] = index\n",
    "encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TX2\n",
    "\n",
    "This section shows how to put everything into the TX2 wrapper to get the dashboard widget displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tx2.wrapper import Wrapper\n",
    "from tx2.dashboard import Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Cache path found\n",
      "INFO:root:Checking for cached predictions...\n",
      "INFO:root:Running classifier...\n",
      "/home/81n/miniconda3/envs/tx2test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2173: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "INFO:root:Saving predictions...\n",
      "INFO:root:Writing to data/predictions.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached embeddings...\n",
      "INFO:root:Embedding training and testing datasets\n",
      "INFO:root:Saving embeddings...\n",
      "INFO:root:Writing to data/embedding_training.json\n",
      "INFO:root:Writing to data/embedding_testing.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached projections...\n",
      "INFO:root:Training projector...\n",
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Applying projector to test dataset...\n",
      "INFO:root:Saving projections...\n",
      "INFO:root:Writing to data/projections_training.json\n",
      "INFO:root:Writing to data/projections_testing.json\n",
      "INFO:root:Writing to data/projector.pkl.gz\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached salience maps...\n",
      "INFO:root:Computing salience maps...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa69737a99c43c9b252ed5d21d276e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2173: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "INFO:root:Saving salience maps...\n",
      "INFO:root:Writing to data/salience.pkl.gz\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached cluster profiles...\n",
      "INFO:root:Clustering projections...\n",
      "INFO:root:Saving cluster profiles...\n",
      "INFO:root:Writing to data/clusters.json\n",
      "INFO:root:Writing to data/cluster_profiles.pkl.gz\n",
      "INFO:root:Done!\n",
      "/home/81n/miniconda3/envs/tx2test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2173: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2173: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2173: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2173: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2173: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2173: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2173: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "INFO:root:Saving cluster labels...\n",
      "INFO:root:Writing to data/cluster_labels.json\n",
      "INFO:root:Done!\n",
      "/home/81n/miniconda3/envs/tx2test/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "INFO:root:Saving cluster word counts...\n",
      "INFO:root:Writing to data/cluster_words.json\n",
      "INFO:root:Writing to data/cluster_class_words.json\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "wrapper = Wrapper(\n",
    "    train_texts=train_df.text,\n",
    "    train_labels=train_df.target,\n",
    "    test_texts=test_df.text[:2000],\n",
    "    test_labels=test_df.target[:2000],\n",
    "    encodings=encodings, \n",
    "    classifier=model, \n",
    "    language_model=model.l1, \n",
    "    tokenizer=tokenizer,\n",
    "    overwrite=False\n",
    ")\n",
    "wrapper.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9e3a4c9bee46a88e55a8356587d057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>UMAP Embedding Graph</h3>'), HBox(children=(Output(), VBox(child…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2test/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2173: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "import matplotlib.pyplot as plt\n",
    "dash = Dashboard(wrapper)\n",
    "dash.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To play with different UMAP and DBSCAN arguments without having to recompute the entire `prepare()` function, you can use `recompute_projections` (which will recompute both the projections and visual clusterings) or `recompute_visual_clusterings` (which will only redo the clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper.recompute_visual_clusterings(\"KMeans\", clustering_args=dict(n_clusters=18))\n",
    "# wrapper.recompute_visual_clusterings(\"OPTICS\", clustering_args=dict())\n",
    "# wrapper.recompute_projections(umap_args=dict(min_dist=.2), dbscan_args=dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test or debug the classification model/see what raw outputs the viusualizations are getting, or create your own visualization tools, you can manually call the `classify()`, `soft_classify()`, `embed()` functions, or get access to any of the cached data as seen in the bottom cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.5490002632141113,\n",
       "  0.5447496771812439,\n",
       "  0.6420480012893677,\n",
       "  -0.07533420622348785,\n",
       "  0.10862702131271362,\n",
       "  -0.28583580255508423,\n",
       "  1.7111026048660278,\n",
       "  0.7454321980476379,\n",
       "  -0.004717615433037281,\n",
       "  -0.40546083450317383,\n",
       "  -0.28679436445236206,\n",
       "  -0.32511797547340393,\n",
       "  1.1484254598617554,\n",
       "  0.08552921563386917,\n",
       "  -0.5705219507217407,\n",
       "  -0.3043102025985718,\n",
       "  -0.7019385099411011,\n",
       "  -0.3324044942855835,\n",
       "  -1.4107578992843628,\n",
       "  -0.9105768203735352]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.soft_classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.24136868119239807,\n",
       "  0.45420998334884644,\n",
       "  -0.07024809718132019,\n",
       "  -0.6937272548675537,\n",
       "  -0.10671645402908325,\n",
       "  0.7351047992706299,\n",
       "  -0.000835121376439929,\n",
       "  -0.5239612460136414,\n",
       "  -0.2446032613515854,\n",
       "  -1.330655813217163,\n",
       "  -0.15375931560993195,\n",
       "  0.5208644270896912,\n",
       "  0.031323742121458054,\n",
       "  0.5739494562149048,\n",
       "  -0.5563528537750244,\n",
       "  0.40088096261024475,\n",
       "  -0.05439304560422897,\n",
       "  0.1793462485074997,\n",
       "  0.03958629444241524,\n",
       "  0.21150530874729156,\n",
       "  -0.10047881305217743,\n",
       "  -0.10382146388292313,\n",
       "  0.8633599877357483,\n",
       "  -0.4873283803462982,\n",
       "  -0.1611892580986023,\n",
       "  -0.412416934967041,\n",
       "  -0.4943382143974304,\n",
       "  1.1622172594070435,\n",
       "  0.32461875677108765,\n",
       "  0.48047739267349243,\n",
       "  -0.9756738543510437,\n",
       "  0.9022844433784485,\n",
       "  -0.16612473130226135,\n",
       "  0.020706497132778168,\n",
       "  -0.26731815934181213,\n",
       "  0.1457855999469757,\n",
       "  0.6985318064689636,\n",
       "  0.03634147346019745,\n",
       "  -0.4847303330898285,\n",
       "  0.04799717664718628,\n",
       "  -0.8177706003189087,\n",
       "  0.07881990075111389,\n",
       "  0.6913429498672485,\n",
       "  -0.27848610281944275,\n",
       "  -0.5868977308273315,\n",
       "  0.45794835686683655,\n",
       "  0.3203936517238617,\n",
       "  -0.4487933814525604,\n",
       "  -0.6231805086135864,\n",
       "  0.5487084984779358,\n",
       "  -0.933383047580719,\n",
       "  0.72989422082901,\n",
       "  0.2361009567975998,\n",
       "  0.8168031573295593,\n",
       "  0.570946216583252,\n",
       "  0.9821208715438843,\n",
       "  -1.0154974460601807,\n",
       "  0.3310355246067047,\n",
       "  -0.6283186078071594,\n",
       "  0.4809246361255646,\n",
       "  -0.4432927072048187,\n",
       "  -0.4120069742202759,\n",
       "  0.2844390273094177,\n",
       "  0.975853443145752,\n",
       "  0.23380158841609955,\n",
       "  -0.5162692070007324,\n",
       "  0.6260197758674622,\n",
       "  -0.4014357626438141,\n",
       "  0.5331149697303772,\n",
       "  -0.6260994076728821,\n",
       "  0.36104559898376465,\n",
       "  0.7033503651618958,\n",
       "  0.6345570087432861,\n",
       "  0.7690702080726624,\n",
       "  0.8006882667541504,\n",
       "  -0.9173746109008789,\n",
       "  -0.2317827194929123,\n",
       "  0.39023998379707336,\n",
       "  -0.7165942192077637,\n",
       "  -0.22484059631824493,\n",
       "  1.0771408081054688,\n",
       "  -0.24181780219078064,\n",
       "  -1.066224217414856,\n",
       "  -0.17500363290309906,\n",
       "  -0.2993814945220947,\n",
       "  0.35945749282836914,\n",
       "  -0.02649654820561409,\n",
       "  -0.22423504292964935,\n",
       "  0.46586373448371887,\n",
       "  0.06271214038133621,\n",
       "  -0.10336524248123169,\n",
       "  0.3991997241973877,\n",
       "  -1.0880943536758423,\n",
       "  0.22905388474464417,\n",
       "  -0.05019427463412285,\n",
       "  0.37024345993995667,\n",
       "  0.26625335216522217,\n",
       "  0.9741399884223938,\n",
       "  4.890498161315918,\n",
       "  0.07308464497327805,\n",
       "  0.33825352787971497,\n",
       "  -0.3871200382709503,\n",
       "  -0.20726777613162994,\n",
       "  -0.54521244764328,\n",
       "  0.13703298568725586,\n",
       "  -0.23359298706054688,\n",
       "  -0.13016389310359955,\n",
       "  -1.3083540201187134,\n",
       "  0.6463975310325623,\n",
       "  0.2226756066083908,\n",
       "  0.8142932057380676,\n",
       "  0.23158510029315948,\n",
       "  1.1566182374954224,\n",
       "  0.4003516435623169,\n",
       "  0.46526557207107544,\n",
       "  -0.02881365269422531,\n",
       "  -1.0360229015350342,\n",
       "  0.5737377405166626,\n",
       "  -0.6925733685493469,\n",
       "  -0.3036552369594574,\n",
       "  -0.03572331741452217,\n",
       "  0.17035797238349915,\n",
       "  1.954849123954773,\n",
       "  0.24840061366558075,\n",
       "  -1.314111590385437,\n",
       "  0.1572355031967163,\n",
       "  -0.09036368131637573,\n",
       "  -0.026761207729578018,\n",
       "  0.6687387824058533,\n",
       "  -0.7542951107025146,\n",
       "  -0.7479246854782104,\n",
       "  -0.35542795062065125,\n",
       "  -0.501958966255188,\n",
       "  0.5125020146369934,\n",
       "  -0.021656300872564316,\n",
       "  0.07521550357341766,\n",
       "  -0.9434342980384827,\n",
       "  -0.4194796681404114,\n",
       "  -1.7959507703781128,\n",
       "  0.6870133876800537,\n",
       "  -1.094658374786377,\n",
       "  0.38057246804237366,\n",
       "  0.6205134391784668,\n",
       "  -0.7874189019203186,\n",
       "  -0.5752055644989014,\n",
       "  2.624201774597168,\n",
       "  0.10046468675136566,\n",
       "  -0.5485617518424988,\n",
       "  0.14632901549339294,\n",
       "  -0.9233874678611755,\n",
       "  0.9814543128013611,\n",
       "  0.9219241142272949,\n",
       "  -0.11278274655342102,\n",
       "  0.5748962163925171,\n",
       "  1.034182071685791,\n",
       "  -0.8793008923530579,\n",
       "  -0.2824196517467499,\n",
       "  -0.09392604976892471,\n",
       "  0.1520797610282898,\n",
       "  0.7346460223197937,\n",
       "  0.0061901044100522995,\n",
       "  -0.14032180607318878,\n",
       "  -0.04323241859674454,\n",
       "  -0.40181034803390503,\n",
       "  1.161881685256958,\n",
       "  -1.079260230064392,\n",
       "  1.12712824344635,\n",
       "  -0.9277558922767639,\n",
       "  -0.058901116251945496,\n",
       "  0.12704981863498688,\n",
       "  -0.4081950783729553,\n",
       "  0.05844059959053993,\n",
       "  -1.4935353994369507,\n",
       "  0.9965844750404358,\n",
       "  0.21535660326480865,\n",
       "  -0.2240644097328186,\n",
       "  0.38957762718200684,\n",
       "  0.7392343282699585,\n",
       "  0.07226883620023727,\n",
       "  -0.5782806277275085,\n",
       "  -0.4836016297340393,\n",
       "  0.41654545068740845,\n",
       "  -0.5634438395500183,\n",
       "  -0.2839806377887726,\n",
       "  -0.037645310163497925,\n",
       "  -0.08860080689191818,\n",
       "  0.09245945513248444,\n",
       "  -0.4607069790363312,\n",
       "  -0.09295964241027832,\n",
       "  -0.12120989710092545,\n",
       "  -0.2737588882446289,\n",
       "  0.07268209755420685,\n",
       "  0.09339944273233414,\n",
       "  -0.37777459621429443,\n",
       "  0.7345579862594604,\n",
       "  0.1266021430492401,\n",
       "  0.10626791417598724,\n",
       "  -0.022013213485479355,\n",
       "  -0.7730684876441956,\n",
       "  0.37469545006752014,\n",
       "  -0.2365778535604477,\n",
       "  -0.1898455023765564,\n",
       "  -0.7336264848709106,\n",
       "  -0.15263597667217255,\n",
       "  1.1031389236450195,\n",
       "  0.22795997560024261,\n",
       "  0.4765324294567108,\n",
       "  -0.08697249740362167,\n",
       "  0.5700715184211731,\n",
       "  -0.424629807472229,\n",
       "  -0.4454925060272217,\n",
       "  -0.17084717750549316,\n",
       "  0.6912627816200256,\n",
       "  0.07957551628351212,\n",
       "  0.8419063687324524,\n",
       "  -0.32328638434410095,\n",
       "  0.007372220046818256,\n",
       "  -0.004193931818008423,\n",
       "  0.14606644213199615,\n",
       "  0.03164571896195412,\n",
       "  -0.25832799077033997,\n",
       "  0.013711178675293922,\n",
       "  -1.0811773538589478,\n",
       "  -0.16956090927124023,\n",
       "  0.8179556131362915,\n",
       "  -0.2763102352619171,\n",
       "  -0.050244782119989395,\n",
       "  0.24013440310955048,\n",
       "  0.4111805260181427,\n",
       "  -0.5681942701339722,\n",
       "  0.6234771013259888,\n",
       "  0.3119150400161743,\n",
       "  -0.344996839761734,\n",
       "  -0.8200101852416992,\n",
       "  0.17074993252754211,\n",
       "  0.2665458917617798,\n",
       "  -0.7551681399345398,\n",
       "  0.8329501748085022,\n",
       "  -0.2091098427772522,\n",
       "  -0.0659894123673439,\n",
       "  -0.20591242611408234,\n",
       "  -1.1548364162445068,\n",
       "  0.1347963511943817,\n",
       "  -0.24798206984996796,\n",
       "  0.5067719221115112,\n",
       "  0.744808554649353,\n",
       "  0.44218945503234863,\n",
       "  0.47014835476875305,\n",
       "  0.6518460512161255,\n",
       "  -0.791201114654541,\n",
       "  1.008506178855896,\n",
       "  -0.1718892604112625,\n",
       "  -0.2319338321685791,\n",
       "  -0.2769477069377899,\n",
       "  0.39670443534851074,\n",
       "  0.22430674731731415,\n",
       "  -1.0168861150741577,\n",
       "  -1.114914894104004,\n",
       "  0.7838667631149292,\n",
       "  -0.983573853969574,\n",
       "  0.158505380153656,\n",
       "  -2.900749921798706,\n",
       "  0.7698073983192444,\n",
       "  0.32774704694747925,\n",
       "  -0.3856593072414398,\n",
       "  -0.3644147217273712,\n",
       "  0.43117794394493103,\n",
       "  -0.14425376057624817,\n",
       "  0.16597279906272888,\n",
       "  0.406304270029068,\n",
       "  0.7955422401428223,\n",
       "  -0.43122589588165283,\n",
       "  -0.44599953293800354,\n",
       "  -0.29810163378715515,\n",
       "  0.1635197401046753,\n",
       "  0.46884581446647644,\n",
       "  -0.3696860671043396,\n",
       "  0.10669061541557312,\n",
       "  0.46648624539375305,\n",
       "  -0.5393046140670776,\n",
       "  -0.1232786700129509,\n",
       "  0.2828008830547333,\n",
       "  -1.212656855583191,\n",
       "  0.4105988144874573,\n",
       "  -0.722632646560669,\n",
       "  0.36875152587890625,\n",
       "  1.0892947912216187,\n",
       "  -0.8637595176696777,\n",
       "  0.4062210023403168,\n",
       "  3.15291166305542,\n",
       "  0.7332964539527893,\n",
       "  -0.6906397342681885,\n",
       "  0.40243443846702576,\n",
       "  -1.0078200101852417,\n",
       "  -0.2541201710700989,\n",
       "  -0.7473400831222534,\n",
       "  -0.4284476637840271,\n",
       "  -0.8282778859138489,\n",
       "  -0.9184359312057495,\n",
       "  0.8121761679649353,\n",
       "  1.055322289466858,\n",
       "  0.08556205779314041,\n",
       "  -0.8120126128196716,\n",
       "  -0.11977189034223557,\n",
       "  -0.6341015696525574,\n",
       "  -0.7407373785972595,\n",
       "  0.24588295817375183,\n",
       "  0.21174120903015137,\n",
       "  -0.5832275748252869,\n",
       "  -0.8672177195549011,\n",
       "  0.45357415080070496,\n",
       "  -0.32370489835739136,\n",
       "  0.22740697860717773,\n",
       "  -0.11465181410312653,\n",
       "  -1.0282503366470337,\n",
       "  -0.7489537596702576,\n",
       "  -0.42254796624183655,\n",
       "  -0.007427132222801447,\n",
       "  -0.8698719143867493,\n",
       "  -0.9561528563499451,\n",
       "  0.5958376526832581,\n",
       "  -0.8106282353401184,\n",
       "  -0.626301646232605,\n",
       "  -0.0724867582321167,\n",
       "  -0.7236653566360474,\n",
       "  0.011844166554510593,\n",
       "  -0.005667595658451319,\n",
       "  0.28366950154304504,\n",
       "  -0.5976107716560364,\n",
       "  0.4896620512008667,\n",
       "  -0.4942649304866791,\n",
       "  -0.3821846544742584,\n",
       "  -0.01887313462793827,\n",
       "  0.02987930364906788,\n",
       "  -0.6302741765975952,\n",
       "  0.43592220544815063,\n",
       "  0.054317403584718704,\n",
       "  0.20250877737998962,\n",
       "  -0.13112066686153412,\n",
       "  -0.28172385692596436,\n",
       "  0.19470474123954773,\n",
       "  0.4526956379413605,\n",
       "  0.3887913227081299,\n",
       "  -0.3287208676338196,\n",
       "  0.02727419137954712,\n",
       "  -0.1351989060640335,\n",
       "  0.11272884905338287,\n",
       "  -0.6003046631813049,\n",
       "  1.0214568376541138,\n",
       "  -0.021760428324341774,\n",
       "  0.44005700945854187,\n",
       "  0.02515658363699913,\n",
       "  0.16422922909259796,\n",
       "  -0.048711057752370834,\n",
       "  0.3467467427253723,\n",
       "  -0.0873107835650444,\n",
       "  -0.3765546381473541,\n",
       "  -0.17029240727424622,\n",
       "  -0.713411808013916,\n",
       "  0.1897692084312439,\n",
       "  -0.034449633210897446,\n",
       "  -1.181972622871399,\n",
       "  0.9541508555412292,\n",
       "  -0.08672019094228745,\n",
       "  0.3221459984779358,\n",
       "  -0.7187120914459229,\n",
       "  0.13652437925338745,\n",
       "  -0.7079848051071167,\n",
       "  -0.10249438136816025,\n",
       "  0.42995473742485046,\n",
       "  0.2403181493282318,\n",
       "  0.7412478923797607,\n",
       "  -0.0238460972905159,\n",
       "  0.3839443624019623,\n",
       "  0.4971471130847931,\n",
       "  -0.6154783368110657,\n",
       "  -0.5944807529449463,\n",
       "  0.906113862991333,\n",
       "  -0.6399142146110535,\n",
       "  0.33364585041999817,\n",
       "  -0.16601791977882385,\n",
       "  0.5496038198471069,\n",
       "  0.38525018095970154,\n",
       "  -1.0952847003936768,\n",
       "  0.1900467425584793,\n",
       "  0.038992106914520264,\n",
       "  0.7728155851364136,\n",
       "  -0.20986132323741913,\n",
       "  -0.5628237128257751,\n",
       "  0.769964873790741,\n",
       "  0.4453147351741791,\n",
       "  -0.8805474638938904,\n",
       "  -0.17035385966300964,\n",
       "  -0.878441333770752,\n",
       "  -0.33777567744255066,\n",
       "  0.6616302728652954,\n",
       "  -0.11594712734222412,\n",
       "  -0.0258055217564106,\n",
       "  1.0061105489730835,\n",
       "  -0.26185375452041626,\n",
       "  -0.4106033146381378,\n",
       "  -0.32759517431259155,\n",
       "  -0.6097429990768433,\n",
       "  0.17827413976192474,\n",
       "  -0.23332591354846954,\n",
       "  0.4716963469982147,\n",
       "  0.3488776683807373,\n",
       "  0.17322388291358948,\n",
       "  -1.6830426454544067,\n",
       "  -0.05348395183682442,\n",
       "  0.02602498047053814,\n",
       "  -0.5892478823661804,\n",
       "  0.23982229828834534,\n",
       "  -0.26933783292770386,\n",
       "  0.7690585255622864,\n",
       "  -0.4403291940689087,\n",
       "  -0.20063747465610504,\n",
       "  0.588251531124115,\n",
       "  0.0965975672006607,\n",
       "  -0.3651140332221985,\n",
       "  0.12812122702598572,\n",
       "  0.5285024046897888,\n",
       "  -0.22674426436424255,\n",
       "  -0.6478016376495361,\n",
       "  0.6255075335502625,\n",
       "  0.08795444667339325,\n",
       "  0.37460070848464966,\n",
       "  -0.9353488683700562,\n",
       "  0.37682095170021057,\n",
       "  0.9185649752616882,\n",
       "  -0.22441506385803223,\n",
       "  0.5100520253181458,\n",
       "  0.3246205449104309,\n",
       "  0.0015474179526790977,\n",
       "  0.420659601688385,\n",
       "  -0.3883756101131439,\n",
       "  0.2918241322040558,\n",
       "  -1.1134742498397827,\n",
       "  0.0748181864619255,\n",
       "  3.312986373901367,\n",
       "  -0.806873083114624,\n",
       "  0.19023512303829193,\n",
       "  -0.18190379440784454,\n",
       "  -0.3646090626716614,\n",
       "  -0.23295858502388,\n",
       "  -0.2773857116699219,\n",
       "  -0.4201689064502716,\n",
       "  0.679624617099762,\n",
       "  -0.5008583068847656,\n",
       "  -0.3176896572113037,\n",
       "  -0.25042399764060974,\n",
       "  -0.764889657497406,\n",
       "  -0.3992827236652374,\n",
       "  -0.19833490252494812,\n",
       "  0.6928412914276123,\n",
       "  0.17675358057022095,\n",
       "  0.8826518058776855,\n",
       "  0.35647520422935486,\n",
       "  -0.9524871706962585,\n",
       "  0.9257861971855164,\n",
       "  -0.5890988707542419,\n",
       "  0.592312216758728,\n",
       "  0.5946087837219238,\n",
       "  -0.46612033247947693,\n",
       "  0.783071756362915,\n",
       "  -0.3232305347919464,\n",
       "  -0.4601980149745941,\n",
       "  0.6429296731948853,\n",
       "  -0.19657742977142334,\n",
       "  0.07073865830898285,\n",
       "  0.3199387490749359,\n",
       "  0.04547863453626633,\n",
       "  0.33942756056785583,\n",
       "  0.09669968485832214,\n",
       "  -0.3169667720794678,\n",
       "  0.00283829472027719,\n",
       "  0.19143807888031006,\n",
       "  0.08248168230056763,\n",
       "  0.19558575749397278,\n",
       "  0.8173366785049438,\n",
       "  -0.10101057589054108,\n",
       "  0.5218547582626343,\n",
       "  -0.4797780215740204,\n",
       "  0.32101842761039734,\n",
       "  0.18788236379623413,\n",
       "  0.37082916498184204,\n",
       "  -0.40070509910583496,\n",
       "  -0.0758156105875969,\n",
       "  0.6126566529273987,\n",
       "  0.6736883521080017,\n",
       "  0.4323806166648865,\n",
       "  0.4308491349220276,\n",
       "  -0.7808271050453186,\n",
       "  0.4111320674419403,\n",
       "  0.15281090140342712,\n",
       "  -1.7020704746246338,\n",
       "  -0.7725474238395691,\n",
       "  -0.5296152234077454,\n",
       "  -0.10650960355997086,\n",
       "  0.43338438868522644,\n",
       "  -0.7074828147888184,\n",
       "  0.34371641278266907,\n",
       "  -0.45467397570610046,\n",
       "  0.4070904552936554,\n",
       "  -0.6583300232887268,\n",
       "  0.9917113780975342,\n",
       "  -0.9312076568603516,\n",
       "  -0.32837915420532227,\n",
       "  -0.3802391290664673,\n",
       "  -0.43065595626831055,\n",
       "  0.7911748886108398,\n",
       "  -0.8361691832542419,\n",
       "  -0.682152271270752,\n",
       "  0.5248737931251526,\n",
       "  -0.6508537530899048,\n",
       "  0.5803791284561157,\n",
       "  0.2911585867404938,\n",
       "  0.599579393863678,\n",
       "  -0.7207133173942566,\n",
       "  -0.11509238928556442,\n",
       "  -0.4117330014705658,\n",
       "  -0.10260199010372162,\n",
       "  -0.7293556928634644,\n",
       "  0.634249746799469,\n",
       "  0.12140727043151855,\n",
       "  0.2140921652317047,\n",
       "  -0.6276500821113586,\n",
       "  0.028152761980891228,\n",
       "  -0.3123396635055542,\n",
       "  0.47653794288635254,\n",
       "  -0.16234518587589264,\n",
       "  0.14404557645320892,\n",
       "  -1.0501047372817993,\n",
       "  0.13558778166770935,\n",
       "  0.2753061056137085,\n",
       "  -0.09200052171945572,\n",
       "  0.17086605727672577,\n",
       "  0.3405456244945526,\n",
       "  0.2685559093952179,\n",
       "  0.03733501210808754,\n",
       "  -0.15732353925704956,\n",
       "  -0.05059532821178436,\n",
       "  0.31645888090133667,\n",
       "  -0.9956822395324707,\n",
       "  0.26497527956962585,\n",
       "  0.36685711145401,\n",
       "  0.2521969974040985,\n",
       "  1.058899164199829,\n",
       "  0.35189422965049744,\n",
       "  0.968764066696167,\n",
       "  -0.4908081293106079,\n",
       "  -0.12216384708881378,\n",
       "  -0.5074498057365417,\n",
       "  -0.23778343200683594,\n",
       "  0.8378623127937317,\n",
       "  0.159831702709198,\n",
       "  -1.1337639093399048,\n",
       "  -5.38762092590332,\n",
       "  0.22841639816761017,\n",
       "  0.7778055667877197,\n",
       "  0.2869074046611786,\n",
       "  -0.31095224618911743,\n",
       "  -0.4609522819519043,\n",
       "  -0.21692785620689392,\n",
       "  0.009724695235490799,\n",
       "  -0.15395429730415344,\n",
       "  -0.057089146226644516,\n",
       "  -0.5326313376426697,\n",
       "  -0.32367587089538574,\n",
       "  -1.4313462972640991,\n",
       "  -0.056257497519254684,\n",
       "  -0.24168875813484192,\n",
       "  0.22315390408039093,\n",
       "  0.41834235191345215,\n",
       "  -0.9860339760780334,\n",
       "  -0.37441155314445496,\n",
       "  0.653359591960907,\n",
       "  -0.3811655044555664,\n",
       "  -0.2691815495491028,\n",
       "  -0.12372810393571854,\n",
       "  0.2274189442396164,\n",
       "  0.5202042460441589,\n",
       "  0.7860680222511292,\n",
       "  0.13686305284500122,\n",
       "  -0.245605006814003,\n",
       "  -0.30659395456314087,\n",
       "  0.0760967954993248,\n",
       "  0.27532774209976196,\n",
       "  0.8894467353820801,\n",
       "  0.6708648204803467,\n",
       "  -0.4931492209434509,\n",
       "  -0.059041958302259445,\n",
       "  -0.4192465841770172,\n",
       "  0.023518726229667664,\n",
       "  0.020206520333886147,\n",
       "  -0.10620968043804169,\n",
       "  -0.1000748723745346,\n",
       "  0.24424457550048828,\n",
       "  -0.07781591266393661,\n",
       "  0.31396588683128357,\n",
       "  0.6797340512275696,\n",
       "  -0.5948927402496338,\n",
       "  -0.12254411727190018,\n",
       "  -0.3974601626396179,\n",
       "  -0.33632150292396545,\n",
       "  0.7355470061302185,\n",
       "  -0.30566272139549255,\n",
       "  1.1077256202697754,\n",
       "  0.25339001417160034,\n",
       "  -0.17315854132175446,\n",
       "  -0.359850138425827,\n",
       "  -0.2062879055738449,\n",
       "  0.2463783472776413,\n",
       "  -0.4454503357410431,\n",
       "  0.8492851853370667,\n",
       "  0.27596381306648254,\n",
       "  -0.9047751426696777,\n",
       "  -1.3492180109024048,\n",
       "  -0.5126927495002747,\n",
       "  0.30090367794036865,\n",
       "  0.32260945439338684,\n",
       "  0.18248797953128815,\n",
       "  -0.014917544089257717,\n",
       "  -0.5856148600578308,\n",
       "  -0.5588572025299072,\n",
       "  0.10703884810209274,\n",
       "  -0.05052492022514343,\n",
       "  -0.6369605660438538,\n",
       "  -0.262251079082489,\n",
       "  -0.041888944804668427,\n",
       "  -0.40388789772987366,\n",
       "  -0.19912517070770264,\n",
       "  -0.6928375363349915,\n",
       "  0.10494426637887955,\n",
       "  -0.5106005668640137,\n",
       "  -0.5101284980773926,\n",
       "  -0.024061152711510658,\n",
       "  -1.016286015510559,\n",
       "  -0.09834159910678864,\n",
       "  0.6799950003623962,\n",
       "  0.09971676766872406,\n",
       "  -0.21052995324134827,\n",
       "  0.4797295331954956,\n",
       "  -0.5606369376182556,\n",
       "  0.1314791440963745,\n",
       "  -0.67149817943573,\n",
       "  0.5961520671844482,\n",
       "  -0.05805625393986702,\n",
       "  -0.22510211169719696,\n",
       "  -0.10641498118638992,\n",
       "  0.6347039341926575,\n",
       "  0.12261683493852615,\n",
       "  0.892147421836853,\n",
       "  -0.8162917494773865,\n",
       "  -0.4374884068965912,\n",
       "  -0.23337671160697937,\n",
       "  0.058299433439970016,\n",
       "  -0.3273658752441406,\n",
       "  0.396356463432312,\n",
       "  -0.6440353989601135,\n",
       "  -0.31736627221107483,\n",
       "  0.15418264269828796,\n",
       "  0.43464577198028564,\n",
       "  2.311110496520996,\n",
       "  -0.5042864084243774,\n",
       "  -0.3943621814250946,\n",
       "  0.8093128800392151,\n",
       "  0.4319644868373871,\n",
       "  0.34009596705436707,\n",
       "  -0.0050784009508788586,\n",
       "  0.42940554022789,\n",
       "  0.7789132595062256,\n",
       "  0.8749922513961792,\n",
       "  -0.8582037091255188,\n",
       "  -0.07492752373218536,\n",
       "  0.4673578143119812,\n",
       "  0.3250606060028076,\n",
       "  -0.23692339658737183,\n",
       "  -0.626206636428833,\n",
       "  -0.2363165318965912,\n",
       "  -0.10505516082048416,\n",
       "  0.31970787048339844,\n",
       "  0.32695460319519043,\n",
       "  1.1695642471313477,\n",
       "  -0.45309072732925415,\n",
       "  -0.5376868844032288,\n",
       "  -0.37556955218315125,\n",
       "  1.331621766090393,\n",
       "  -0.2551594078540802,\n",
       "  -0.32144811749458313,\n",
       "  -0.07517523318529129,\n",
       "  0.13985894620418549,\n",
       "  -0.4336807131767273,\n",
       "  -0.2624608278274536,\n",
       "  -0.036415718495845795,\n",
       "  0.02348938211798668,\n",
       "  0.4895268976688385,\n",
       "  -0.26080426573753357,\n",
       "  1.110724925994873,\n",
       "  0.0366356298327446,\n",
       "  -0.6627916097640991,\n",
       "  -0.17101523280143738,\n",
       "  -0.33620524406433105,\n",
       "  -0.32384878396987915,\n",
       "  -0.8439356684684753,\n",
       "  -1.499755859375,\n",
       "  0.7872241139411926,\n",
       "  -0.09762884676456451,\n",
       "  -0.05993214249610901,\n",
       "  -0.5818908214569092,\n",
       "  -0.2559947669506073,\n",
       "  0.617591917514801,\n",
       "  -0.743317723274231,\n",
       "  -0.07445625960826874,\n",
       "  0.127338245511055,\n",
       "  -0.6165348887443542,\n",
       "  1.0477503538131714,\n",
       "  0.7219261527061462,\n",
       "  0.45493826270103455,\n",
       "  0.003062155097723007,\n",
       "  0.30878788232803345,\n",
       "  -0.8966346383094788,\n",
       "  0.1313723623752594,\n",
       "  -0.38437917828559875,\n",
       "  0.48052382469177246,\n",
       "  0.8864767551422119,\n",
       "  0.8626394867897034,\n",
       "  0.05650787428021431,\n",
       "  -0.40523388981819153,\n",
       "  -0.06861802190542221,\n",
       "  0.8993397951126099,\n",
       "  0.22692522406578064,\n",
       "  -0.17056502401828766,\n",
       "  -0.316167414188385,\n",
       "  -0.05734885483980179,\n",
       "  -1.714473843574524,\n",
       "  0.5878476500511169,\n",
       "  -0.42975541949272156,\n",
       "  0.4087775945663452,\n",
       "  -0.1388469785451889,\n",
       "  -0.6491731405258179,\n",
       "  0.8120172023773193,\n",
       "  -0.4205626845359802,\n",
       "  0.0876774713397026,\n",
       "  0.3382278382778168,\n",
       "  1.0151114463806152,\n",
       "  1.0900181531906128,\n",
       "  0.630458652973175,\n",
       "  -0.16522328555583954,\n",
       "  -0.30965107679367065,\n",
       "  -0.4097084105014801,\n",
       "  0.5125986933708191,\n",
       "  -0.37395137548446655,\n",
       "  0.26014089584350586,\n",
       "  0.14702092111110687,\n",
       "  -0.09123756736516953,\n",
       "  0.6877101063728333,\n",
       "  -0.15717853605747223,\n",
       "  0.42875340580940247,\n",
       "  0.7832932472229004,\n",
       "  -0.4368418753147125,\n",
       "  -0.45776981115341187,\n",
       "  0.1871875524520874,\n",
       "  0.017090432345867157,\n",
       "  1.128692865371704,\n",
       "  -0.49359381198883057,\n",
       "  0.8352996706962585,\n",
       "  0.3952459394931793]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.embed([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cached data:\n",
    "# wrapper.embeddings_training\n",
    "# wrapper.embeddings_testing\n",
    "# wrapper.projector\n",
    "# wrapper.projections_training\n",
    "# wrapper.projections_testing\n",
    "# wrapper.salience_maps\n",
    "# wrapper.clusters\n",
    "# wrapper.cluster_profiles\n",
    "# wrapper.cluster_words_freqs\n",
    "# wrapper.cluster_class_word_sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

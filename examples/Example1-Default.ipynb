{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1 - Default Approach\n",
    "\n",
    "This notebook demonstrates how to use the TX2 dashboard with a sequence classification transformer using the default approach as described in the \"Basic Usage\" docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd -q ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LRU_CACHE_CAPACITY'] = '1' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We enable logging to view the output from `wrapper.prepare()` further down in the notebook. (It's a long running function, and logs which step it's on.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import cuda\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example notebook, we use the 20 newsgroups dataset, which can be downloaded through huggingfacevia below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cceaf979b82d49ba8befb1b5e9a18534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/734 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/SetFit--20_newsgroups to /home/81n/.cache/huggingface/datasets/SetFit___json/SetFit--20_newsgroups-f05bfc706e284479/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf466e782aa94138a765bbae53023cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a2a032b00542adac63c9cfa783bcaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/81n/.cache/huggingface/datasets/SetFit___json/SetFit--20_newsgroups-f05bfc706e284479/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/81n/.cache/huggingface/datasets/SetFit___json/SetFit--20_newsgroups-f05bfc706e284479/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# getting newsgroups data from huggingface\n",
    "train_data = pd.DataFrame(data=load_dataset(\"SetFit/20_newsgroups\", split=\"train\"))\n",
    "test_data = pd.DataFrame(data=load_dataset(\"SetFit/20_newsgroups\", split=\"test\"))\n",
    "\n",
    "# setting up pytorch device\n",
    "if cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.has_mps:\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Defined below is a simple sequence classification model with a variable for the language model itself `l1`. Since it is a BERT model, we take the sequence embedding from the `[CLS]` token (via `output_1[0][:, 0, :])`) and pipe that into the linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def52f8dfcb949d0a4e7f0d70fc61fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13551e4ca4e94d17b682c8f98067349f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1281131250b4405cab5aae6198a67039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0cdfb330ed04e40bbad4319edfeb3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11029bbfc72c409ebd4566f0febba3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "        self.l2 = torch.nn.Linear(768, 20)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        output_1 = self.l1(ids, mask)\n",
    "        output = self.l2(output_1[0][:, 0, :])  # use just the [CLS] output embedding\n",
    "        return output\n",
    "\n",
    "\n",
    "model = BERTClass()\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some simplistic data cleaning, and putting all data into dataframes for the wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    # text = text[text.index(\"\\n\\n\") + 2 :]\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"    \", \" \")\n",
    "    text = text.replace(\"   \", \" \")\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fair number of brave souls who upgraded thei...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>well folks, my mac plus finally gave up the gh...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you have Weitek's address/phone number? I'd...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From article &lt;C5owCB.n3p@world.std.com&gt;, by to...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye) DN...</td>\n",
       "      <td>13</td>\n",
       "      <td>sci.med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>I have a (very old) Mac 512k and a Mac Plus, b...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>Wouldn't this require a hyper-sphere. In 3-spa...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>Stolen from Pasadena between 4:30 and 6:30 pm ...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      I was wondering if anyone out there could enli...      7   \n",
       "1      A fair number of brave souls who upgraded thei...      4   \n",
       "2      well folks, my mac plus finally gave up the gh...      4   \n",
       "3      Do you have Weitek's address/phone number? I'd...      1   \n",
       "4      From article <C5owCB.n3p@world.std.com>, by to...     14   \n",
       "...                                                  ...    ...   \n",
       "11309  DN> From: nyeda@cnsvax.uwec.edu (David Nye) DN...     13   \n",
       "11310  I have a (very old) Mac 512k and a Mac Plus, b...      4   \n",
       "11311  I just installed a DX2-66 CPU in a clone mothe...      3   \n",
       "11312  Wouldn't this require a hyper-sphere. In 3-spa...      1   \n",
       "11313  Stolen from Pasadena between 4:30 and 6:30 pm ...      8   \n",
       "\n",
       "                     label_text  \n",
       "0                     rec.autos  \n",
       "1         comp.sys.mac.hardware  \n",
       "2         comp.sys.mac.hardware  \n",
       "3                 comp.graphics  \n",
       "4                     sci.space  \n",
       "...                         ...  \n",
       "11309                   sci.med  \n",
       "11310     comp.sys.mac.hardware  \n",
       "11311  comp.sys.ibm.pc.hardware  \n",
       "11312             comp.graphics  \n",
       "11313           rec.motorcycles  \n",
       "\n",
       "[11014 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean long white space or extensive character returns\n",
    "train_data.text = train_data.text.apply(lambda x: clean_text(x))\n",
    "test_data.text = test_data.text.apply(lambda x: clean_text(x))\n",
    "\n",
    "# remove empty entries or trivially short ones\n",
    "train_cleaned = train_data[train_data[\"text\"].str.len() > 1]\n",
    "test_cleaned = test_data[test_data[\"text\"].str.len() > 1]\n",
    "train_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "This section minimally trains the classification and language model - nothing fancy here, just to give the dashboard demo something to work with. Most of this is similar to the huggingface tutorial notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11014\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "class EncodedSet(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        print(self.len)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.data.text[index])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True,\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            \"targets\": torch.tensor(self.data.label[index], dtype=torch.long),\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "\n",
    "train_cleaned.reset_index(drop=True, inplace=True)\n",
    "test_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_set = EncodedSet(train_cleaned, tokenizer, 256)\n",
    "test_set = EncodedSet(test_cleaned[:1000], tokenizer, 256)\n",
    "\n",
    "train_params = {\"batch_size\": 16, \"shuffle\": True, \"num_workers\": 0}\n",
    "\n",
    "test_params = {\"batch_size\": 2, \"shuffle\": True, \"num_workers\": 0}\n",
    "\n",
    "# put everything into data loaders\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    loss_history = []\n",
    "    for _, data in tqdm(\n",
    "        enumerate(train_loader, start=0), total=len(train_loader), desc=f\"Epoch {epoch}\"\n",
    "    ):\n",
    "        ids = data[\"ids\"].to(device, dtype=torch.long)\n",
    "        mask = data[\"mask\"].to(device, dtype=torch.long)\n",
    "        targets = data[\"targets\"].to(device, dtype=torch.long)\n",
    "\n",
    "        outputs = model(ids, mask).squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, targets)\n",
    "        if _ % 100 == 0:\n",
    "            print(f\"Epoch: {epoch}, Loss:  {loss.item()}\")\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #         torch.cuda.empty_cache()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26044cc582db45c5ad113d9f046447d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/689 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  3.139150381088257\n",
      "Epoch: 0, Loss:  2.0730278491973877\n",
      "Epoch: 0, Loss:  1.1646325588226318\n",
      "Epoch: 0, Loss:  0.8112739324569702\n",
      "Epoch: 0, Loss:  1.2353179454803467\n",
      "Epoch: 0, Loss:  1.0301554203033447\n",
      "Epoch: 0, Loss:  1.0289490222930908\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(1):\n",
    "    losses.extend(train(epoch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapper uses an `encodings` dictionary for various labels/visualizations, and can be set up with something similar to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism': 0,\n",
       " 'comp.graphics': 1,\n",
       " 'comp.os.ms-windows.misc': 2,\n",
       " 'comp.sys.ibm.pc.hardware': 3,\n",
       " 'comp.sys.mac.hardware': 4,\n",
       " 'comp.windows.x': 5,\n",
       " 'misc.forsale': 6,\n",
       " 'rec.autos': 7,\n",
       " 'rec.motorcycles': 8,\n",
       " 'rec.sport.baseball': 9,\n",
       " 'rec.sport.hockey': 10,\n",
       " 'sci.crypt': 11,\n",
       " 'sci.electronics': 12,\n",
       " 'sci.med': 13,\n",
       " 'sci.space': 14,\n",
       " 'soc.religion.christian': 15,\n",
       " 'talk.politics.guns': 16,\n",
       " 'talk.politics.mideast': 17,\n",
       " 'talk.politics.misc': 18,\n",
       " 'talk.religion.misc': 19}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = (\n",
    "    train_cleaned[[\"label\", \"label_text\"]]\n",
    "    .groupby([\"label_text\"])\n",
    "    .apply(lambda x: x[\"label\"].tolist()[0])\n",
    "    .to_dict()\n",
    ")\n",
    "encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TX2\n",
    "\n",
    "This section shows how to put everything into the TX2 wrapper to get the dashboard widget displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/micromamba/envs/tx2/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/81n/micromamba/envs/tx2/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/81n/micromamba/envs/tx2/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/home/81n/micromamba/envs/tx2/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "from tx2.dashboard import Dashboard\n",
    "from tx2.wrapper import Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (l2): Linear(in_features=768, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval() # shouldn't be necessary since done in wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Cache path found\n",
      "INFO:root:Checking for cached predictions...\n",
      "INFO:root:Running classifier...\n",
      "INFO:root:Saving predictions...\n",
      "INFO:root:Writing to data/predictions.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached embeddings...\n",
      "INFO:root:Embedding training and testing datasets\n",
      "INFO:root:Saving embeddings...\n",
      "INFO:root:Writing to data/embedding_training.json\n",
      "INFO:root:Writing to data/embedding_testing.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached projections...\n",
      "INFO:root:Training projector...\n",
      "INFO:root:Applying projector to test dataset...\n",
      "INFO:root:Saving projections...\n",
      "INFO:root:Writing to data/projections_training.json\n",
      "INFO:root:Writing to data/projections_testing.json\n",
      "INFO:root:Writing to data/projector.pkl.gz\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached salience maps...\n",
      "INFO:root:Computing salience maps...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcd1236b0eb4324968c362af3452df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving salience maps...\n",
      "INFO:root:Writing to data/salience.pkl.gz\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached cluster profiles...\n",
      "INFO:root:Clustering projections...\n",
      "INFO:root:Saving cluster profiles...\n",
      "INFO:root:Writing to data/clusters.json\n",
      "INFO:root:Writing to data/cluster_profiles.pkl.gz\n",
      "INFO:root:Done!\n",
      "INFO:root:Saving cluster labels...\n",
      "INFO:root:Writing to data/cluster_labels.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Saving cluster word counts...\n",
      "INFO:root:Writing to data/cluster_words.json\n",
      "INFO:root:Writing to data/cluster_class_words.json\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "wrapper = Wrapper(\n",
    "    train_texts=train_cleaned.text,\n",
    "    train_labels=train_cleaned.label,\n",
    "    test_texts=test_cleaned.text[:2000],\n",
    "    test_labels=test_cleaned.label[:2000],\n",
    "    encodings=encodings,\n",
    "    classifier=model,\n",
    "    language_model=model.l1,\n",
    "    tokenizer=tokenizer,\n",
    "    overwrite=True,\n",
    ")\n",
    "wrapper.batch_size = 16\n",
    "wrapper.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wrapper._compute_all_salience_maps_raw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31b89af71de4f1b8e14d9314e4f652c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>UMAP Embedding Graph</h3>'), HBox(children=(Output(), VBox(child…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dash = Dashboard(wrapper)\n",
    "dash.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To play with different UMAP and DBSCAN arguments without having to recompute the entire `prepare()` function, you can use `recompute_projections` (which will recompute both the projections and visual clusterings) or `recompute_visual_clusterings` (which will only redo the clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Clustering projections...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Saving cluster profiles...\n",
      "INFO:root:Writing to data/clusters.json\n",
      "INFO:root:Writing to data/cluster_profiles.pkl.gz\n",
      "INFO:root:Done!\n",
      "INFO:root:Saving cluster labels...\n",
      "INFO:root:Writing to data/cluster_labels.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Saving cluster word counts...\n",
      "INFO:root:Writing to data/cluster_words.json\n",
      "INFO:root:Writing to data/cluster_class_words.json\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "wrapper.recompute_visual_clusterings(\"KMeans\", clustering_args=dict(n_clusters=20))\n",
    "# wrapper.recompute_visual_clusterings(\"OPTICS\", clustering_args=dict())\n",
    "# wrapper.recompute_projections(umap_args=dict(min_dist=.2), dbscan_args=dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test or debug the classification model/see what raw outputs the viusualizations are getting, or create your own visualization tools, you can manually call the `classify()`, `soft_classify()`, `embed()` functions, or get access to any of the cached data as seen in the bottom cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.170468807220459,\n",
       "  -0.42441028356552124,\n",
       "  -0.4678337275981903,\n",
       "  -0.7580161094665527,\n",
       "  0.07608048617839813,\n",
       "  -0.31217095255851746,\n",
       "  0.48881950974464417,\n",
       "  1.4150304794311523,\n",
       "  1.7861741781234741,\n",
       "  -0.1740753948688507,\n",
       "  -0.19095690548419952,\n",
       "  -0.34646695852279663,\n",
       "  0.7207998633384705,\n",
       "  -0.689913809299469,\n",
       "  0.7936819791793823,\n",
       "  -1.1157079935073853,\n",
       "  -0.25155022740364075,\n",
       "  -0.8481627106666565,\n",
       "  -1.0242692232131958,\n",
       "  -0.9014149904251099]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.soft_classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.39172840118408203,\n",
       "  1.1071618795394897,\n",
       "  0.8399309515953064,\n",
       "  0.005346053745597601,\n",
       "  -0.213631734251976,\n",
       "  -0.19168049097061157,\n",
       "  -0.09819252043962479,\n",
       "  -0.7724509835243225,\n",
       "  -0.33011215925216675,\n",
       "  -1.0723963975906372,\n",
       "  -0.00808426458388567,\n",
       "  -0.4216598570346832,\n",
       "  0.18245543539524078,\n",
       "  0.7774981260299683,\n",
       "  -0.22453688085079193,\n",
       "  0.5082960724830627,\n",
       "  0.8072395324707031,\n",
       "  -0.32681772112846375,\n",
       "  0.8773772120475769,\n",
       "  -0.8285756707191467,\n",
       "  -0.10850708186626434,\n",
       "  0.4685605764389038,\n",
       "  0.35311469435691833,\n",
       "  -0.9684391021728516,\n",
       "  -0.9024025797843933,\n",
       "  -1.2777366638183594,\n",
       "  0.17258375883102417,\n",
       "  1.0642080307006836,\n",
       "  0.9749150276184082,\n",
       "  -0.6136587858200073,\n",
       "  -1.0525697469711304,\n",
       "  0.23584699630737305,\n",
       "  -0.2278098315000534,\n",
       "  -0.31781333684921265,\n",
       "  0.1963496208190918,\n",
       "  -0.36000850796699524,\n",
       "  0.6943233609199524,\n",
       "  1.1887900829315186,\n",
       "  -0.529232919216156,\n",
       "  0.21239279210567474,\n",
       "  0.006872887723147869,\n",
       "  0.07971421629190445,\n",
       "  -0.3789396286010742,\n",
       "  0.013942397199571133,\n",
       "  0.27317991852760315,\n",
       "  -0.4336453378200531,\n",
       "  0.06788797676563263,\n",
       "  -0.5875279307365417,\n",
       "  0.18614649772644043,\n",
       "  0.6835001111030579,\n",
       "  0.9029459357261658,\n",
       "  1.4009610414505005,\n",
       "  0.18354472517967224,\n",
       "  0.11779224127531052,\n",
       "  0.4418039917945862,\n",
       "  -0.15387123823165894,\n",
       "  -0.4908428192138672,\n",
       "  0.9164953827857971,\n",
       "  -0.2924410104751587,\n",
       "  -0.08791861683130264,\n",
       "  -0.12753382325172424,\n",
       "  -0.594351589679718,\n",
       "  -0.315096914768219,\n",
       "  0.5551295876502991,\n",
       "  -0.180266872048378,\n",
       "  0.02507915161550045,\n",
       "  0.7564659118652344,\n",
       "  -1.5237852334976196,\n",
       "  0.6700976490974426,\n",
       "  -0.7488680481910706,\n",
       "  0.9466915726661682,\n",
       "  0.9873738288879395,\n",
       "  0.3256498873233795,\n",
       "  -0.42199113965034485,\n",
       "  1.5265291929244995,\n",
       "  -0.700206995010376,\n",
       "  -0.2883663773536682,\n",
       "  -0.4173123836517334,\n",
       "  -1.193505883216858,\n",
       "  0.36440181732177734,\n",
       "  0.18705832958221436,\n",
       "  -0.44312331080436707,\n",
       "  -0.6691160202026367,\n",
       "  0.14971360564231873,\n",
       "  -0.28516682982444763,\n",
       "  0.4687400460243225,\n",
       "  -0.052955545485019684,\n",
       "  0.3473813533782959,\n",
       "  0.3100403845310211,\n",
       "  -0.6656962633132935,\n",
       "  -0.19378118216991425,\n",
       "  0.8130960464477539,\n",
       "  -1.008659839630127,\n",
       "  -0.23811545968055725,\n",
       "  -0.06788066774606705,\n",
       "  -0.007873913273215294,\n",
       "  -0.7202467918395996,\n",
       "  1.223069190979004,\n",
       "  3.221039295196533,\n",
       "  -1.1828585863113403,\n",
       "  0.11932498216629028,\n",
       "  -0.8579875826835632,\n",
       "  0.2847783863544464,\n",
       "  -0.5577989816665649,\n",
       "  0.03492392972111702,\n",
       "  -0.3370289206504822,\n",
       "  -0.4633626341819763,\n",
       "  -0.8264659643173218,\n",
       "  0.3526809811592102,\n",
       "  -0.03462649881839752,\n",
       "  0.48771190643310547,\n",
       "  0.7909263372421265,\n",
       "  0.5854268670082092,\n",
       "  1.012807846069336,\n",
       "  -0.461598664522171,\n",
       "  0.06733047217130661,\n",
       "  0.029527511447668076,\n",
       "  -0.15138249099254608,\n",
       "  -0.2104497104883194,\n",
       "  0.26115110516548157,\n",
       "  0.12939508259296417,\n",
       "  0.7825204133987427,\n",
       "  1.7781072854995728,\n",
       "  -1.0353924036026,\n",
       "  0.0607210174202919,\n",
       "  -0.33164870738983154,\n",
       "  0.6088292598724365,\n",
       "  0.5098981857299805,\n",
       "  1.207358717918396,\n",
       "  0.1254289448261261,\n",
       "  -0.3611011803150177,\n",
       "  0.10726182162761688,\n",
       "  -0.6803921461105347,\n",
       "  1.127672553062439,\n",
       "  -0.8656238913536072,\n",
       "  0.018822522833943367,\n",
       "  -1.8606197834014893,\n",
       "  -0.10854332149028778,\n",
       "  -2.414140462875366,\n",
       "  -0.005525623913854361,\n",
       "  -1.2270795106887817,\n",
       "  0.9541064500808716,\n",
       "  -0.1764424741268158,\n",
       "  -0.738823652267456,\n",
       "  -0.7623053789138794,\n",
       "  1.407934546470642,\n",
       "  -0.6844809055328369,\n",
       "  0.027361338958144188,\n",
       "  0.8010807037353516,\n",
       "  -0.2135828286409378,\n",
       "  0.029307983815670013,\n",
       "  0.06842063367366791,\n",
       "  0.1461164802312851,\n",
       "  -0.9840052127838135,\n",
       "  0.8274251222610474,\n",
       "  -1.1170549392700195,\n",
       "  -0.6832382678985596,\n",
       "  -0.5233111381530762,\n",
       "  0.4166502356529236,\n",
       "  1.342957854270935,\n",
       "  0.11306536197662354,\n",
       "  0.46595239639282227,\n",
       "  -0.017462071031332016,\n",
       "  -0.02894625812768936,\n",
       "  0.8553206920623779,\n",
       "  -0.29438018798828125,\n",
       "  0.5779933333396912,\n",
       "  0.3782993257045746,\n",
       "  -0.40619638562202454,\n",
       "  -0.47391557693481445,\n",
       "  -0.7500214576721191,\n",
       "  -0.8277407884597778,\n",
       "  -0.6317543983459473,\n",
       "  0.7668736577033997,\n",
       "  0.23387223482131958,\n",
       "  0.7937071323394775,\n",
       "  0.801521897315979,\n",
       "  0.17061714828014374,\n",
       "  -0.6626601219177246,\n",
       "  -0.6731182336807251,\n",
       "  -0.7588475346565247,\n",
       "  0.09409750252962112,\n",
       "  -0.38404107093811035,\n",
       "  -1.141688346862793,\n",
       "  0.3214537501335144,\n",
       "  -0.06961273401975632,\n",
       "  0.6404469013214111,\n",
       "  -0.6273432970046997,\n",
       "  1.4047973155975342,\n",
       "  -0.8397138118743896,\n",
       "  -0.3926643431186676,\n",
       "  -1.0277283191680908,\n",
       "  -0.42404255270957947,\n",
       "  -0.39192336797714233,\n",
       "  1.8425918817520142,\n",
       "  -0.05790475010871887,\n",
       "  -0.011672035790979862,\n",
       "  -0.08164358139038086,\n",
       "  -0.057249218225479126,\n",
       "  0.05135512724518776,\n",
       "  0.15491828322410583,\n",
       "  0.33775168657302856,\n",
       "  -0.624370276927948,\n",
       "  0.7101345062255859,\n",
       "  0.3927046060562134,\n",
       "  0.32685843110084534,\n",
       "  0.5261954665184021,\n",
       "  0.5618636012077332,\n",
       "  0.16662448644638062,\n",
       "  0.09170904010534286,\n",
       "  -1.1830493211746216,\n",
       "  -0.5467891097068787,\n",
       "  0.9949676394462585,\n",
       "  -0.1415875256061554,\n",
       "  0.008152578957378864,\n",
       "  0.12944047152996063,\n",
       "  0.1547238677740097,\n",
       "  1.1338489055633545,\n",
       "  0.3221279978752136,\n",
       "  -0.3323517143726349,\n",
       "  -0.3903636932373047,\n",
       "  -0.047563254833221436,\n",
       "  0.460622638463974,\n",
       "  -0.28673699498176575,\n",
       "  0.13429485261440277,\n",
       "  0.1735651195049286,\n",
       "  0.778719961643219,\n",
       "  0.40166568756103516,\n",
       "  -0.40690672397613525,\n",
       "  -0.2256518453359604,\n",
       "  0.881553053855896,\n",
       "  1.390292763710022,\n",
       "  -0.6723548769950867,\n",
       "  0.3003308176994324,\n",
       "  -0.6082736849784851,\n",
       "  0.22084979712963104,\n",
       "  0.16897307336330414,\n",
       "  0.6490168571472168,\n",
       "  -0.7768673896789551,\n",
       "  -0.6115509867668152,\n",
       "  -0.5415298938751221,\n",
       "  -0.8248106241226196,\n",
       "  -0.4758132994174957,\n",
       "  0.7042736411094666,\n",
       "  -1.3412022590637207,\n",
       "  -1.3825228214263916,\n",
       "  0.21646089851856232,\n",
       "  -0.048944104462862015,\n",
       "  1.3320564031600952,\n",
       "  -0.45059069991111755,\n",
       "  0.9575724601745605,\n",
       "  -0.16830620169639587,\n",
       "  -0.08563884347677231,\n",
       "  -0.7295026779174805,\n",
       "  0.1590174436569214,\n",
       "  0.5683072209358215,\n",
       "  -0.20526960492134094,\n",
       "  -0.5818122029304504,\n",
       "  1.7326182126998901,\n",
       "  -0.2312716692686081,\n",
       "  0.996512770652771,\n",
       "  -2.1842403411865234,\n",
       "  0.44190269708633423,\n",
       "  -0.15104196965694427,\n",
       "  0.5243170857429504,\n",
       "  -0.3658451735973358,\n",
       "  0.2378348410129547,\n",
       "  0.33431121706962585,\n",
       "  0.33371520042419434,\n",
       "  0.2068903148174286,\n",
       "  0.27572688460350037,\n",
       "  0.5042077302932739,\n",
       "  0.07871069014072418,\n",
       "  -0.22850891947746277,\n",
       "  0.7321962118148804,\n",
       "  1.1320511102676392,\n",
       "  0.5443405508995056,\n",
       "  -0.8829616904258728,\n",
       "  0.9344590902328491,\n",
       "  0.12251222133636475,\n",
       "  -0.5813647508621216,\n",
       "  0.6507569551467896,\n",
       "  -1.315523624420166,\n",
       "  -0.4725707173347473,\n",
       "  -1.1967873573303223,\n",
       "  0.4061247706413269,\n",
       "  1.2242881059646606,\n",
       "  -0.5512977838516235,\n",
       "  0.36562514305114746,\n",
       "  1.6117461919784546,\n",
       "  0.5048696994781494,\n",
       "  0.19516004621982574,\n",
       "  -0.49762001633644104,\n",
       "  -0.7599297761917114,\n",
       "  -0.643675684928894,\n",
       "  -0.5532803535461426,\n",
       "  0.0049308836460113525,\n",
       "  -1.4286222457885742,\n",
       "  0.3362494111061096,\n",
       "  -0.09391790628433228,\n",
       "  0.16313081979751587,\n",
       "  0.27858445048332214,\n",
       "  0.24709898233413696,\n",
       "  -0.35109567642211914,\n",
       "  -0.5041067600250244,\n",
       "  -0.47920674085617065,\n",
       "  0.27654123306274414,\n",
       "  0.02031235210597515,\n",
       "  -0.057715293020009995,\n",
       "  -1.0232503414154053,\n",
       "  0.4361801743507385,\n",
       "  0.08578216284513474,\n",
       "  -0.7177267074584961,\n",
       "  -0.3121900260448456,\n",
       "  -0.9759765863418579,\n",
       "  -1.1195743083953857,\n",
       "  0.09820329397916794,\n",
       "  -0.2480320930480957,\n",
       "  -0.3059700131416321,\n",
       "  0.013631435111165047,\n",
       "  0.5520253777503967,\n",
       "  -0.07355336099863052,\n",
       "  -1.0896550416946411,\n",
       "  0.7387250661849976,\n",
       "  -0.14846207201480865,\n",
       "  0.5368480682373047,\n",
       "  0.2559007406234741,\n",
       "  -0.9817807078361511,\n",
       "  -1.2255362272262573,\n",
       "  -0.024427451193332672,\n",
       "  -0.6450631618499756,\n",
       "  -0.33275502920150757,\n",
       "  -1.057077407836914,\n",
       "  0.6359021067619324,\n",
       "  0.3722946345806122,\n",
       "  0.577971875667572,\n",
       "  0.07143726199865341,\n",
       "  0.944985032081604,\n",
       "  0.03454069048166275,\n",
       "  -0.038784563541412354,\n",
       "  0.22746698558330536,\n",
       "  0.6449285745620728,\n",
       "  0.35415616631507874,\n",
       "  -1.704606294631958,\n",
       "  1.129115343093872,\n",
       "  -0.016346793621778488,\n",
       "  0.5154545307159424,\n",
       "  -0.22489933669567108,\n",
       "  0.3492234945297241,\n",
       "  0.45719558000564575,\n",
       "  0.45584970712661743,\n",
       "  -0.9854437708854675,\n",
       "  0.1266794055700302,\n",
       "  0.6684359908103943,\n",
       "  0.6573747396469116,\n",
       "  -0.3593292236328125,\n",
       "  -0.27212145924568176,\n",
       "  0.040349241346120834,\n",
       "  0.30372294783592224,\n",
       "  0.19210420548915863,\n",
       "  -0.6626415848731995,\n",
       "  -0.29625919461250305,\n",
       "  1.4114986658096313,\n",
       "  -0.05621236190199852,\n",
       "  0.5299146175384521,\n",
       "  -1.6411309242248535,\n",
       "  0.15383411943912506,\n",
       "  0.04505137726664543,\n",
       "  -0.20534025132656097,\n",
       "  0.44217780232429504,\n",
       "  0.2890639305114746,\n",
       "  -0.07447981834411621,\n",
       "  0.01253778301179409,\n",
       "  0.13049837946891785,\n",
       "  0.2762756943702698,\n",
       "  -0.19502587616443634,\n",
       "  -0.20664367079734802,\n",
       "  0.6993551850318909,\n",
       "  -1.0213403701782227,\n",
       "  -0.20132862031459808,\n",
       "  0.023999705910682678,\n",
       "  0.6626269817352295,\n",
       "  1.5426706075668335,\n",
       "  0.4677031338214874,\n",
       "  0.6357035636901855,\n",
       "  0.2485903799533844,\n",
       "  0.6859211325645447,\n",
       "  0.1854395866394043,\n",
       "  -0.3670976459980011,\n",
       "  -0.6742914915084839,\n",
       "  0.3928475081920624,\n",
       "  -1.098288893699646,\n",
       "  1.3445637226104736,\n",
       "  -0.6304594874382019,\n",
       "  0.2645144760608673,\n",
       "  0.046655721962451935,\n",
       "  -0.5042611956596375,\n",
       "  0.5168680548667908,\n",
       "  0.1595546305179596,\n",
       "  -1.101974368095398,\n",
       "  -1.155465841293335,\n",
       "  -0.9080635905265808,\n",
       "  -1.7185304164886475,\n",
       "  0.05713425949215889,\n",
       "  0.05764113739132881,\n",
       "  0.8145368099212646,\n",
       "  0.13312092423439026,\n",
       "  0.69655841588974,\n",
       "  -0.6733043193817139,\n",
       "  -0.025556322187185287,\n",
       "  -0.24573910236358643,\n",
       "  0.025695474818348885,\n",
       "  0.15553584694862366,\n",
       "  -0.10744751989841461,\n",
       "  0.6483277082443237,\n",
       "  0.39071765542030334,\n",
       "  0.02329794317483902,\n",
       "  0.5959824323654175,\n",
       "  -0.7343570590019226,\n",
       "  0.3515149652957916,\n",
       "  -0.4945578873157501,\n",
       "  0.1432521492242813,\n",
       "  -0.18873104453086853,\n",
       "  -0.2235114872455597,\n",
       "  0.03954775258898735,\n",
       "  0.14257638156414032,\n",
       "  0.7589738368988037,\n",
       "  -0.19497667253017426,\n",
       "  0.9174829125404358,\n",
       "  0.30321916937828064,\n",
       "  -0.9132193922996521,\n",
       "  0.46402740478515625,\n",
       "  0.20095543563365936,\n",
       "  0.6095683574676514,\n",
       "  -0.28583112359046936,\n",
       "  0.6441015005111694,\n",
       "  -0.17791275680065155,\n",
       "  -0.22912831604480743,\n",
       "  -0.1944604068994522,\n",
       "  1.6374099254608154,\n",
       "  -0.755740225315094,\n",
       "  -0.18017543852329254,\n",
       "  -0.5949761271476746,\n",
       "  -0.6818135380744934,\n",
       "  -0.6173484325408936,\n",
       "  0.6998723149299622,\n",
       "  -0.2218722403049469,\n",
       "  0.06330115348100662,\n",
       "  -0.8364161849021912,\n",
       "  -0.46025022864341736,\n",
       "  0.3983321189880371,\n",
       "  -0.43360093235969543,\n",
       "  -1.3422170877456665,\n",
       "  -0.14330169558525085,\n",
       "  0.4131048917770386,\n",
       "  0.3655959367752075,\n",
       "  0.1482010930776596,\n",
       "  -0.1682916134595871,\n",
       "  -0.3568761944770813,\n",
       "  0.001923855277709663,\n",
       "  -0.7400437593460083,\n",
       "  1.637403130531311,\n",
       "  0.27855977416038513,\n",
       "  0.0026026167906820774,\n",
       "  -0.1438804715871811,\n",
       "  0.1773862987756729,\n",
       "  -0.09478956460952759,\n",
       "  0.16573406755924225,\n",
       "  -0.6356770992279053,\n",
       "  -0.8815776705741882,\n",
       "  0.7869543433189392,\n",
       "  -0.7942736744880676,\n",
       "  -0.7255598902702332,\n",
       "  0.589109480381012,\n",
       "  -1.2391821146011353,\n",
       "  0.34260401129722595,\n",
       "  -0.16420462727546692,\n",
       "  0.35038337111473083,\n",
       "  0.7302660346031189,\n",
       "  0.12324213236570358,\n",
       "  -0.5431938767433167,\n",
       "  0.30966758728027344,\n",
       "  -1.452879786491394,\n",
       "  0.21848033368587494,\n",
       "  0.1853276491165161,\n",
       "  0.3183668851852417,\n",
       "  0.7789844870567322,\n",
       "  -1.1202387809753418,\n",
       "  1.1603434085845947,\n",
       "  0.7002398371696472,\n",
       "  1.0205729007720947,\n",
       "  0.10161729902029037,\n",
       "  -1.212885856628418,\n",
       "  0.671737015247345,\n",
       "  0.14743684232234955,\n",
       "  -0.6197475790977478,\n",
       "  -0.3635096848011017,\n",
       "  -1.0003801584243774,\n",
       "  -0.7721640467643738,\n",
       "  0.04633387178182602,\n",
       "  -0.8143088221549988,\n",
       "  -0.38352981209754944,\n",
       "  0.5734195113182068,\n",
       "  0.3894117772579193,\n",
       "  -0.9724974036216736,\n",
       "  0.976525068283081,\n",
       "  -0.17186526954174042,\n",
       "  -0.7679359912872314,\n",
       "  -0.4276140630245209,\n",
       "  -0.30979520082473755,\n",
       "  1.118749976158142,\n",
       "  -0.6099492311477661,\n",
       "  -0.15294310450553894,\n",
       "  0.5653479695320129,\n",
       "  -1.0556870698928833,\n",
       "  0.48565685749053955,\n",
       "  0.25970974564552307,\n",
       "  0.34780609607696533,\n",
       "  -0.691843569278717,\n",
       "  0.5101189613342285,\n",
       "  0.7638551592826843,\n",
       "  0.5279810428619385,\n",
       "  -0.8393628001213074,\n",
       "  0.3523811101913452,\n",
       "  -0.061840228736400604,\n",
       "  0.7731403112411499,\n",
       "  -0.6649372577667236,\n",
       "  -0.08519736677408218,\n",
       "  -0.2066938728094101,\n",
       "  -0.34674835205078125,\n",
       "  -0.1260562688112259,\n",
       "  0.6762200593948364,\n",
       "  -2.054210901260376,\n",
       "  0.34470340609550476,\n",
       "  0.10937704890966415,\n",
       "  -0.4633106291294098,\n",
       "  -0.11156460642814636,\n",
       "  0.1822689026594162,\n",
       "  0.4563710689544678,\n",
       "  -1.1552705764770508,\n",
       "  -0.17932027578353882,\n",
       "  -0.5728808045387268,\n",
       "  0.8666744828224182,\n",
       "  -0.08585164695978165,\n",
       "  0.7565653324127197,\n",
       "  0.5178430080413818,\n",
       "  0.007387134712189436,\n",
       "  0.8562649488449097,\n",
       "  -0.02202453650534153,\n",
       "  0.6310586929321289,\n",
       "  -0.5130695700645447,\n",
       "  -0.27002453804016113,\n",
       "  0.4363011121749878,\n",
       "  0.9056969881057739,\n",
       "  -0.6772075891494751,\n",
       "  1.5589849948883057,\n",
       "  -0.4489455223083496,\n",
       "  -4.380568981170654,\n",
       "  0.495278000831604,\n",
       "  -0.04812389984726906,\n",
       "  -0.5273628830909729,\n",
       "  -0.2444014847278595,\n",
       "  -0.4019226133823395,\n",
       "  -0.47414615750312805,\n",
       "  0.3267970085144043,\n",
       "  -0.24810490012168884,\n",
       "  0.011849535629153252,\n",
       "  0.29736799001693726,\n",
       "  0.08922331035137177,\n",
       "  -1.3012537956237793,\n",
       "  0.8828151226043701,\n",
       "  -0.7756553292274475,\n",
       "  0.43197253346443176,\n",
       "  0.15130341053009033,\n",
       "  -0.852565586566925,\n",
       "  -0.48998576402664185,\n",
       "  1.063584327697754,\n",
       "  0.14353738725185394,\n",
       "  -0.11102031916379929,\n",
       "  -0.38833364844322205,\n",
       "  0.6917363405227661,\n",
       "  0.5274506211280823,\n",
       "  0.6196513175964355,\n",
       "  0.43255680799484253,\n",
       "  -1.1784913539886475,\n",
       "  -1.0200085639953613,\n",
       "  -0.9882622361183167,\n",
       "  -0.6896303296089172,\n",
       "  0.5574647784233093,\n",
       "  0.23130108416080475,\n",
       "  -1.1537971496582031,\n",
       "  -0.001536067109555006,\n",
       "  -0.9032675623893738,\n",
       "  0.42666757106781006,\n",
       "  0.35195931792259216,\n",
       "  0.9757703542709351,\n",
       "  -0.6135739088058472,\n",
       "  0.3574436902999878,\n",
       "  0.16329514980316162,\n",
       "  0.4869275391101837,\n",
       "  0.23968152701854706,\n",
       "  0.7171211242675781,\n",
       "  -0.38016262650489807,\n",
       "  0.32910096645355225,\n",
       "  -0.7837554216384888,\n",
       "  0.558627188205719,\n",
       "  0.049370817840099335,\n",
       "  1.6540412902832031,\n",
       "  0.07413364946842194,\n",
       "  -0.6067342162132263,\n",
       "  0.6985649466514587,\n",
       "  0.006566322408616543,\n",
       "  -0.5431504249572754,\n",
       "  0.5475283265113831,\n",
       "  -0.3313971757888794,\n",
       "  0.9790967106819153,\n",
       "  -0.6089697480201721,\n",
       "  -0.9967039823532104,\n",
       "  0.6235671043395996,\n",
       "  0.16959211230278015,\n",
       "  0.3384960889816284,\n",
       "  -0.5995057225227356,\n",
       "  0.32847753167152405,\n",
       "  0.22637885808944702,\n",
       "  -0.10896676778793335,\n",
       "  -0.17701882123947144,\n",
       "  0.3583609163761139,\n",
       "  -0.7278904914855957,\n",
       "  -0.3458455204963684,\n",
       "  -0.0933922529220581,\n",
       "  0.1331242173910141,\n",
       "  0.5774913430213928,\n",
       "  -0.28997376561164856,\n",
       "  -0.13468582928180695,\n",
       "  -0.5502707958221436,\n",
       "  -0.3327186703681946,\n",
       "  -0.11756913363933563,\n",
       "  -0.5409225225448608,\n",
       "  0.2903434932231903,\n",
       "  -0.3423502743244171,\n",
       "  0.03801325708627701,\n",
       "  -0.27651381492614746,\n",
       "  -0.038352448493242264,\n",
       "  -1.524534821510315,\n",
       "  0.7749121189117432,\n",
       "  0.44543465971946716,\n",
       "  0.445160448551178,\n",
       "  -0.7083746790885925,\n",
       "  0.11487589031457901,\n",
       "  0.24286700785160065,\n",
       "  0.9851303100585938,\n",
       "  -0.20615991950035095,\n",
       "  0.13325093686580658,\n",
       "  -0.5612971186637878,\n",
       "  -0.08699887245893478,\n",
       "  -0.22861848771572113,\n",
       "  -0.5100253820419312,\n",
       "  -0.33911842107772827,\n",
       "  0.18092747032642365,\n",
       "  -0.006691649090498686,\n",
       "  0.09859014302492142,\n",
       "  0.5219862461090088,\n",
       "  0.8944407105445862,\n",
       "  1.8310779333114624,\n",
       "  -0.3131132423877716,\n",
       "  -0.5472593903541565,\n",
       "  0.5935381054878235,\n",
       "  0.6263880729675293,\n",
       "  -0.09482014924287796,\n",
       "  0.3819997310638428,\n",
       "  0.4435679614543915,\n",
       "  0.47731950879096985,\n",
       "  0.2593724727630615,\n",
       "  -0.90920490026474,\n",
       "  -0.7194564938545227,\n",
       "  0.4951889216899872,\n",
       "  -0.01912882551550865,\n",
       "  -0.6611623764038086,\n",
       "  -0.36980539560317993,\n",
       "  -0.49275362491607666,\n",
       "  -0.07559601962566376,\n",
       "  0.6268748641014099,\n",
       "  0.6541723012924194,\n",
       "  0.18266882002353668,\n",
       "  -1.1225554943084717,\n",
       "  -0.19566188752651215,\n",
       "  -1.1068724393844604,\n",
       "  -0.06198028847575188,\n",
       "  -0.45075520873069763,\n",
       "  0.03839939832687378,\n",
       "  -0.03474663943052292,\n",
       "  -0.4176180362701416,\n",
       "  -0.914214551448822,\n",
       "  0.05977557227015495,\n",
       "  -0.05941470339894295,\n",
       "  0.16597238183021545,\n",
       "  0.8376713395118713,\n",
       "  0.09209901094436646,\n",
       "  1.3409613370895386,\n",
       "  0.5686839818954468,\n",
       "  -0.08898473531007767,\n",
       "  -0.16086958348751068,\n",
       "  0.29589784145355225,\n",
       "  -0.276025652885437,\n",
       "  -0.743439793586731,\n",
       "  -0.6907654404640198,\n",
       "  0.39455732703208923,\n",
       "  -0.6057212948799133,\n",
       "  -0.1658754050731659,\n",
       "  -1.1995058059692383,\n",
       "  -0.5043386816978455,\n",
       "  -0.11667747050523758,\n",
       "  -0.7605596780776978,\n",
       "  0.34796908497810364,\n",
       "  0.8389514088630676,\n",
       "  -0.7322452664375305,\n",
       "  1.963263988494873,\n",
       "  1.5036317110061646,\n",
       "  0.6818318367004395,\n",
       "  1.349906325340271,\n",
       "  -0.22025346755981445,\n",
       "  -0.16090615093708038,\n",
       "  -0.5430188179016113,\n",
       "  -1.0619022846221924,\n",
       "  0.19419614970684052,\n",
       "  -0.3180990517139435,\n",
       "  2.1200931072235107,\n",
       "  0.22242504358291626,\n",
       "  -0.3280840218067169,\n",
       "  -0.020742198452353477,\n",
       "  0.44260942935943604,\n",
       "  -0.21056707203388214,\n",
       "  -1.592710018157959,\n",
       "  0.000797176908235997,\n",
       "  -0.24420562386512756,\n",
       "  -0.6278805732727051,\n",
       "  0.23969805240631104,\n",
       "  0.4404953718185425,\n",
       "  1.0901840925216675,\n",
       "  0.02002216875553131,\n",
       "  -0.33734041452407837,\n",
       "  0.5457267165184021,\n",
       "  -0.17002969980239868,\n",
       "  0.1961698830127716,\n",
       "  0.22090601921081543,\n",
       "  0.5263476371765137,\n",
       "  0.6612794399261475,\n",
       "  -0.6232616305351257,\n",
       "  -0.42752495408058167,\n",
       "  -1.2719271183013916,\n",
       "  -0.5434466004371643,\n",
       "  -0.814355194568634,\n",
       "  0.15070773661136627,\n",
       "  0.20715303719043732,\n",
       "  0.26370421051979065,\n",
       "  -0.5337266325950623,\n",
       "  0.2932787537574768,\n",
       "  -0.18679817020893097,\n",
       "  0.2171974927186966,\n",
       "  1.2400943040847778,\n",
       "  -0.7025730609893799,\n",
       "  -0.3324364423751831,\n",
       "  -0.33171966671943665,\n",
       "  -0.3569253087043762,\n",
       "  0.6659753918647766,\n",
       "  -0.4654781222343445,\n",
       "  0.565321147441864,\n",
       "  0.2345104068517685]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.embed([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cached data:\n",
    "# wrapper.embeddings_training\n",
    "# wrapper.embeddings_testing\n",
    "# wrapper.projector\n",
    "# wrapper.projections_training\n",
    "# wrapper.projections_testing\n",
    "# wrapper.salience_maps\n",
    "# wrapper.clusters\n",
    "# wrapper.cluster_profiles\n",
    "# wrapper.cluster_words_freqs\n",
    "# wrapper.cluster_class_word_sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c8ebf232dea6577f6ceae92998c8d758983422845017e0e774d4bf7f66f7ab9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

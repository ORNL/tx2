{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2 - Custom Approach\n",
    "\n",
    "This notebook demonstrates how to use the TX2 dashboard with a sequence classification transformer using the custom approach as described in the \"Basic Usage\" docs. To demonstrate, we simply take the default functions for each and manually define them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -q ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We enable logging to view the output from `wrapper.prepare()` further down in the notebook. (It's a long running function, and logs which step it's on.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import cuda\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example notebook, we use the 20 newsgroups dataset, which can be downloaded through sklearn via below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "train_data = fetch_20newsgroups(subset='train')\n",
    "test_data = fetch_20newsgroups(subset='test')\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Defined below is a simple sequence classification model with a variable for the language model itself `l1`. Since it is a BERT model, we take the sequence embedding from the `[CLS]` token (via `output_1[0][:, 0, :])`) and pipe that into the linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "        self.l2 = torch.nn.Linear(768, 20)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        output_1= self.l1(ids, mask)\n",
    "        output = self.l2(output_1[0][:, 0, :]) # use just the [CLS] output embedding\n",
    "        return output\n",
    "    \n",
    "model = BERTClass()\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some simplistic data cleaning, and putting all data into dataframes for the wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text[text.index(\"\\n\\n\")+2:]\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"    \", \" \")\n",
    "    text = text.replace(\"   \", \" \")\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_rows = []\n",
    "for i in range(len(train_data[\"data\"])):\n",
    "    row = {}\n",
    "    row[\"text\"] = clean_text(train_data[\"data\"][i])\n",
    "    row[\"target\"] = train_data['target'][i]\n",
    "    if row[\"text\"] == \"\" or row[\"text\"] == \" \": continue\n",
    "    train_rows.append(row)\n",
    "train_df = pd.DataFrame(train_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rows = []\n",
    "for i in range(len(test_data[\"data\"])):\n",
    "    row = {}\n",
    "    row[\"text\"] = clean_text(test_data[\"data\"][i])\n",
    "    row[\"target\"] = test_data['target'][i]\n",
    "    if row[\"text\"] == \"\" or row[\"text\"] == \" \": continue\n",
    "    test_rows.append(row)\n",
    "test_df = pd.DataFrame(test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "This section minimally trains the classification and language model - nothing fancy here, just to give the dashboard demo something to work with. Most of this is similar to the huggingface tutorial notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11296\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "class EncodedSet(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        print(self.len)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.data.text[index])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.target[index], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "train_set = EncodedSet(train_df, tokenizer, 256)\n",
    "test_set = EncodedSet(test_df[:1000], tokenizer, 256)\n",
    "\n",
    "train_params = {'batch_size': 16,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': 2,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "# put everything into data loaders\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "    loss_history = []\n",
    "    for _,data in tqdm(enumerate(train_loader, 0), total=len(train_loader), desc=f\"Epoch {epoch}\"):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask).squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, targets)\n",
    "        if _%100==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         torch.cuda.empty_cache()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2013d413c648428af5965af99e562f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch 0'), FloatProgress(value=0.0, max=706.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  2.9316442012786865\n",
      "Epoch: 0, Loss:  2.4549002647399902\n",
      "Epoch: 0, Loss:  1.0166977643966675\n",
      "Epoch: 0, Loss:  0.7657784223556519\n",
      "Epoch: 0, Loss:  1.1686592102050781\n",
      "Epoch: 0, Loss:  1.1292028427124023\n",
      "Epoch: 0, Loss:  0.5788240432739258\n",
      "Epoch: 0, Loss:  0.9440498352050781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(1):\n",
    "    losses.extend(train(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapper uses an `encodings` dictionary for various labels/visualizations, and can be set up with something similar to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism': 0,\n",
       " 'comp.graphics': 1,\n",
       " 'comp.os.ms-windows.misc': 2,\n",
       " 'comp.sys.ibm.pc.hardware': 3,\n",
       " 'comp.sys.mac.hardware': 4,\n",
       " 'comp.windows.x': 5,\n",
       " 'misc.forsale': 6,\n",
       " 'rec.autos': 7,\n",
       " 'rec.motorcycles': 8,\n",
       " 'rec.sport.baseball': 9,\n",
       " 'rec.sport.hockey': 10,\n",
       " 'sci.crypt': 11,\n",
       " 'sci.electronics': 12,\n",
       " 'sci.med': 13,\n",
       " 'sci.space': 14,\n",
       " 'soc.religion.christian': 15,\n",
       " 'talk.politics.guns': 16,\n",
       " 'talk.politics.mideast': 17,\n",
       " 'talk.politics.misc': 18,\n",
       " 'talk.religion.misc': 19}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = {}\n",
    "for index, entry in enumerate(train_data[\"target_names\"]):\n",
    "    encodings[entry] = index\n",
    "encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TX2\n",
    "\n",
    "This section shows how to put everything into the TX2 wrapper to get the dashboard widget displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/llvmlite/binding/ffi.py:137: UserWarning: Module tx2 was already imported from None, but /home/81n/lab/tx2 is being added to sys.path\n",
      "  from pkg_resources import resource_filename\n"
     ]
    }
   ],
   "source": [
    "from tx2.wrapper import Wrapper\n",
    "from tx2.dashboard import Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tx2 import utils\n",
    "\n",
    "def custom_encoding_function(text):\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=256,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=True,\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(encoded[\"input_ids\"], device=device),\n",
    "        \"attention_mask\": torch.tensor(encoded[\"attention_mask\"], device=device),\n",
    "    }\n",
    "\n",
    "def custom_classification_function(inputs):\n",
    "    return torch.argmax(model(inputs[\"input_ids\"], inputs[\"attention_mask\"]), dim=1)\n",
    "\n",
    "def custom_embedding_function(inputs):\n",
    "    return model.l1(inputs[\"input_ids\"], inputs[\"attention_mask\"])[0][:, 0, :]  # [CLS] token embedding\n",
    "\n",
    "def custom_soft_classification_function(inputs):\n",
    "    return model(inputs[\"input_ids\"], inputs[\"attention_mask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Cache path not found, creating...\n",
      "INFO:root:Checking for cached predictions...\n",
      "INFO:root:Running classifier...\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "INFO:root:Saving predictions...\n",
      "INFO:root:Writing to data/custom_cache/predictions.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached embeddings...\n",
      "INFO:root:Embedding training and testing datasets\n",
      "INFO:root:Saving embeddings...\n",
      "INFO:root:Writing to data/custom_cache/embedding_training.json\n",
      "INFO:root:Writing to data/custom_cache/embedding_testing.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached projections...\n",
      "INFO:root:Training projector...\n",
      "INFO:root:Applying projector to test dataset...\n",
      "INFO:root:Saving projections...\n",
      "INFO:root:Writing to data/custom_cache/projections_training.json\n",
      "INFO:root:Writing to data/custom_cache/projections_testing.json\n",
      "INFO:root:Writing to data/custom_cache/projector.pkl.gz\n",
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached salience maps...\n",
      "INFO:root:Computing salience maps...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a67760987c4eda803d408b85a480e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "INFO:root:Saving salience maps...\n",
      "INFO:root:Writing to data/custom_cache/salience.pkl.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Done!\n",
      "INFO:root:Checking for cached cluster profiles...\n",
      "INFO:root:Clustering projections...\n",
      "INFO:root:Saving cluster profiles...\n",
      "INFO:root:Writing to data/custom_cache/clusters.json\n",
      "INFO:root:Writing to data/custom_cache/cluster_profiles.pkl.gz\n",
      "INFO:root:Done!\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "INFO:root:Saving cluster labels...\n",
      "INFO:root:Writing to data/custom_cache/cluster_labels.json\n",
      "INFO:root:Done!\n",
      "INFO:root:Saving cluster word counts...\n",
      "INFO:root:Writing to data/custom_cache/cluster_words.json\n",
      "INFO:root:Writing to data/custom_cache/cluster_class_words.json\n",
      "INFO:root:Done!\n"
     ]
    }
   ],
   "source": [
    "wrapper = Wrapper(\n",
    "    train_texts=train_df.text,\n",
    "    train_labels=train_df.target,\n",
    "    test_texts=test_df.text[:2000],\n",
    "    test_labels=test_df.target[:2000],\n",
    "    encodings=encodings, \n",
    "    cache_path=\"data/custom_cache\",\n",
    "    overwrite=True\n",
    ")\n",
    "wrapper.encode_function = custom_encoding_function\n",
    "wrapper.classification_function = custom_classification_function\n",
    "wrapper.soft_classification_function = custom_soft_classification_function\n",
    "wrapper.embedding_function = custom_embedding_function\n",
    "wrapper.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86553bfc03d4159bf9223354bca5c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>UMAP Embedding Graph</h3>'), HBox(children=(Output(), VBox(child…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "dash = Dashboard(wrapper, show_wordclouds=True)\n",
    "dash.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To play with different UMAP and DBSCAN arguments without having to recompute the entire `prepare()` function, you can use `recompute_projections` (which will recompute both the projections and visual clusterings) or `recompute_visual_clusterings` (which will only redo the clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper.recompute_visual_clusterings(dbscan_args=dict())\n",
    "# wrapper.recompute_projections(umap_args=dict(min_dist=.2), dbscan_args=dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test or debug the classification model/see what raw outputs the viusualizations are getting, or create your own visualization tools, you can manually call the `classify()`, `soft_classify()`, `embed()` functions, or get access to any of the cached data as seen in the bottom cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1.0488052368164062,\n",
       "  -0.03285098820924759,\n",
       "  -0.2580734193325043,\n",
       "  -0.3668859302997589,\n",
       "  0.15141808986663818,\n",
       "  -0.15236662328243256,\n",
       "  1.9831351041793823,\n",
       "  1.2149289846420288,\n",
       "  1.321704387664795,\n",
       "  -0.19445110857486725,\n",
       "  0.08170069754123688,\n",
       "  -0.11487706750631332,\n",
       "  1.019587516784668,\n",
       "  -0.02104061096906662,\n",
       "  -0.6935140490531921,\n",
       "  -0.22049453854560852,\n",
       "  -0.9581518173217773,\n",
       "  0.4018412232398987,\n",
       "  -0.6637047529220581,\n",
       "  -0.3188351094722748]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.soft_classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.43734872341156006,\n",
       "  0.16381454467773438,\n",
       "  0.08185862749814987,\n",
       "  -0.38637927174568176,\n",
       "  -0.2747752070426941,\n",
       "  0.29509079456329346,\n",
       "  0.2484285533428192,\n",
       "  -0.34395158290863037,\n",
       "  -0.5298862457275391,\n",
       "  -1.2994873523712158,\n",
       "  0.03324988856911659,\n",
       "  0.22103442251682281,\n",
       "  -0.5836265087127686,\n",
       "  0.8374025821685791,\n",
       "  -1.2318155765533447,\n",
       "  0.9985899329185486,\n",
       "  0.2384842485189438,\n",
       "  0.33898913860321045,\n",
       "  0.40220141410827637,\n",
       "  0.458391010761261,\n",
       "  -0.5837693810462952,\n",
       "  -0.9413780570030212,\n",
       "  0.21607470512390137,\n",
       "  -1.1177239418029785,\n",
       "  0.49385640025138855,\n",
       "  -0.10062618553638458,\n",
       "  0.31760454177856445,\n",
       "  1.296376347541809,\n",
       "  0.18768341839313507,\n",
       "  -0.25272172689437866,\n",
       "  -0.0787934958934784,\n",
       "  0.5208892226219177,\n",
       "  0.9109460115432739,\n",
       "  -0.030176391825079918,\n",
       "  0.07182762026786804,\n",
       "  0.11704669892787933,\n",
       "  -0.11009922623634338,\n",
       "  0.2647625207901001,\n",
       "  -0.34480756521224976,\n",
       "  -0.46474146842956543,\n",
       "  -1.0423533916473389,\n",
       "  -0.025282690301537514,\n",
       "  0.38863736391067505,\n",
       "  0.17145593464374542,\n",
       "  -0.593326210975647,\n",
       "  -0.3690794110298157,\n",
       "  0.3109707534313202,\n",
       "  -0.08692661672830582,\n",
       "  -0.5467129945755005,\n",
       "  0.6668668389320374,\n",
       "  0.8054032921791077,\n",
       "  0.9340326189994812,\n",
       "  -0.7603568434715271,\n",
       "  0.5358501076698303,\n",
       "  -0.22948797047138214,\n",
       "  0.26543232798576355,\n",
       "  -0.39430034160614014,\n",
       "  -0.30584853887557983,\n",
       "  -0.1544594168663025,\n",
       "  -0.10851555317640305,\n",
       "  -0.7760321497917175,\n",
       "  0.9239840507507324,\n",
       "  0.49869275093078613,\n",
       "  1.105225920677185,\n",
       "  -0.2330029308795929,\n",
       "  -0.05822562798857689,\n",
       "  0.6813044548034668,\n",
       "  -0.17397856712341309,\n",
       "  -0.4811317026615143,\n",
       "  -0.7230173945426941,\n",
       "  0.7081827521324158,\n",
       "  0.20135152339935303,\n",
       "  1.4638184309005737,\n",
       "  0.5260268449783325,\n",
       "  1.2055211067199707,\n",
       "  -0.3831968903541565,\n",
       "  -0.3084973990917206,\n",
       "  0.6622761487960815,\n",
       "  0.04490388184785843,\n",
       "  0.15252022445201874,\n",
       "  -0.1517838090658188,\n",
       "  0.2482653260231018,\n",
       "  -0.06666126847267151,\n",
       "  -0.29455456137657166,\n",
       "  -0.39323508739471436,\n",
       "  -0.5092183947563171,\n",
       "  -0.014000960625708103,\n",
       "  -0.03211173787713051,\n",
       "  0.6564860343933105,\n",
       "  0.45293760299682617,\n",
       "  -0.14890502393245697,\n",
       "  0.01109230238944292,\n",
       "  -1.2693520784378052,\n",
       "  0.21900369226932526,\n",
       "  -0.3055206537246704,\n",
       "  0.3985435366630554,\n",
       "  0.16371652483940125,\n",
       "  1.449711561203003,\n",
       "  2.531806707382202,\n",
       "  0.378120481967926,\n",
       "  0.10518196225166321,\n",
       "  -0.7666534781455994,\n",
       "  1.141404390335083,\n",
       "  -0.2186208814382553,\n",
       "  0.27568572759628296,\n",
       "  0.20912334322929382,\n",
       "  -0.22858980298042297,\n",
       "  0.26890629529953003,\n",
       "  0.15717269480228424,\n",
       "  -0.21604324877262115,\n",
       "  1.2817318439483643,\n",
       "  -0.051127467304468155,\n",
       "  0.9276458621025085,\n",
       "  0.457057386636734,\n",
       "  -0.1274314522743225,\n",
       "  -0.8580064177513123,\n",
       "  -0.35611188411712646,\n",
       "  0.46458736062049866,\n",
       "  -0.11264410614967346,\n",
       "  -0.0018738178769126534,\n",
       "  0.4773169457912445,\n",
       "  1.1190733909606934,\n",
       "  0.5515074729919434,\n",
       "  0.0046227374114096165,\n",
       "  -1.2384722232818604,\n",
       "  -0.311805784702301,\n",
       "  -0.39194658398628235,\n",
       "  0.3437376022338867,\n",
       "  0.7307606339454651,\n",
       "  -0.13112281262874603,\n",
       "  -0.5186178088188171,\n",
       "  0.060467787086963654,\n",
       "  0.095222607254982,\n",
       "  0.022441793233156204,\n",
       "  0.1947307139635086,\n",
       "  -0.2325255274772644,\n",
       "  -0.7862486243247986,\n",
       "  0.48241323232650757,\n",
       "  -1.5063438415527344,\n",
       "  0.564981997013092,\n",
       "  0.07604379206895828,\n",
       "  -0.24771389365196228,\n",
       "  0.4732740819454193,\n",
       "  -0.06662353873252869,\n",
       "  0.15728871524333954,\n",
       "  1.0929994583129883,\n",
       "  0.10579846799373627,\n",
       "  0.5335031747817993,\n",
       "  0.0006533304695039988,\n",
       "  -0.607653796672821,\n",
       "  0.47546783089637756,\n",
       "  -0.057916708290576935,\n",
       "  -0.24746258556842804,\n",
       "  -0.10789209604263306,\n",
       "  0.2177671641111374,\n",
       "  -0.6563754677772522,\n",
       "  -0.20466604828834534,\n",
       "  -1.4302687644958496,\n",
       "  0.5178923010826111,\n",
       "  -0.3321598172187805,\n",
       "  -0.41891834139823914,\n",
       "  -0.2586105167865753,\n",
       "  0.15683481097221375,\n",
       "  0.01269823033362627,\n",
       "  0.0074179647490382195,\n",
       "  -0.3421858251094818,\n",
       "  0.0990583673119545,\n",
       "  0.03662753477692604,\n",
       "  -0.44088900089263916,\n",
       "  1.1168255805969238,\n",
       "  -0.5958248376846313,\n",
       "  -0.5647624731063843,\n",
       "  -1.9375025033950806,\n",
       "  0.738528847694397,\n",
       "  0.39548707008361816,\n",
       "  -0.055371444672346115,\n",
       "  1.1127299070358276,\n",
       "  0.855583131313324,\n",
       "  -0.27886146306991577,\n",
       "  -0.6415232419967651,\n",
       "  -0.7077296376228333,\n",
       "  0.8517398834228516,\n",
       "  0.5813860893249512,\n",
       "  -0.10019752383232117,\n",
       "  0.043020687997341156,\n",
       "  0.6702999472618103,\n",
       "  0.36136943101882935,\n",
       "  -0.6206201910972595,\n",
       "  0.12924718856811523,\n",
       "  -0.61910080909729,\n",
       "  0.6521410942077637,\n",
       "  -0.7094514966011047,\n",
       "  -0.6147260069847107,\n",
       "  0.5015829801559448,\n",
       "  0.636406660079956,\n",
       "  -0.18324065208435059,\n",
       "  0.0633021891117096,\n",
       "  -0.18383817374706268,\n",
       "  -0.3481768071651459,\n",
       "  -0.234099879860878,\n",
       "  -0.6893999576568604,\n",
       "  0.2834685444831848,\n",
       "  -0.6038915514945984,\n",
       "  0.06798899173736572,\n",
       "  0.11308465152978897,\n",
       "  0.01803736574947834,\n",
       "  0.29456546902656555,\n",
       "  -1.0056086778640747,\n",
       "  0.4454600214958191,\n",
       "  0.4501638114452362,\n",
       "  -0.6609534621238708,\n",
       "  -0.23983630537986755,\n",
       "  0.5998791456222534,\n",
       "  -0.011311558075249195,\n",
       "  0.33869415521621704,\n",
       "  -0.3867037892341614,\n",
       "  -0.02770400047302246,\n",
       "  0.37944096326828003,\n",
       "  -0.07150128483772278,\n",
       "  -0.03655121102929115,\n",
       "  -0.4375445544719696,\n",
       "  -0.30713197588920593,\n",
       "  -0.68166583776474,\n",
       "  0.032124072313308716,\n",
       "  0.18239189684391022,\n",
       "  -0.4307558536529541,\n",
       "  -0.5487300753593445,\n",
       "  0.07559233903884888,\n",
       "  -0.2545469105243683,\n",
       "  0.40242013335227966,\n",
       "  0.9118335843086243,\n",
       "  0.1574103832244873,\n",
       "  -0.16426771879196167,\n",
       "  -0.0540485717356205,\n",
       "  0.07995688170194626,\n",
       "  0.21152466535568237,\n",
       "  -0.27555111050605774,\n",
       "  1.3222297430038452,\n",
       "  -0.532882034778595,\n",
       "  -0.23278681933879852,\n",
       "  -0.09625900536775589,\n",
       "  -0.6818658113479614,\n",
       "  0.7777673006057739,\n",
       "  0.010546286590397358,\n",
       "  0.03374876081943512,\n",
       "  0.049970678985118866,\n",
       "  0.7562365531921387,\n",
       "  0.12854614853858948,\n",
       "  0.15355637669563293,\n",
       "  -0.4022819399833679,\n",
       "  0.14696837961673737,\n",
       "  0.021012086421251297,\n",
       "  -0.8186517357826233,\n",
       "  -0.19664216041564941,\n",
       "  0.4922017753124237,\n",
       "  0.269708514213562,\n",
       "  -0.2613272964954376,\n",
       "  -0.6484733819961548,\n",
       "  0.8427254557609558,\n",
       "  -0.30028605461120605,\n",
       "  0.29379022121429443,\n",
       "  -1.009903907775879,\n",
       "  -0.0025961855426430702,\n",
       "  -0.3354032039642334,\n",
       "  0.6738681793212891,\n",
       "  -0.15294310450553894,\n",
       "  -0.7623574137687683,\n",
       "  0.009366600774228573,\n",
       "  -0.6586668491363525,\n",
       "  0.18624956905841827,\n",
       "  0.6375772953033447,\n",
       "  -0.7975708842277527,\n",
       "  -0.08397004753351212,\n",
       "  0.27405017614364624,\n",
       "  0.8992999196052551,\n",
       "  0.1603490114212036,\n",
       "  0.11146467924118042,\n",
       "  -0.7794198393821716,\n",
       "  0.2926175594329834,\n",
       "  -0.541013777256012,\n",
       "  -0.3128334879875183,\n",
       "  0.5170604586601257,\n",
       "  -1.1213951110839844,\n",
       "  1.138793706893921,\n",
       "  -0.7466362118721008,\n",
       "  0.7072031497955322,\n",
       "  0.9036934971809387,\n",
       "  -0.35536131262779236,\n",
       "  -0.38547179102897644,\n",
       "  1.5651395320892334,\n",
       "  0.6512636542320251,\n",
       "  -0.8375299572944641,\n",
       "  -0.03041284903883934,\n",
       "  -0.022745875641703606,\n",
       "  -0.5844519138336182,\n",
       "  0.02908986806869507,\n",
       "  0.04929516837000847,\n",
       "  -0.4904218316078186,\n",
       "  -0.6170645952224731,\n",
       "  0.20301811397075653,\n",
       "  0.37247151136398315,\n",
       "  -0.20374833047389984,\n",
       "  -0.4156286418437958,\n",
       "  0.1594448685646057,\n",
       "  -1.2959790229797363,\n",
       "  -0.05500054731965065,\n",
       "  -0.0034907159861177206,\n",
       "  0.056839559227228165,\n",
       "  -0.32253438234329224,\n",
       "  0.38958150148391724,\n",
       "  -0.710431694984436,\n",
       "  0.12341490387916565,\n",
       "  -0.28640758991241455,\n",
       "  -0.2961639165878296,\n",
       "  -1.3382395505905151,\n",
       "  -0.7841609120368958,\n",
       "  -0.5752162337303162,\n",
       "  0.3887084722518921,\n",
       "  -0.7372307181358337,\n",
       "  -0.14068646728992462,\n",
       "  0.44271498918533325,\n",
       "  0.5989047884941101,\n",
       "  -0.5874540209770203,\n",
       "  -0.048081234097480774,\n",
       "  -0.23168818652629852,\n",
       "  0.838311493396759,\n",
       "  0.6276289820671082,\n",
       "  -0.10826301574707031,\n",
       "  -0.7693272233009338,\n",
       "  0.26937586069107056,\n",
       "  0.0869477316737175,\n",
       "  0.5533854961395264,\n",
       "  -0.16331452131271362,\n",
       "  0.7879760265350342,\n",
       "  -0.9895719885826111,\n",
       "  0.01854707859456539,\n",
       "  -0.22593246400356293,\n",
       "  0.47565382719039917,\n",
       "  0.2740943431854248,\n",
       "  -0.5244295597076416,\n",
       "  -0.2592928111553192,\n",
       "  1.024665117263794,\n",
       "  -0.6705440282821655,\n",
       "  -0.20997756719589233,\n",
       "  0.7563191652297974,\n",
       "  -0.34425345063209534,\n",
       "  -0.010136113502085209,\n",
       "  -0.8907795548439026,\n",
       "  0.8863651752471924,\n",
       "  -0.15911279618740082,\n",
       "  -0.04465309903025627,\n",
       "  -0.5719935894012451,\n",
       "  -0.2537548542022705,\n",
       "  -0.33229953050613403,\n",
       "  -0.1521211862564087,\n",
       "  -0.13373924791812897,\n",
       "  0.30079564452171326,\n",
       "  -0.03228011727333069,\n",
       "  -0.823269784450531,\n",
       "  0.04177132248878479,\n",
       "  0.3651905953884125,\n",
       "  -0.8351092338562012,\n",
       "  1.2526111602783203,\n",
       "  0.2195335030555725,\n",
       "  1.6003475189208984,\n",
       "  -0.20379899442195892,\n",
       "  -0.4240292012691498,\n",
       "  0.23110896348953247,\n",
       "  -0.5146353244781494,\n",
       "  0.861534833908081,\n",
       "  0.330291211605072,\n",
       "  0.190670907497406,\n",
       "  -0.1670508235692978,\n",
       "  -0.1709202378988266,\n",
       "  0.24479684233665466,\n",
       "  -0.22128164768218994,\n",
       "  0.6694042086601257,\n",
       "  0.025201208889484406,\n",
       "  0.026405222713947296,\n",
       "  0.0065006595104932785,\n",
       "  -0.6894447207450867,\n",
       "  0.4371272027492523,\n",
       "  -0.04446619376540184,\n",
       "  0.48360371589660645,\n",
       "  0.2524532079696655,\n",
       "  0.8168191909790039,\n",
       "  -0.2618543207645416,\n",
       "  0.42692580819129944,\n",
       "  0.450091689825058,\n",
       "  -0.22632470726966858,\n",
       "  0.39835765957832336,\n",
       "  -0.40788033604621887,\n",
       "  0.11904948204755783,\n",
       "  -0.4003901481628418,\n",
       "  -0.2203197032213211,\n",
       "  -0.09920607507228851,\n",
       "  0.4328151047229767,\n",
       "  0.3293505311012268,\n",
       "  0.7812917828559875,\n",
       "  -0.6363142132759094,\n",
       "  0.12602198123931885,\n",
       "  0.13183069229125977,\n",
       "  -0.0851946473121643,\n",
       "  -0.4213433861732483,\n",
       "  -0.32241737842559814,\n",
       "  0.640181839466095,\n",
       "  -0.41595107316970825,\n",
       "  -0.36526399850845337,\n",
       "  -0.02663363702595234,\n",
       "  0.12023575603961945,\n",
       "  0.9927319288253784,\n",
       "  0.5279598236083984,\n",
       "  -0.26212912797927856,\n",
       "  0.18452252447605133,\n",
       "  1.0544933080673218,\n",
       "  -0.10267497599124908,\n",
       "  -0.8325592279434204,\n",
       "  0.5517750978469849,\n",
       "  -0.02126290835440159,\n",
       "  -0.12082424014806747,\n",
       "  -0.12134193629026413,\n",
       "  0.15290969610214233,\n",
       "  0.27296462655067444,\n",
       "  -0.8605350852012634,\n",
       "  -0.3789879381656647,\n",
       "  0.34495243430137634,\n",
       "  -0.3658701479434967,\n",
       "  -1.169464349746704,\n",
       "  0.4680177867412567,\n",
       "  0.12277683615684509,\n",
       "  0.31274694204330444,\n",
       "  0.49603188037872314,\n",
       "  -0.33265799283981323,\n",
       "  0.05100470408797264,\n",
       "  -0.3910512924194336,\n",
       "  -0.12625662982463837,\n",
       "  0.7285405993461609,\n",
       "  -0.7890374064445496,\n",
       "  0.8431500196456909,\n",
       "  1.081636905670166,\n",
       "  -0.70831298828125,\n",
       "  -0.010430877096951008,\n",
       "  0.4354343116283417,\n",
       "  -0.6230211853981018,\n",
       "  -0.15037840604782104,\n",
       "  0.34742191433906555,\n",
       "  -0.22085034847259521,\n",
       "  0.18279729783535004,\n",
       "  -0.4595649838447571,\n",
       "  -0.30729833245277405,\n",
       "  -0.3010976016521454,\n",
       "  0.6139541864395142,\n",
       "  -0.1621519774198532,\n",
       "  -0.6120238304138184,\n",
       "  0.5483061075210571,\n",
       "  -0.3424553871154785,\n",
       "  0.5828123688697815,\n",
       "  0.009383795782923698,\n",
       "  -1.287401556968689,\n",
       "  0.11469263583421707,\n",
       "  -0.5137220025062561,\n",
       "  0.12516187131404877,\n",
       "  0.3644440770149231,\n",
       "  1.1606374979019165,\n",
       "  0.6574710011482239,\n",
       "  -0.005305309779942036,\n",
       "  -0.5775519013404846,\n",
       "  0.6832769513130188,\n",
       "  -0.5162717700004578,\n",
       "  -0.6042145490646362,\n",
       "  -0.4047665297985077,\n",
       "  -0.2992805242538452,\n",
       "  -0.06606593728065491,\n",
       "  0.7869070172309875,\n",
       "  -0.15826834738254547,\n",
       "  0.485502690076828,\n",
       "  0.2223171591758728,\n",
       "  0.7933880090713501,\n",
       "  0.41600093245506287,\n",
       "  1.2630325555801392,\n",
       "  0.07166916131973267,\n",
       "  -0.04283500835299492,\n",
       "  -0.26002237200737,\n",
       "  0.8171700835227966,\n",
       "  0.8516066074371338,\n",
       "  -0.08421847224235535,\n",
       "  0.2319510281085968,\n",
       "  -0.3643583059310913,\n",
       "  0.19829712808132172,\n",
       "  0.0382952056825161,\n",
       "  0.2817331552505493,\n",
       "  0.5992657542228699,\n",
       "  -0.253181517124176,\n",
       "  0.2653008997440338,\n",
       "  -0.2674325406551361,\n",
       "  -0.4053597152233124,\n",
       "  -1.0432829856872559,\n",
       "  -0.40580591559410095,\n",
       "  -0.6051008105278015,\n",
       "  -0.11783954501152039,\n",
       "  -0.40389618277549744,\n",
       "  0.21425972878932953,\n",
       "  -0.1302568018436432,\n",
       "  0.4002934992313385,\n",
       "  -0.5497509241104126,\n",
       "  0.38608843088150024,\n",
       "  0.5816430449485779,\n",
       "  0.5807685852050781,\n",
       "  -0.5470295548439026,\n",
       "  -1.5225545167922974,\n",
       "  0.3556467890739441,\n",
       "  -0.6049278974533081,\n",
       "  -0.45401620864868164,\n",
       "  0.3120594322681427,\n",
       "  0.22721537947654724,\n",
       "  -0.36651214957237244,\n",
       "  0.866790235042572,\n",
       "  -0.06637046486139297,\n",
       "  -0.027699274942278862,\n",
       "  0.6007184386253357,\n",
       "  0.6309886574745178,\n",
       "  0.13252855837345123,\n",
       "  -0.8982263207435608,\n",
       "  0.1783190667629242,\n",
       "  0.7338998317718506,\n",
       "  -0.21335016191005707,\n",
       "  -0.00700076250359416,\n",
       "  0.6042906045913696,\n",
       "  -0.17026466131210327,\n",
       "  -0.05696409195661545,\n",
       "  -0.0884048268198967,\n",
       "  0.28574812412261963,\n",
       "  -0.1874721199274063,\n",
       "  -0.20932388305664062,\n",
       "  -0.5613303184509277,\n",
       "  -0.3875916004180908,\n",
       "  -0.3743765354156494,\n",
       "  -0.5617007613182068,\n",
       "  0.36792561411857605,\n",
       "  -0.3817973732948303,\n",
       "  0.4471079707145691,\n",
       "  0.08995623141527176,\n",
       "  0.38646525144577026,\n",
       "  -0.530953049659729,\n",
       "  0.1054316908121109,\n",
       "  -0.09382314234972,\n",
       "  0.4368070960044861,\n",
       "  -0.8136230111122131,\n",
       "  -0.20120631158351898,\n",
       "  -0.16655196249485016,\n",
       "  0.06987055391073227,\n",
       "  0.3271302878856659,\n",
       "  -0.48590636253356934,\n",
       "  -0.1956508755683899,\n",
       "  -0.28627297282218933,\n",
       "  0.6928426027297974,\n",
       "  -0.6217676401138306,\n",
       "  -6.775979518890381,\n",
       "  0.1628042757511139,\n",
       "  0.5316336750984192,\n",
       "  0.30152490735054016,\n",
       "  -0.5836636424064636,\n",
       "  0.15018349885940552,\n",
       "  0.8887717723846436,\n",
       "  0.20311230421066284,\n",
       "  0.06617403775453568,\n",
       "  -0.28575506806373596,\n",
       "  -0.6392951607704163,\n",
       "  0.10548591613769531,\n",
       "  -1.3192375898361206,\n",
       "  0.579712450504303,\n",
       "  -0.3940896689891815,\n",
       "  0.5695053339004517,\n",
       "  0.44958895444869995,\n",
       "  -1.2897818088531494,\n",
       "  0.2409057319164276,\n",
       "  0.6186288595199585,\n",
       "  0.06628460437059402,\n",
       "  0.33097273111343384,\n",
       "  -0.036153968423604965,\n",
       "  -0.14104320108890533,\n",
       "  0.8847872614860535,\n",
       "  0.7153189778327942,\n",
       "  0.05388258025050163,\n",
       "  -0.3467027246952057,\n",
       "  0.3821605443954468,\n",
       "  0.04135094955563545,\n",
       "  0.010474123992025852,\n",
       "  0.48507994413375854,\n",
       "  0.31122997403144836,\n",
       "  -1.064932107925415,\n",
       "  -0.03301346302032471,\n",
       "  -0.9921003580093384,\n",
       "  0.09006808698177338,\n",
       "  0.21928098797798157,\n",
       "  0.24491047859191895,\n",
       "  -1.5100101232528687,\n",
       "  0.5606715083122253,\n",
       "  -0.11517328768968582,\n",
       "  -0.35228586196899414,\n",
       "  -0.1139683872461319,\n",
       "  -0.5500222444534302,\n",
       "  -0.3287143409252167,\n",
       "  0.09052566438913345,\n",
       "  -0.24682073295116425,\n",
       "  0.9911482334136963,\n",
       "  0.6398839950561523,\n",
       "  1.4320616722106934,\n",
       "  0.7825803160667419,\n",
       "  0.0002160164003726095,\n",
       "  -0.4991826117038727,\n",
       "  -0.06681036949157715,\n",
       "  0.7486667633056641,\n",
       "  -0.10039841383695602,\n",
       "  0.673008382320404,\n",
       "  1.176823616027832,\n",
       "  -0.08920735120773315,\n",
       "  -0.6367038488388062,\n",
       "  -0.06678411364555359,\n",
       "  -0.314863383769989,\n",
       "  -0.4658237397670746,\n",
       "  0.04951930046081543,\n",
       "  0.35632529854774475,\n",
       "  0.6241808533668518,\n",
       "  0.05186793580651283,\n",
       "  0.620514452457428,\n",
       "  0.26997965574264526,\n",
       "  0.2919096052646637,\n",
       "  0.08926423639059067,\n",
       "  -0.02677747793495655,\n",
       "  0.2756219804286957,\n",
       "  0.2124992460012436,\n",
       "  0.21775084733963013,\n",
       "  -0.8962925672531128,\n",
       "  -0.1546524614095688,\n",
       "  -1.3608267307281494,\n",
       "  0.4356168508529663,\n",
       "  -0.4000692665576935,\n",
       "  0.04042305797338486,\n",
       "  0.3041609227657318,\n",
       "  0.3831139802932739,\n",
       "  0.058986518532037735,\n",
       "  0.009856234304606915,\n",
       "  -0.8411582112312317,\n",
       "  -0.06982050836086273,\n",
       "  -0.16347116231918335,\n",
       "  -0.42170894145965576,\n",
       "  -0.5506396889686584,\n",
       "  -0.45622751116752625,\n",
       "  -1.1356143951416016,\n",
       "  1.2766578197479248,\n",
       "  -0.20354658365249634,\n",
       "  0.21902449429035187,\n",
       "  0.06493829935789108,\n",
       "  0.3972140848636627,\n",
       "  -0.0854693353176117,\n",
       "  -0.06826336681842804,\n",
       "  -0.8838551044464111,\n",
       "  0.8872929811477661,\n",
       "  -0.930823028087616,\n",
       "  -0.589393138885498,\n",
       "  0.24827000498771667,\n",
       "  0.35977017879486084,\n",
       "  1.0069745779037476,\n",
       "  -0.01933986134827137,\n",
       "  0.18919122219085693,\n",
       "  1.0161092281341553,\n",
       "  0.11128392815589905,\n",
       "  0.7165914177894592,\n",
       "  0.6056979894638062,\n",
       "  0.4674069583415985,\n",
       "  -0.14379654824733734,\n",
       "  0.5303284525871277,\n",
       "  -0.6409708261489868,\n",
       "  -0.28515851497650146,\n",
       "  0.6651978492736816,\n",
       "  0.2581302523612976,\n",
       "  -0.3851640522480011,\n",
       "  -0.8590890765190125,\n",
       "  -0.02154519408941269,\n",
       "  -0.9177353978157043,\n",
       "  0.3918355405330658,\n",
       "  0.6313782930374146,\n",
       "  0.09674002975225449,\n",
       "  -0.9118431210517883,\n",
       "  -0.2475106418132782,\n",
       "  -0.6567744016647339,\n",
       "  0.40757235884666443,\n",
       "  -0.8823003768920898,\n",
       "  -0.06950797885656357,\n",
       "  0.05424799025058746,\n",
       "  0.20978595316410065,\n",
       "  -0.3941158950328827,\n",
       "  0.3361428380012512,\n",
       "  -0.12338019907474518,\n",
       "  0.21016332507133484,\n",
       "  0.8508817553520203,\n",
       "  0.014895036816596985,\n",
       "  0.3782806992530823,\n",
       "  0.4715026021003723,\n",
       "  -0.6047579646110535,\n",
       "  0.4760069251060486,\n",
       "  0.40637481212615967,\n",
       "  0.3198540210723877,\n",
       "  -0.14403197169303894,\n",
       "  -1.3548657894134521,\n",
       "  -0.020599020645022392,\n",
       "  -0.11630946397781372,\n",
       "  0.19045832753181458,\n",
       "  -0.470293790102005,\n",
       "  -0.12372734397649765,\n",
       "  0.44929713010787964,\n",
       "  -0.6891227960586548,\n",
       "  0.05648525804281235,\n",
       "  0.18390820920467377,\n",
       "  -0.5390512347221375,\n",
       "  1.4783048629760742,\n",
       "  0.8389219641685486,\n",
       "  -0.523695170879364,\n",
       "  0.3974228501319885,\n",
       "  -0.3736113905906677,\n",
       "  0.31700506806373596,\n",
       "  -0.23799709975719452,\n",
       "  -0.02423163689672947,\n",
       "  -0.08830337226390839,\n",
       "  0.48056066036224365,\n",
       "  0.965661346912384,\n",
       "  -1.3476375341415405,\n",
       "  -0.19267050921916962,\n",
       "  -0.34902575612068176,\n",
       "  0.0678403377532959,\n",
       "  -0.36777326464653015,\n",
       "  -1.3666541576385498,\n",
       "  -0.4510999619960785,\n",
       "  0.6172265410423279,\n",
       "  -1.1050422191619873,\n",
       "  -0.09438387304544449,\n",
       "  0.0032000397332012653,\n",
       "  -0.37954628467559814,\n",
       "  -0.6334083080291748,\n",
       "  -0.9380371570587158,\n",
       "  0.9646251201629639,\n",
       "  0.246079221367836,\n",
       "  0.39043718576431274,\n",
       "  -0.3790621757507324,\n",
       "  -0.1545514315366745,\n",
       "  0.1831105649471283,\n",
       "  0.19710280001163483,\n",
       "  0.34852439165115356,\n",
       "  -1.325474739074707,\n",
       "  -0.49542301893234253,\n",
       "  -0.1743106096982956,\n",
       "  -0.027016373351216316,\n",
       "  -0.5775903463363647,\n",
       "  0.31398653984069824,\n",
       "  -0.9037181735038757,\n",
       "  0.39045611023902893,\n",
       "  -0.0931813195347786,\n",
       "  0.04637786000967026,\n",
       "  -0.7622135281562805,\n",
       "  -1.195105791091919,\n",
       "  0.4037027060985565,\n",
       "  -0.006445905659347773,\n",
       "  -0.006409736350178719,\n",
       "  0.3131965100765228,\n",
       "  -0.5669305920600891,\n",
       "  0.2172461301088333,\n",
       "  -0.2292461097240448]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.embed([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cached data:\n",
    "# wrapper.embeddings_training\n",
    "# wrapper.embeddings_testing\n",
    "# wrapper.projector\n",
    "# wrapper.projections_training\n",
    "# wrapper.projections_testing\n",
    "# wrapper.salience_maps\n",
    "# wrapper.clusters\n",
    "# wrapper.cluster_profiles\n",
    "# wrapper.cluster_words_freqs\n",
    "# wrapper.cluster_class_word_sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

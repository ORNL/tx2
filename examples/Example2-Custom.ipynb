{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2 - Custom Approach\n",
    "\n",
    "This notebook demonstrates how to use the TX2 dashboard with a sequence classification transformer using the custom approach as described in the \"Basic Usage\" docs. To demonstrate, we simply take the default functions for each and manually define them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd -q ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We enable logging to view the output from `wrapper.prepare()` further down in the notebook. (It's a long running function, and logs which step it's on.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import cuda\n",
    "from transformers import AutoModel, AutoTokenizer, BertTokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example notebook, we use the 20 newsgroups dataset, which can be downloaded through sklearn via below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "train_data = fetch_20newsgroups(subset='train')\n",
    "test_data = fetch_20newsgroups(subset='test')\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "Defined below is a simple sequence classification model with a variable for the language model itself `l1`. Since it is a BERT model, we take the sequence embedding from the `[CLS]` token (via `output_1[0][:, 0, :])`) and pipe that into the linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "        self.l2 = torch.nn.Linear(768, 20)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        output_1= self.l1(ids, mask)\n",
    "        output = self.l2(output_1[0][:, 0, :]) # use just the [CLS] output embedding\n",
    "        return output\n",
    "    \n",
    "model = BERTClass()\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some simplistic data cleaning, and putting all data into dataframes for the wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text[text.index(\"\\n\\n\")+2:]\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\"    \", \" \")\n",
    "    text = text.replace(\"   \", \" \")\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_rows = []\n",
    "for i in range(len(train_data[\"data\"])):\n",
    "    row = {}\n",
    "    row[\"text\"] = clean_text(train_data[\"data\"][i])\n",
    "    row[\"target\"] = train_data['target'][i]\n",
    "    if row[\"text\"] == \"\" or row[\"text\"] == \" \": continue\n",
    "    train_rows.append(row)\n",
    "train_df = pd.DataFrame(train_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rows = []\n",
    "for i in range(len(test_data[\"data\"])):\n",
    "    row = {}\n",
    "    row[\"text\"] = clean_text(test_data[\"data\"][i])\n",
    "    row[\"target\"] = test_data['target'][i]\n",
    "    if row[\"text\"] == \"\" or row[\"text\"] == \" \": continue\n",
    "    test_rows.append(row)\n",
    "test_df = pd.DataFrame(test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "This section minimally trains the classification and language model - nothing fancy here, just to give the dashboard demo something to work with. Most of this is similar to the huggingface tutorial notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11296\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "class EncodedSet(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        print(self.len)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.data.text[index])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.target[index], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "train_set = EncodedSet(train_df, tokenizer, 256)\n",
    "test_set = EncodedSet(test_df[:1000], tokenizer, 256)\n",
    "\n",
    "train_params = {'batch_size': 16,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': 2,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "# put everything into data loaders\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "    loss_history = []\n",
    "    for _,data in tqdm(enumerate(train_loader, 0), total=len(train_loader), desc=f\"Epoch {epoch}\"):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask).squeeze()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs, targets)\n",
    "        if _%100==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         torch.cuda.empty_cache()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59537217ee644a0b27db7220249b934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch 0'), FloatProgress(value=0.0, max=706.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:  3.0621426105499268\n",
      "Epoch: 0, Loss:  2.1853384971618652\n",
      "Epoch: 0, Loss:  1.2323518991470337\n",
      "Epoch: 0, Loss:  0.7899547815322876\n",
      "Epoch: 0, Loss:  0.6378146409988403\n",
      "Epoch: 0, Loss:  0.34727099537849426\n",
      "Epoch: 0, Loss:  0.7990703582763672\n",
      "Epoch: 0, Loss:  0.4353039562702179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(1):\n",
    "    losses.extend(train(epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapper uses an `encodings` dictionary for various labels/visualizations, and can be set up with something similar to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alt.atheism': 0,\n",
       " 'comp.graphics': 1,\n",
       " 'comp.os.ms-windows.misc': 2,\n",
       " 'comp.sys.ibm.pc.hardware': 3,\n",
       " 'comp.sys.mac.hardware': 4,\n",
       " 'comp.windows.x': 5,\n",
       " 'misc.forsale': 6,\n",
       " 'rec.autos': 7,\n",
       " 'rec.motorcycles': 8,\n",
       " 'rec.sport.baseball': 9,\n",
       " 'rec.sport.hockey': 10,\n",
       " 'sci.crypt': 11,\n",
       " 'sci.electronics': 12,\n",
       " 'sci.med': 13,\n",
       " 'sci.space': 14,\n",
       " 'soc.religion.christian': 15,\n",
       " 'talk.politics.guns': 16,\n",
       " 'talk.politics.mideast': 17,\n",
       " 'talk.politics.misc': 18,\n",
       " 'talk.religion.misc': 19}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = {}\n",
    "for index, entry in enumerate(train_data[\"target_names\"]):\n",
    "    encodings[entry] = index\n",
    "encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TX2\n",
    "\n",
    "This section shows how to put everything into the TX2 wrapper to get the dashboard widget displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/llvmlite/binding/ffi.py:137: UserWarning: Module tx2 was already imported from None, but /home/81n/lab/tx2 is being added to sys.path\n",
      "  from pkg_resources import resource_filename\n"
     ]
    }
   ],
   "source": [
    "from tx2.wrapper import Wrapper\n",
    "from tx2.dashboard import Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tx2 import utils\n",
    "\n",
    "def custom_encoding_function(text):\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        text,\n",
    "        None,\n",
    "        add_special_tokens=True,\n",
    "        max_length=256,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True,\n",
    "        return_token_type_ids=True,\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(encoded[\"input_ids\"], device=device),\n",
    "        \"attention_mask\": torch.tensor(encoded[\"attention_mask\"], device=device),\n",
    "    }\n",
    "\n",
    "def custom_classification_function(inputs):\n",
    "    return torch.argmax(model(inputs[\"input_ids\"], inputs[\"attention_mask\"]), dim=1)\n",
    "\n",
    "def custom_embedding_function(inputs):\n",
    "    return model.l1(inputs[\"input_ids\"], inputs[\"attention_mask\"])[0][:, 0, :]  # [CLS] token embedding\n",
    "\n",
    "def custom_soft_classification_function(inputs):\n",
    "    return model(inputs[\"input_ids\"], inputs[\"attention_mask\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Cache path found\n",
      "INFO:root:Checking for cached predictions...\n",
      "INFO:root:cached version 'data/custom_cache/predictions.json' found\n",
      "INFO:root:Checking for cached embeddings...\n",
      "INFO:root:cached version 'data/custom_cache/embedding_training.json' found\n",
      "INFO:root:cached version 'data/custom_cache/embedding_testing.json' found\n",
      "INFO:root:Checking for cached projections...\n",
      "INFO:root:cached version 'data/custom_cache/projections_training.json' found\n",
      "INFO:root:cached version 'data/custom_cache/projections_testing.json' found\n",
      "INFO:root:cached version 'data/custom_cache/projector.pkl.gz' found\n",
      "INFO:root:Checking for cached salience maps...\n",
      "INFO:root:cached version 'data/custom_cache/salience.pkl.gz' found\n",
      "INFO:root:Checking for cached cluster profiles...\n",
      "INFO:root:cached version 'data/custom_cache/cluster_profiles.pkl.gz' found\n",
      "INFO:root:cached version 'data/custom_cache/clusters.json' found\n",
      "INFO:root:cached version 'data/custom_cache/cluster_labels.json' found\n",
      "INFO:root:cached version 'data/custom_cache/cluster_words.json' found\n",
      "INFO:root:cached version 'data/custom_cache/cluster_class_words.json' found\n"
     ]
    }
   ],
   "source": [
    "wrapper = Wrapper(\n",
    "    train_texts=train_df.text,\n",
    "    train_labels=train_df.target,\n",
    "    test_texts=test_df.text[:2000],\n",
    "    test_labels=test_df.target[:2000],\n",
    "    encodings=encodings, \n",
    "    cache_path=\"data/custom_cache\",\n",
    "    overwrite=False\n",
    ")\n",
    "wrapper.encode_function = custom_encoding_function\n",
    "wrapper.classification_function = custom_classification_function\n",
    "wrapper.soft_classification_function = custom_soft_classification_function\n",
    "wrapper.embedding_function = custom_embedding_function\n",
    "wrapper.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00ce740f5dc4bf1a1fd241572c8e2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>UMAP Embedding Graph</h3>'), HBox(children=(Output(), VBox(child…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/81n/miniconda3/envs/tx2/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "dash = Dashboard(wrapper, show_wordclouds=True)\n",
    "dash.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To play with different UMAP and DBSCAN arguments without having to recompute the entire `prepare()` function, you can use `recompute_projections` (which will recompute both the projections and visual clusterings) or `recompute_visual_clusterings` (which will only redo the clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper.recompute_visual_clusterings(dbscan_args=dict())\n",
    "# wrapper.recompute_projections(umap_args=dict(min_dist=.2), dbscan_args=dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test or debug the classification model/see what raw outputs the viusualizations are getting, or create your own visualization tools, you can manually call the `classify()`, `soft_classify()`, `embed()` functions, or get access to any of the cached data as seen in the bottom cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.0289225485175848,\n",
       "  0.21903502941131592,\n",
       "  -0.18919363617897034,\n",
       "  0.1605398803949356,\n",
       "  0.35047945380210876,\n",
       "  -0.5973342657089233,\n",
       "  1.0397224426269531,\n",
       "  1.237997055053711,\n",
       "  1.0223766565322876,\n",
       "  -0.4297390282154083,\n",
       "  -0.6682910919189453,\n",
       "  -1.2943071126937866,\n",
       "  1.389951229095459,\n",
       "  1.2935385704040527,\n",
       "  1.6164648532867432,\n",
       "  -1.0083789825439453,\n",
       "  -0.5446566343307495,\n",
       "  -0.4000367820262909,\n",
       "  0.32286688685417175,\n",
       "  -0.2159416824579239]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.soft_classify([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5794275999069214,\n",
       "  -0.30842527747154236,\n",
       "  -0.0424782894551754,\n",
       "  -0.30981895327568054,\n",
       "  -0.950285792350769,\n",
       "  -0.6514168381690979,\n",
       "  -0.3009045720100403,\n",
       "  -0.32175737619400024,\n",
       "  -1.2961032390594482,\n",
       "  -1.067375898361206,\n",
       "  0.5512518286705017,\n",
       "  -0.06799433380365372,\n",
       "  -0.5763489007949829,\n",
       "  0.9716912508010864,\n",
       "  -0.12169316411018372,\n",
       "  -0.40487140417099,\n",
       "  0.12381374090909958,\n",
       "  -0.1836201548576355,\n",
       "  0.8955320119857788,\n",
       "  0.30653151869773865,\n",
       "  0.038127750158309937,\n",
       "  1.0368579626083374,\n",
       "  0.5208004713058472,\n",
       "  -0.216702401638031,\n",
       "  -0.46597930788993835,\n",
       "  -0.24625352025032043,\n",
       "  0.20494405925273895,\n",
       "  0.43428710103034973,\n",
       "  -0.13562679290771484,\n",
       "  -0.06501410901546478,\n",
       "  -0.8096764087677002,\n",
       "  1.6236478090286255,\n",
       "  -0.5914164185523987,\n",
       "  -0.09828721731901169,\n",
       "  -0.04803937301039696,\n",
       "  0.4422769546508789,\n",
       "  -0.023149991407990456,\n",
       "  -0.13874715566635132,\n",
       "  0.2850764989852905,\n",
       "  0.30533310770988464,\n",
       "  -1.0567861795425415,\n",
       "  -0.04981256648898125,\n",
       "  -0.6363614201545715,\n",
       "  -0.12316347658634186,\n",
       "  0.6840664744377136,\n",
       "  -0.2359188050031662,\n",
       "  -0.43075355887413025,\n",
       "  -0.7258733510971069,\n",
       "  -0.5584375262260437,\n",
       "  1.046665906906128,\n",
       "  0.16865931451320648,\n",
       "  1.2876026630401611,\n",
       "  0.8049183487892151,\n",
       "  0.5609402656555176,\n",
       "  0.7644240260124207,\n",
       "  0.41896241903305054,\n",
       "  -0.6711384057998657,\n",
       "  -0.7355194091796875,\n",
       "  -0.14001630246639252,\n",
       "  0.6844278573989868,\n",
       "  -0.062159791588783264,\n",
       "  -0.26407569646835327,\n",
       "  -0.7983140349388123,\n",
       "  1.0427826642990112,\n",
       "  0.2501938045024872,\n",
       "  -0.481728196144104,\n",
       "  0.414817214012146,\n",
       "  -0.22044028341770172,\n",
       "  0.17822371423244476,\n",
       "  0.19267414510250092,\n",
       "  0.49384909868240356,\n",
       "  0.1806449145078659,\n",
       "  0.15484096109867096,\n",
       "  0.06621599942445755,\n",
       "  0.9434936046600342,\n",
       "  -0.7722559571266174,\n",
       "  0.44418421387672424,\n",
       "  -0.12303414195775986,\n",
       "  -1.3748937845230103,\n",
       "  0.5163073539733887,\n",
       "  0.5853450894355774,\n",
       "  -0.517403244972229,\n",
       "  -0.42223191261291504,\n",
       "  -0.5874415636062622,\n",
       "  0.615358293056488,\n",
       "  -0.10352499037981033,\n",
       "  -0.8376932144165039,\n",
       "  0.15793947875499725,\n",
       "  0.6135917901992798,\n",
       "  0.13565365970134735,\n",
       "  0.06458792835474014,\n",
       "  0.4711156487464905,\n",
       "  -0.7946925759315491,\n",
       "  0.8382329344749451,\n",
       "  -0.5620477795600891,\n",
       "  0.439014196395874,\n",
       "  0.20200282335281372,\n",
       "  1.2435541152954102,\n",
       "  0.9437997341156006,\n",
       "  -0.04275776445865631,\n",
       "  0.1921265572309494,\n",
       "  -0.8444339632987976,\n",
       "  -0.25940263271331787,\n",
       "  0.24514172971248627,\n",
       "  0.0025134175084531307,\n",
       "  0.7741695046424866,\n",
       "  0.09016206115484238,\n",
       "  -0.6001692414283752,\n",
       "  0.0848904699087143,\n",
       "  -0.1478583961725235,\n",
       "  0.48687469959259033,\n",
       "  0.2997775673866272,\n",
       "  -0.16761194169521332,\n",
       "  0.8764302134513855,\n",
       "  -0.7281224131584167,\n",
       "  -0.45243924856185913,\n",
       "  -0.549859344959259,\n",
       "  -0.6991528868675232,\n",
       "  -0.715717613697052,\n",
       "  0.3172728717327118,\n",
       "  0.6924461722373962,\n",
       "  -0.7367532849311829,\n",
       "  1.8389403820037842,\n",
       "  -0.6248996257781982,\n",
       "  -0.9550243616104126,\n",
       "  0.36524417996406555,\n",
       "  -0.35333365201950073,\n",
       "  0.5305680632591248,\n",
       "  0.6731092929840088,\n",
       "  -0.6586732864379883,\n",
       "  -0.04803280904889107,\n",
       "  -0.7359394431114197,\n",
       "  -0.5777141451835632,\n",
       "  0.03332541137933731,\n",
       "  -0.05043075978755951,\n",
       "  -0.1385779231786728,\n",
       "  -1.6754114627838135,\n",
       "  1.4226888418197632,\n",
       "  -1.925755262374878,\n",
       "  0.41702449321746826,\n",
       "  -1.0254766941070557,\n",
       "  -0.40351879596710205,\n",
       "  0.03542420268058777,\n",
       "  -0.34525585174560547,\n",
       "  -0.42248886823654175,\n",
       "  1.772295355796814,\n",
       "  -0.4860093593597412,\n",
       "  -0.8028653860092163,\n",
       "  1.387425422668457,\n",
       "  -0.32241764664649963,\n",
       "  -0.5203568935394287,\n",
       "  0.26067763566970825,\n",
       "  -0.46653515100479126,\n",
       "  -1.3869644403457642,\n",
       "  -0.7572191953659058,\n",
       "  -1.4546787738800049,\n",
       "  -0.20400939881801605,\n",
       "  0.5438793301582336,\n",
       "  0.43748360872268677,\n",
       "  -0.03833026811480522,\n",
       "  -0.6508514881134033,\n",
       "  -1.2299323081970215,\n",
       "  -0.42726200819015503,\n",
       "  -0.5487986207008362,\n",
       "  0.8547870516777039,\n",
       "  -2.0331532955169678,\n",
       "  1.9466544389724731,\n",
       "  -0.5331860780715942,\n",
       "  -0.5090201497077942,\n",
       "  -0.5516724586486816,\n",
       "  0.16184942424297333,\n",
       "  -0.656632661819458,\n",
       "  -0.5683995485305786,\n",
       "  0.32531100511550903,\n",
       "  -0.38532161712646484,\n",
       "  0.3516118824481964,\n",
       "  0.1112009808421135,\n",
       "  0.17581309378147125,\n",
       "  -0.6815605759620667,\n",
       "  -1.027612328529358,\n",
       "  0.06211744621396065,\n",
       "  1.207534670829773,\n",
       "  -0.02050413191318512,\n",
       "  -0.9273245930671692,\n",
       "  -0.37727266550064087,\n",
       "  0.14934366941452026,\n",
       "  -0.3780975937843323,\n",
       "  -0.14480651915073395,\n",
       "  0.43863585591316223,\n",
       "  -0.5332514047622681,\n",
       "  0.8824429512023926,\n",
       "  0.8376866579055786,\n",
       "  -0.7676658630371094,\n",
       "  0.5290164351463318,\n",
       "  0.7155138850212097,\n",
       "  0.6040441989898682,\n",
       "  -0.013549424707889557,\n",
       "  0.32346630096435547,\n",
       "  -0.11507668346166611,\n",
       "  -0.1415180265903473,\n",
       "  0.22188812494277954,\n",
       "  0.3363384008407593,\n",
       "  -1.5116854906082153,\n",
       "  -0.3631655275821686,\n",
       "  0.09467028081417084,\n",
       "  -0.0023297674488276243,\n",
       "  -0.995013952255249,\n",
       "  -0.08816182613372803,\n",
       "  0.8804423213005066,\n",
       "  -0.37511149048805237,\n",
       "  -0.6043616533279419,\n",
       "  0.0175436120480299,\n",
       "  1.5738979578018188,\n",
       "  0.7264550924301147,\n",
       "  -0.2620641589164734,\n",
       "  0.03803671523928642,\n",
       "  -0.4092245101928711,\n",
       "  -0.27884751558303833,\n",
       "  0.42554351687431335,\n",
       "  0.30433037877082825,\n",
       "  -0.7283826470375061,\n",
       "  0.8902703523635864,\n",
       "  -0.5681374073028564,\n",
       "  -0.7624568939208984,\n",
       "  0.37503454089164734,\n",
       "  0.7186759114265442,\n",
       "  0.2912859618663788,\n",
       "  0.945967972278595,\n",
       "  0.20599479973316193,\n",
       "  -0.7565481662750244,\n",
       "  0.854051411151886,\n",
       "  0.8975323438644409,\n",
       "  -0.6656701564788818,\n",
       "  -0.9952164888381958,\n",
       "  0.40389567613601685,\n",
       "  0.7106534242630005,\n",
       "  -0.803645670413971,\n",
       "  0.5170267820358276,\n",
       "  0.01661183126270771,\n",
       "  -0.04554815962910652,\n",
       "  -0.5547384023666382,\n",
       "  -0.5781826972961426,\n",
       "  0.47792109847068787,\n",
       "  -0.13135521113872528,\n",
       "  0.47303155064582825,\n",
       "  0.4724554419517517,\n",
       "  0.9987715482711792,\n",
       "  0.8719304203987122,\n",
       "  0.7880333662033081,\n",
       "  0.36228594183921814,\n",
       "  1.8928886651992798,\n",
       "  0.37412741780281067,\n",
       "  -0.05792711675167084,\n",
       "  0.670413076877594,\n",
       "  1.032377004623413,\n",
       "  0.11769793182611465,\n",
       "  -0.3809901475906372,\n",
       "  -0.3447471559047699,\n",
       "  2.1615006923675537,\n",
       "  -1.9937330484390259,\n",
       "  1.4231805801391602,\n",
       "  -3.0889244079589844,\n",
       "  0.6004447937011719,\n",
       "  -0.17208637297153473,\n",
       "  -0.6757478713989258,\n",
       "  -0.36188197135925293,\n",
       "  0.41121119260787964,\n",
       "  0.9104775786399841,\n",
       "  1.054426908493042,\n",
       "  0.14979806542396545,\n",
       "  1.2089877128601074,\n",
       "  0.019122369587421417,\n",
       "  -0.9991908073425293,\n",
       "  0.100847527384758,\n",
       "  0.40236350893974304,\n",
       "  0.592964768409729,\n",
       "  0.4920524060726166,\n",
       "  0.7122094631195068,\n",
       "  0.27403199672698975,\n",
       "  -0.07523329555988312,\n",
       "  -1.550963282585144,\n",
       "  0.7592858076095581,\n",
       "  -0.3430601954460144,\n",
       "  0.9821615219116211,\n",
       "  -0.34059977531433105,\n",
       "  0.1353529393672943,\n",
       "  1.0383049249649048,\n",
       "  -1.3839644193649292,\n",
       "  -0.16916190087795258,\n",
       "  2.826307535171509,\n",
       "  0.4387098252773285,\n",
       "  -0.18187420070171356,\n",
       "  -0.5204911231994629,\n",
       "  0.24856802821159363,\n",
       "  -0.4357922673225403,\n",
       "  0.26543888449668884,\n",
       "  -0.7297430634498596,\n",
       "  -0.3483695089817047,\n",
       "  -1.2864420413970947,\n",
       "  0.9787932634353638,\n",
       "  0.6472861766815186,\n",
       "  0.31731659173965454,\n",
       "  -0.41290083527565,\n",
       "  0.27360591292381287,\n",
       "  -1.4121922254562378,\n",
       "  -1.39189875125885,\n",
       "  0.9411246180534363,\n",
       "  -0.6809040904045105,\n",
       "  0.04596149921417236,\n",
       "  -0.7115921974182129,\n",
       "  0.29470938444137573,\n",
       "  0.7983066439628601,\n",
       "  -0.506873369216919,\n",
       "  -0.8518205881118774,\n",
       "  -1.2591118812561035,\n",
       "  0.07094591856002808,\n",
       "  -0.4225235879421234,\n",
       "  0.13829387724399567,\n",
       "  -1.913007378578186,\n",
       "  -0.8124913573265076,\n",
       "  -0.2539919316768646,\n",
       "  0.09284664690494537,\n",
       "  -0.22956448793411255,\n",
       "  -0.5954520106315613,\n",
       "  -0.20717573165893555,\n",
       "  -0.5201261639595032,\n",
       "  -0.030081773176789284,\n",
       "  0.12540093064308167,\n",
       "  -1.3441715240478516,\n",
       "  0.6802475452423096,\n",
       "  0.676523745059967,\n",
       "  -1.2599395513534546,\n",
       "  0.23478473722934723,\n",
       "  -1.7121317386627197,\n",
       "  -0.6111226677894592,\n",
       "  0.0070368447341024876,\n",
       "  -0.05004863068461418,\n",
       "  0.34053945541381836,\n",
       "  1.200920820236206,\n",
       "  -0.5486708283424377,\n",
       "  -0.061143580824136734,\n",
       "  -0.05825100466609001,\n",
       "  0.1486562192440033,\n",
       "  -1.4818025827407837,\n",
       "  -0.09411925822496414,\n",
       "  -0.03969632834196091,\n",
       "  0.12569814920425415,\n",
       "  -0.9179345369338989,\n",
       "  -0.23824447393417358,\n",
       "  -0.7110853791236877,\n",
       "  -0.29370880126953125,\n",
       "  -1.144753098487854,\n",
       "  0.9375413656234741,\n",
       "  -1.1645421981811523,\n",
       "  0.055302944034338,\n",
       "  0.8567380309104919,\n",
       "  -0.8453959822654724,\n",
       "  -0.6414861679077148,\n",
       "  -0.11842330545186996,\n",
       "  -0.7497613430023193,\n",
       "  -0.6110763549804688,\n",
       "  -1.4667704105377197,\n",
       "  0.8417717814445496,\n",
       "  -0.19506950676441193,\n",
       "  -0.45605650544166565,\n",
       "  -0.9585486650466919,\n",
       "  0.6009999513626099,\n",
       "  -1.8381825685501099,\n",
       "  0.09744200855493546,\n",
       "  0.20885314047336578,\n",
       "  1.1826579570770264,\n",
       "  0.5264837145805359,\n",
       "  -0.1325359046459198,\n",
       "  0.6386473178863525,\n",
       "  0.3427184820175171,\n",
       "  -0.2313171923160553,\n",
       "  -0.4854908585548401,\n",
       "  0.500526487827301,\n",
       "  -0.7416778206825256,\n",
       "  -0.02884448878467083,\n",
       "  0.7694582939147949,\n",
       "  0.8579497337341309,\n",
       "  1.2270433902740479,\n",
       "  -0.35160425305366516,\n",
       "  0.4913167357444763,\n",
       "  0.32331913709640503,\n",
       "  1.5037046670913696,\n",
       "  -0.1799679845571518,\n",
       "  0.44033077359199524,\n",
       "  0.9443545341491699,\n",
       "  0.049745798110961914,\n",
       "  -1.2653898000717163,\n",
       "  0.029098449274897575,\n",
       "  -1.3340688943862915,\n",
       "  -0.18237067759037018,\n",
       "  0.8949186205863953,\n",
       "  -1.0385715961456299,\n",
       "  0.6544530391693115,\n",
       "  1.2176852226257324,\n",
       "  -1.4039157629013062,\n",
       "  -0.8412463068962097,\n",
       "  -0.45762884616851807,\n",
       "  -0.3359953463077545,\n",
       "  -0.000893856689799577,\n",
       "  -0.039483144879341125,\n",
       "  0.64676433801651,\n",
       "  -0.21523457765579224,\n",
       "  0.5016087293624878,\n",
       "  -1.8923934698104858,\n",
       "  1.2775222063064575,\n",
       "  -0.8573390245437622,\n",
       "  0.19576521217823029,\n",
       "  -0.17426078021526337,\n",
       "  0.3553663194179535,\n",
       "  1.0738506317138672,\n",
       "  -0.5542758703231812,\n",
       "  0.1466265618801117,\n",
       "  0.425555944442749,\n",
       "  1.2746583223342896,\n",
       "  -0.488338440656662,\n",
       "  -0.5374215841293335,\n",
       "  -0.2167862355709076,\n",
       "  -0.06365930289030075,\n",
       "  -0.6695882678031921,\n",
       "  0.30711033940315247,\n",
       "  0.5302034020423889,\n",
       "  0.3256048560142517,\n",
       "  -0.6608856320381165,\n",
       "  0.06311474740505219,\n",
       "  0.2884477376937866,\n",
       "  -1.260964274406433,\n",
       "  0.5620587468147278,\n",
       "  0.3460234999656677,\n",
       "  -0.2152474969625473,\n",
       "  -0.0952637791633606,\n",
       "  0.25989747047424316,\n",
       "  0.11083197593688965,\n",
       "  -0.4084568917751312,\n",
       "  -0.5731146931648254,\n",
       "  2.1159369945526123,\n",
       "  0.10228849947452545,\n",
       "  -0.8057408928871155,\n",
       "  0.2869601845741272,\n",
       "  -0.4123813211917877,\n",
       "  -0.07087627798318863,\n",
       "  -0.02543613687157631,\n",
       "  0.08841066807508469,\n",
       "  0.5859398245811462,\n",
       "  -0.9908239841461182,\n",
       "  -0.8612903952598572,\n",
       "  0.2567127048969269,\n",
       "  1.0425348281860352,\n",
       "  -1.1243454217910767,\n",
       "  -0.13828137516975403,\n",
       "  0.6503690481185913,\n",
       "  1.4542570114135742,\n",
       "  0.48576757311820984,\n",
       "  0.3101724684238434,\n",
       "  -1.8540489673614502,\n",
       "  0.3199208080768585,\n",
       "  -0.46281179785728455,\n",
       "  0.42719513177871704,\n",
       "  0.913991391658783,\n",
       "  0.3678445816040039,\n",
       "  0.21924592554569244,\n",
       "  -0.19515196979045868,\n",
       "  0.4977593421936035,\n",
       "  0.5439125299453735,\n",
       "  -0.4259772002696991,\n",
       "  -1.0038663148880005,\n",
       "  0.4909915030002594,\n",
       "  -0.37244343757629395,\n",
       "  0.31120508909225464,\n",
       "  -0.19129349291324615,\n",
       "  0.29951298236846924,\n",
       "  -0.06078064441680908,\n",
       "  -0.5368248820304871,\n",
       "  -0.09263197332620621,\n",
       "  0.9786389470100403,\n",
       "  0.05852316692471504,\n",
       "  -0.5666390657424927,\n",
       "  0.4517189562320709,\n",
       "  -0.3626883924007416,\n",
       "  0.053674906492233276,\n",
       "  0.3044176399707794,\n",
       "  -0.05857077240943909,\n",
       "  -0.9206488132476807,\n",
       "  -0.4393286406993866,\n",
       "  1.372822642326355,\n",
       "  1.5047982931137085,\n",
       "  -0.4699561297893524,\n",
       "  0.6318734288215637,\n",
       "  -0.5778735280036926,\n",
       "  0.49434900283813477,\n",
       "  -0.03748927637934685,\n",
       "  -0.4475117623806,\n",
       "  -0.4845597743988037,\n",
       "  -1.2457236051559448,\n",
       "  -0.7200306057929993,\n",
       "  -0.29186710715293884,\n",
       "  -0.4276648461818695,\n",
       "  -0.3977120816707611,\n",
       "  0.25044915080070496,\n",
       "  -0.10081777721643448,\n",
       "  -0.6153416633605957,\n",
       "  0.6054629683494568,\n",
       "  -1.5096813440322876,\n",
       "  -0.8163586854934692,\n",
       "  -1.0901892185211182,\n",
       "  -0.8719239234924316,\n",
       "  1.611445426940918,\n",
       "  0.3089677691459656,\n",
       "  -1.3969297409057617,\n",
       "  0.3327690064907074,\n",
       "  0.6512887477874756,\n",
       "  0.8823713660240173,\n",
       "  -0.013636467978358269,\n",
       "  0.9773433804512024,\n",
       "  -0.7189017534255981,\n",
       "  1.3122313022613525,\n",
       "  0.5937402248382568,\n",
       "  -0.01736639067530632,\n",
       "  -1.7101936340332031,\n",
       "  0.3104923367500305,\n",
       "  0.36052390933036804,\n",
       "  0.8575000762939453,\n",
       "  0.3461112976074219,\n",
       "  0.1766788810491562,\n",
       "  -0.3900561034679413,\n",
       "  -0.9219352602958679,\n",
       "  -0.48583051562309265,\n",
       "  0.3121010661125183,\n",
       "  -0.6135722398757935,\n",
       "  0.2048288732767105,\n",
       "  -0.20184290409088135,\n",
       "  0.05901133641600609,\n",
       "  0.6798661351203918,\n",
       "  1.40314781665802,\n",
       "  0.13868582248687744,\n",
       "  -0.6601091027259827,\n",
       "  0.8736023306846619,\n",
       "  0.4741506576538086,\n",
       "  0.23493972420692444,\n",
       "  0.21668526530265808,\n",
       "  -0.43456435203552246,\n",
       "  0.4684474766254425,\n",
       "  -0.6509465575218201,\n",
       "  0.8786786794662476,\n",
       "  0.2472173273563385,\n",
       "  0.45875096321105957,\n",
       "  -0.3288070261478424,\n",
       "  -0.6928998231887817,\n",
       "  -0.9152008891105652,\n",
       "  -0.4937761723995209,\n",
       "  0.9111217856407166,\n",
       "  0.9775909185409546,\n",
       "  -0.3907763361930847,\n",
       "  -2.032508373260498,\n",
       "  -0.11744532734155655,\n",
       "  0.010712866671383381,\n",
       "  -0.2546486258506775,\n",
       "  0.5092599391937256,\n",
       "  -0.5320358276367188,\n",
       "  0.3580694794654846,\n",
       "  0.3964398205280304,\n",
       "  0.3430565893650055,\n",
       "  0.8699960112571716,\n",
       "  -0.8146846294403076,\n",
       "  -0.40731629729270935,\n",
       "  -1.5203789472579956,\n",
       "  0.22576704621315002,\n",
       "  -0.938894510269165,\n",
       "  -0.17853191494941711,\n",
       "  0.982621967792511,\n",
       "  -2.326460361480713,\n",
       "  -0.5204741358757019,\n",
       "  -0.19569841027259827,\n",
       "  -0.6495019197463989,\n",
       "  0.13450562953948975,\n",
       "  0.16154836118221283,\n",
       "  0.6813944578170776,\n",
       "  1.2593984603881836,\n",
       "  0.16323132812976837,\n",
       "  0.901594877243042,\n",
       "  -0.7576536536216736,\n",
       "  0.08676143735647202,\n",
       "  -0.013832999393343925,\n",
       "  0.30624690651893616,\n",
       "  1.078084111213684,\n",
       "  0.45739540457725525,\n",
       "  -1.0155563354492188,\n",
       "  0.6363867521286011,\n",
       "  -1.1239060163497925,\n",
       "  -0.055847976356744766,\n",
       "  -0.8489358425140381,\n",
       "  0.8634449243545532,\n",
       "  -0.29647159576416016,\n",
       "  0.06756269186735153,\n",
       "  -1.010870337486267,\n",
       "  -0.33428719639778137,\n",
       "  0.26528894901275635,\n",
       "  0.35060715675354004,\n",
       "  0.5246627926826477,\n",
       "  -0.4266975522041321,\n",
       "  -0.902843713760376,\n",
       "  0.6610350608825684,\n",
       "  -0.6970198154449463,\n",
       "  1.5060561895370483,\n",
       "  0.2914722263813019,\n",
       "  -0.4354623258113861,\n",
       "  -0.4635812044143677,\n",
       "  0.4740959107875824,\n",
       "  0.6648692488670349,\n",
       "  0.09540006518363953,\n",
       "  1.0739226341247559,\n",
       "  0.6474186182022095,\n",
       "  -1.1322879791259766,\n",
       "  -1.336288332939148,\n",
       "  0.05613560974597931,\n",
       "  -0.43450212478637695,\n",
       "  -0.108527772128582,\n",
       "  0.539851725101471,\n",
       "  -0.8629368543624878,\n",
       "  0.06807184219360352,\n",
       "  -1.1637612581253052,\n",
       "  -0.30809885263442993,\n",
       "  -0.186386838555336,\n",
       "  -0.22243963181972504,\n",
       "  -0.6131570339202881,\n",
       "  0.22513456642627716,\n",
       "  -0.281717985868454,\n",
       "  1.0917283296585083,\n",
       "  -0.8546761274337769,\n",
       "  -0.30966225266456604,\n",
       "  -0.47431105375289917,\n",
       "  -0.7892504930496216,\n",
       "  0.41954973340034485,\n",
       "  -0.815855860710144,\n",
       "  0.03402408957481384,\n",
       "  -0.04850894957780838,\n",
       "  -0.6984358429908752,\n",
       "  0.5869811773300171,\n",
       "  -0.018779447302222252,\n",
       "  -0.48084548115730286,\n",
       "  0.7244443297386169,\n",
       "  -0.6206017136573792,\n",
       "  0.5164569020271301,\n",
       "  0.7191300392150879,\n",
       "  -0.40263766050338745,\n",
       "  0.1310102939605713,\n",
       "  0.7820426225662231,\n",
       "  0.3389437794685364,\n",
       "  0.8689771890640259,\n",
       "  -0.6316953897476196,\n",
       "  0.1403413712978363,\n",
       "  0.023558540269732475,\n",
       "  0.44168946146965027,\n",
       "  0.01270663645118475,\n",
       "  0.16869135200977325,\n",
       "  -0.21555694937705994,\n",
       "  0.1550922989845276,\n",
       "  0.6649443507194519,\n",
       "  0.5977864861488342,\n",
       "  2.043086290359497,\n",
       "  0.024982614442706108,\n",
       "  -0.3597475290298462,\n",
       "  0.3552245497703552,\n",
       "  1.1638000011444092,\n",
       "  0.05585043877363205,\n",
       "  0.6263506412506104,\n",
       "  0.7138670682907104,\n",
       "  0.5622302293777466,\n",
       "  0.60023432970047,\n",
       "  -0.18476589024066925,\n",
       "  0.21984437108039856,\n",
       "  0.5477147102355957,\n",
       "  0.2817709445953369,\n",
       "  -0.9124662280082703,\n",
       "  -0.6575933694839478,\n",
       "  -0.24252445995807648,\n",
       "  -0.040281131863594055,\n",
       "  0.14570610225200653,\n",
       "  0.8883280754089355,\n",
       "  1.2056549787521362,\n",
       "  0.4604076147079468,\n",
       "  -0.6961895823478699,\n",
       "  -0.8400110006332397,\n",
       "  1.0594987869262695,\n",
       "  -0.2985570430755615,\n",
       "  0.14796555042266846,\n",
       "  0.19578354060649872,\n",
       "  -0.591547966003418,\n",
       "  0.2687070071697235,\n",
       "  -1.091513991355896,\n",
       "  -0.6399598121643066,\n",
       "  0.6592872738838196,\n",
       "  1.5329759120941162,\n",
       "  -0.6179354786872864,\n",
       "  0.5602681040763855,\n",
       "  0.4511340260505676,\n",
       "  -0.8815662860870361,\n",
       "  0.11066050082445145,\n",
       "  -0.04778924211859703,\n",
       "  -0.7463340759277344,\n",
       "  -1.1065267324447632,\n",
       "  -0.4252888560295105,\n",
       "  -1.0725497007369995,\n",
       "  -1.1990591287612915,\n",
       "  0.24267524480819702,\n",
       "  0.3553712069988251,\n",
       "  0.342699259519577,\n",
       "  0.14998041093349457,\n",
       "  -1.8012808561325073,\n",
       "  -0.34829673171043396,\n",
       "  1.309618353843689,\n",
       "  -0.3441668748855591,\n",
       "  0.8261888027191162,\n",
       "  0.6637338995933533,\n",
       "  0.42735373973846436,\n",
       "  -0.20702168345451355,\n",
       "  0.8672578930854797,\n",
       "  -1.5719144344329834,\n",
       "  0.5242425203323364,\n",
       "  0.2640356719493866,\n",
       "  -0.03076869808137417,\n",
       "  -0.11005325615406036,\n",
       "  1.2961703538894653,\n",
       "  -0.7764121294021606,\n",
       "  -0.7855067253112793,\n",
       "  0.6316243410110474,\n",
       "  0.15476572513580322,\n",
       "  -0.7239136695861816,\n",
       "  -0.4279542565345764,\n",
       "  -0.3252736032009125,\n",
       "  1.128098964691162,\n",
       "  -0.5902414321899414,\n",
       "  -0.2474440485239029,\n",
       "  -0.3838050067424774,\n",
       "  0.6950098872184753,\n",
       "  -0.372837096452713,\n",
       "  -0.2241317480802536,\n",
       "  -0.05820712819695473,\n",
       "  0.7114517688751221,\n",
       "  -0.24612784385681152,\n",
       "  0.3247772753238678,\n",
       "  0.8267360329627991,\n",
       "  1.3313897848129272,\n",
       "  1.2985587120056152,\n",
       "  0.20246493816375732,\n",
       "  -0.6258608102798462,\n",
       "  -0.20867696404457092,\n",
       "  1.0811855792999268,\n",
       "  0.7898407578468323,\n",
       "  0.5594598650932312,\n",
       "  -0.053398218005895615,\n",
       "  -0.2955593168735504,\n",
       "  -0.3384949862957001,\n",
       "  -0.03951195627450943,\n",
       "  0.8664493560791016,\n",
       "  0.3916514813899994,\n",
       "  -1.02322256565094,\n",
       "  0.3887576758861542,\n",
       "  -0.5469453930854797,\n",
       "  -0.1653871238231659,\n",
       "  0.3212801218032837,\n",
       "  -0.8203713297843933,\n",
       "  0.7797914743423462,\n",
       "  1.310255527496338]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper.embed([\"testing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cached data:\n",
    "# wrapper.embeddings_training\n",
    "# wrapper.embeddings_testing\n",
    "# wrapper.projector\n",
    "# wrapper.projections_training\n",
    "# wrapper.projections_testing\n",
    "# wrapper.salience_maps\n",
    "# wrapper.clusters\n",
    "# wrapper.cluster_profiles\n",
    "# wrapper.cluster_words_freqs\n",
    "# wrapper.cluster_class_word_sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
